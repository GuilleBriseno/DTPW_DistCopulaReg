# Fitting function

# Useful trycatch variation:
myTryCatch <- function(expr){
  
  warn <- err <- NULL
  
  value <- withCallingHandlers(
    
    tryCatch(expr, error=function(e) {
      
      err <<- e
      
      NULL
    }), warning=function(w) {
      
      warn <<- w
      
      invokeRestart("muffleWarning")
    })
  
  list(value=value, warning=warn, error=err)
}


# small function for confidence intervals
lies_in_interval <- function(true_value, interval){
  
  
  lies_within <- data.table::between(true_value,
                      lower = interval[1],
                      upper = interval[2])
  
  
  
  # 1 = yes,
  # 0 = no
  return( 1 * lies_within)
  
}



# function for residuals and diagnostics!
compute_deviance_resid <- function(original_status, other_residual){
  
  devres <- sign(other_residual) * sqrt( -2 * (other_residual + original_status * log(original_status - other_residual ) ) )
  
  return(devres)
  
}



compute_relevant_residuals <- function(model, data_short, data_long, type, indices, equation_survmodel){
  
  if(type == "DT"){
    
    pred_haz <- 1 - exp( -exp( predict(model, equation_survmodel) ) )
    
    # cox snell residuals
    cxs_resids <- sapply(indices, function(i)  sum( pred_haz[i]  ) ) 
    
    cxs_resids_logoneminus <- sapply(indices, function(i)  sum( - log( 1 - pred_haz[i]) ) ) 
    
    # martingale
    mart_resids <- data_short$status - cxs_resids
    
    mart_resids_logoneminus <- data_short$status - cxs_resids_logoneminus
    
    # deviance residuals
    dv_resids <- compute_deviance_resid(data_short$status, mart_resids)
    
    dv_resids_logoneminus <- compute_deviance_resid(data_short$status, mart_resids_logoneminus)
    
    
    relevant_residuals <- data.frame(cox_snell_residuals = cxs_resids, 
                                     deviance_residuals = dv_resids,
                                     martingale_residuals = mart_resids,
                                     #
                                     #
                                     logoneminus_cox_snell = cxs_resids_logoneminus,
                                     logoneminus_deviance = dv_resids_logoneminus,
                                     logoneminus_martingale = mart_resids_logoneminus
    ) 
    
    # temporal object
    relevant_residuals_temp <- relevant_residuals
    
    relevant_residuals_temp$status <- data_short$status
    
    # Attach the Nelson Aalen estimator of the cox-snell logoneminus residuals
    relevant_residuals$NelsonAalen_coxsnell_logoneminus <- mice::nelsonaalen(relevant_residuals_temp, logoneminus_cox_snell, status)
    
  }
  
  
  if(type == "PW"){
    
    # hazard rate
    pred_haz <- exp( predict(model, equation_survmodel) )
    
    # cox snell residuals
    cxs_resids <- sapply(1:length(indices), function(i) sum(  pred_haz[ indices[[i]] ] * exp( data_long$offset[ indices[[i]] ] ) ) )
    
    
    # martingale residuals
    mart_resids <- data_short$status - cxs_resids
    
    # deviance residuals 
    dv_resids <- compute_deviance_resid(data_short$status, mart_resids)
    
    
    relevant_residuals <- data.frame(cox_snell_residuals = cxs_resids, 
                                     deviance_residuals = dv_resids,
                                     martingale_residuals = mart_resids) 
    
    # temporal object
    relevant_residuals_temp <- relevant_residuals
    
    relevant_residuals_temp$status <- data_short$status
    
  }
  
  
  # Attach the Nelson Aalen estimator of the cox-snell residuals
  relevant_residuals$NelsonAalen_coxsnell <- mice::nelsonaalen(relevant_residuals_temp, cox_snell_residuals, status)
  
  
  return(relevant_residuals)
  
}




# how to use:
# compute_relevant_residuals(model = res$value, data_short = original_data, data_long = dataset_long_margin2, type = "DT", indices = INDCS_list, equation_survmodel = 2)

library(pammtools)
library(Metrics)
library(matrixStats)
library(discSurv)

# hess_reg  can be either "t", "pC", or "sED".

# The fitting function:
fit_MXS <- function(original_data_object, 
                    copula_class = "N", 
                    # non-survival marginal response
                    NonSurv_Margin = "N",
                    # cuts / intervals
                    number_of_ints = 15, 
                    #
                    maximum_time_cut = 4.6,
                    #
                    varying_dependence = FALSE,
                    # smooth the baseline function of time on time scale or log(time) scale
                    baseline_smooth = "log",
                    # for confidence intervals
                    n.sim = 500,
                    # further arguments
                    hess_reg = "t"
                    ){
  
  original_data <- original_data_object$dataset
  
  # extra reg settings:
  extra.regularization <- hess_reg
    
    
    the_used_cuts <- seq(from = 0,  
                         to = maximum_time_cut, 
                         length.out = number_of_ints)
    
    
    # create intervals:
    # 0 is always included in this function, so remove it from the vector of the_used_cuts!
    dat_disc <-  contToDisc(dataShort = original_data, 
                             timeColumn = "time", 
                             intervalLimits = the_used_cuts[-1]
                            )
    
    
    # Adjustment for identification (see documentation of discSurv)
    dat_disc$timeDisc[dat_disc$timeDisc == max(dat_disc$timeDisc)] <- tail(sort(unique(dat_disc$timeDisc)), 2)[1]
    dat_disc$status[dat_disc$timeDisc == max(dat_disc$timeDisc)] <- 0
    
    
    # create long-format for survival margin (called internally margin 2 but enters the
    # fitting function and is treated there as margin 1)
    dataset_long_margin2 <- discSurv:::dataLong(dat_disc, 
                                                timeColumn = "timeDisc", 
                                                eventColumn = "status")
    
    # create list of indices for margin 2 
    INDCS_list <- sapply(levels(as.factor(dataset_long_margin2$obj)), 
                                    function(i) which(dataset_long_margin2$obj == i), 
                                    simplify = FALSE)
    
    
    # extract unique values of time intervals:
    the_unique_tends <- sort(unique(dat_disc$timeDisc))
    
    
    # attach ped_status in the model:
    # this is to trick GJRM into fitting!
    original_data$y_margin2 <- sample(dataset_long_margin2$y, size = nrow(original_data), replace = TRUE)
    original_data$timeInt_margin2 <- sample(dataset_long_margin2$y, size = nrow(original_data), replace = TRUE)
    
    # rename in long dataset to avoid any issues
    dataset_long_margin2$y_margin2 <- dataset_long_margin2$y
    dataset_long_margin2$timeInt_margin2 <- dataset_long_margin2$timeInt
    
    
    number_basis_k_surv <- 10
    
    order_penalty_m_surv <- 2
    
    
    ###########################################################################################################
    # DTS formula, i.e. smooth baseline hazard using splines
    DTS_formula <- as.formula( y_margin2 ~ s(timeInt_margin2, bs = "ps", k = number_basis_k_surv, m = order_penalty_m_surv) + 
                                 x2 + x4
    )
    
    
    # smooth time on the log() scale (for smoother results according to literature)
    DTS_log_formula <- as.formula(y_margin2 ~ s(log(as.numeric(timeInt_margin2)), bs = "ps", k = number_basis_k_surv,  m = order_penalty_m_surv) 
                                  + x2 + x4
    )
    
    
    # Formula for dependence parameter (necessary in some cases)
    if(varying_dependence){
      
    Copula_param_formula <- as.formula( ~ 1 + x5)
    
    }else{
      
      Copula_param_formula <- as.formula( ~ 1)
    }
    
    #### CONTINUOUS
    # Gaussian
    if(NonSurv_Margin == "N"){
      
        MXS_margins <- c("PO", "N")
        
        NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
        
        NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
        
        # Create final list of formulae for fitting
        if(baseline_smooth == "log"){
          
          MXS_formula <- list(DTS_log_formula,
                              NonSurv_Mar_formula, 
                              NonSurv_Mar_Param2_formula,
                              Copula_param_formula)
          
        }else{
          
          MXS_formula <- list(DTS_formula,
                              NonSurv_Mar_formula,
                              NonSurv_Mar_Param2_formula,
                              Copula_param_formula)
          
        }
    }
    
    # Log-normal
    if(NonSurv_Margin == "LN"){
      
      MXS_margins <- c("PO", "LN")
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(DTS_log_formula,
                            NonSurv_Mar_formula, 
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(DTS_formula,
                            NonSurv_Mar_formula,
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }
      
    }
    
    # Logistic
    if(NonSurv_Margin == "LO"){
      
      MXS_margins <- c("PO", "LO")
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(DTS_log_formula,
                            NonSurv_Mar_formula, 
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(DTS_formula,
                            NonSurv_Mar_formula,
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }
      
    }
    
    # Beta
    if(NonSurv_Margin == "BE"){
      
      MXS_margins <- c("PO", "BE")
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(DTS_log_formula,
                            NonSurv_Mar_formula, 
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(DTS_formula,
                            NonSurv_Mar_formula,
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }
      
    }
    
    # Log-logistic
    if(NonSurv_Margin == "FISK"){
      
      MXS_margins <- c("PO", "FISK")
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(DTS_log_formula,
                            NonSurv_Mar_formula, 
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(DTS_formula,
                            NonSurv_Mar_formula,
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }
      
    }
    
    # Dagum
    if(NonSurv_Margin == "DAGUM"){
      
      MXS_margins <- c("PO", "DAGUM")
      
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
      
      NonSurv_Mar_Param3_formula <- as.formula( ~ 1)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(DTS_log_formula,
                            NonSurv_Mar_formula, 
                            NonSurv_Mar_Param2_formula,
                            NonSurv_Mar_Param3_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(DTS_formula,
                            NonSurv_Mar_formula,
                            NonSurv_Mar_Param2_formula,
                            NonSurv_Mar_Param3_formula,
                            Copula_param_formula)
        
      }
      
    }
    
    
    #### DISCRETE 
    # Poisson
    if(NonSurv_Margin == "PO"){
      
      MXS_margins <- c("PO", "PO")
      
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(DTS_log_formula,
                            NonSurv_Mar_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(DTS_formula,
                            NonSurv_Mar_formula,
                            Copula_param_formula)
        
      }
    }
    
    # Negative binomial I 
    if(NonSurv_Margin == "NBI"){
     
      MXS_margins <- c("PO", "NBI")
      
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      NonSurv_Mar_Param2_formula <- as.formula( ~ x3)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(DTS_log_formula,
                            NonSurv_Mar_formula,
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(DTS_formula,
                            NonSurv_Mar_formula,
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }
      
    }
    
    # Negative binomial I 
    if(NonSurv_Margin == "NBII"){
      
      MXS_margins <- c("PO", "NBII")
      
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      NonSurv_Mar_Param2_formula <- as.formula( ~ x3)
      
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(DTS_log_formula,
                            NonSurv_Mar_formula,
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(DTS_formula,
                            NonSurv_Mar_formula,
                            NonSurv_Mar_Param2_formula,
                            Copula_param_formula)
        
      }
      
    }
    
    
    #### BINARY 
    # Logit
    if(NonSurv_Margin == "logit"){
      
      MXS_margins <- c("logit", "PO")
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(NonSurv_Mar_formula,
                            DTS_log_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(NonSurv_Mar_formula,
                            DTS_formula,
                            Copula_param_formula)
        
      }
    }
    
    # Probit
    if(NonSurv_Margin == "probit"){
      
      MXS_margins <- c("probit", "PO")
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(NonSurv_Mar_formula,
                            DTS_log_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(NonSurv_Mar_formula,
                            DTS_formula,
                            Copula_param_formula)
        
      }
      
    }
    
    # Clog log 
    if(NonSurv_Margin == "cloglog"){
      
      MXS_margins <- c("cloglog", "PO")
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(NonSurv_Mar_formula,
                            DTS_log_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(NonSurv_Mar_formula,
                            DTS_formula,
                            Copula_param_formula)
        
      }
    }
    
    # GEV link
    if(NonSurv_Margin == "GEVlink"){
      
      MXS_margins <- c("GEVlink", "PO")
      
      NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
      
      # Create final list of formulae for fitting
      if(baseline_smooth == "log"){
        
        MXS_formula <- list(NonSurv_Mar_formula,
                            DTS_log_formula,
                            Copula_param_formula)
        
      }else{
        
        MXS_formula <- list(NonSurv_Mar_formula,
                            DTS_formula,
                            Copula_param_formula)
        
      }
    }
    
    
    
    # FIT:
    # 
    model_runtime <- system.time(
      res <- myTryCatch(
        gjrm(
          MXS_formula, 
          data = original_data, 
          BivD = copula_class,      
          # This is either DTS or PWE margin
          margins = MXS_margins, # Combination of margins
          Model = "B",
          # List of subject ids
          ListOfIDs = INDCS_list,
          #   dataset (long)
          PAMM_dataset = dataset_long_margin2,
          # further arguments
          gc.l = FALSE,
          extra.regI = extra.regularization)
      )
    )
    
    
    
    # Check if the model was actually fitted and there is an output!
    if(!is.null(res$value)){
      
      
      # If there are no coefficients in the dependence parameter: 
      
      if( !(varying_dependence) ){
      # In this case we only care about the copula parameter / kendall's tau:
      # Can be modified tho
      if(NonSurv_Margin == "N"){
        
        # Evaluate the fitted model:
        # --- > overall coefficients
        # --- > all prediction points of the spline in 100, equidistant points!
        
        model_coefficients <- coef(res$value)
        
        
        kendall_binary_PWE <- res$value$tau
        
        # Copula / dependence part 
        # --- > intercept of model of copula parameter
        # --- > copula parameter (in copula parameter scale)
        # --- > kendall´s tau (pred.mvt) with confidence interval
        copula_parameter_intercept <- tail(coef(res$value),1)
        copula_parameter <- res$value$theta
        
        # Check fitted bivariate distribution in the MBS model to 
        # compute the correct Kendall's tau:
        #GAUSS copula
        if(res$value$BivD == "N"){
          
          tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
          
        }
        
        # GUMBEL copula
        if(res$value$BivD == "G0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED GUMBEL copula (90)
        if(res$value$BivD == "G90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          
          tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
          
        }
        
        # CLAYTON copula
        if(res$value$BivD == "C0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED CLAYTON copula (90)
        if(res$value$BivD == "C90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- - theta_coppar
          
          tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
          
        }
        
        # FRANK copula
        if(copula_class == "F"){
          
          
          signs <- sign(copula_parameter) 
          theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
          theta_coppar <- theta_coppar*signs 
          
          
          tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
          
        }
        
        # JOE copula
        if(res$value$BivD == "J0"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # ROTATED JOE (90)
        if(res$value$BivD == "J90"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
        #        Object Vb 
        #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
        #        function of the mvt normal distr. is used to sample from them!
        #        Obtain the following coverages: 90% ,     95%,        99%
        #                                       (1-0.05),  (1-0.025)   (1-0.005)
        
        # Confidence intervals of all coefficients will be obtained via simulations
        # For transformations of the linear predictor (i.e. survival function, etc): 
        # simulation as well as direct transformation of the linear predictor
        
        # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
        # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
        # Compute quantiles from this sample of size R.  
        # Set the number of simulations from the posterior to: 500, default = 200.
        
        # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
        # Extract coeffs again
        coefficient_vec <- coef(res$value)
        
        # Extract coeffs
        coeff_cov_mat <- res$value$Vb
        
        n.sim <- 200
        
        # Samples from the asymptotic distribution of of the coefficient vector
        bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
        
        
        # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
        # using the typical levels
        prob_levels <- c(0.01, 0.05, 0.1)
        
        confints_list <- sapply(prob_levels, 
                                function(i) matrixStats:::colQuantiles(bs, 
                                                                       probs = c(i/2, 
                                                                                 1 - i/2),
                                                                       na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        
        # Compute xbeta for copula parameter:
        fitCopParSim <- bs[,length(coefficient_vec)]
        
        
        
        
        # Compute confidence intervals for the copula parameter:
        # GAUSS COPULA
        if(res$value$BivD == "N"){
          
          # just a vector of values, since the model is currently has only an intercept:
          fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                  sign(fitCopParSim)*8.75, 
                                  fitCopParSim)
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- tanh(fitCopParSim) 
          
          # computation of TAU:
          fitTauSim <-  2 / pi * asin(fitCopParSim) 
          # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
          
        }
        
        
        # CLAYTON COPULA
        if(res$value$BivD == "C0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
          
        }
        
        
        # ROTATED CLAYTON COPULA (90)
        if(res$value$BivD == "C90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <-  -( exp( fitCopParSim ) )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
          
          
          
        }
        
        
        # GUMBEL COPULA 
        if(res$value$BivD == "G0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim ) + 1   
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <-  1 - 1 / fitTauSim 
          
        }
        
        
        # ROTATED GUMBEL COPULA (90)
        if(res$value$BivD == "G90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- -( exp( fitCopParSim ) + 1  )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
          
        }
        
        
        # JOE COPULA
        if(res$value$BivD == "J0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp(fitCopParSim) + 1
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          
          fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
          
          
        }
        
        
        # ROTATED JOE COPULA (90)
        if(res$value$BivD == "J90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- - ( exp(fitCopParSim) + 1 )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- - fitTauSim
          
          fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
          
          
        }
        
        
        # FRANK COPULA
        if(res$value$BivD == "F"){
          
          epsilon <- c(sqrt(.Machine$double.eps))
          
          fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                  epsilon, 
                                  fitCopParSim )     
          
          
          signs <- sign(fitCopParSim) 
          
          fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                 35, 
                                 abs(fitCopParSim)) # 
          
          fitCopParSim <- fitCopParSim*signs
          
          fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
          
          
        }
        
        
        
        
        
        confints_copulaparam <-  sapply(prob_levels,
                                        function(i)
                                          quantile(fitCopParSim,
                                                   probs = c(i/2, 1 - i/2),
                                                   na.rm = TRUE),
                                        simplify = FALSE)
        
        
        # intervals for KENDALLs TAU:
        confints_tau <-  sapply(prob_levels,
                                function(i)
                                  quantile(fitTauSim,
                                           probs = c(i/2, 1 - i/2),
                                           na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # Compute the coverages:
        coverage_copula_param <- sapply(confints_copulaparam, function(i) 
          
          lies_in_interval(original_data_object$true_copula_param, i)
          
        )
        
        coverage_tau <- sapply(confints_tau, function(i) 
          
          lies_in_interval(original_data_object$original_tau, i)
          
        )
        
        
        
        
        names(coverage_tau) <- c("99%", "95%", "90%")
        names(coverage_copula_param) <- c("99%", "95%", "90%")
        
        
        
        
        
        
        coverages_materials <-list(tau = coverage_tau,
                                   copula_parameter = coverage_copula_param,
                                   beta_nonsurv_margin = NULL,
                                   beta_surv_margin = NULL)
        
        
        output <- list(model_coefficients = model_coefficients,
                       confints = coverages_materials,
                       estimated_copula_parameter = res$value$theta,
                       estimated_kendall_tau = res$value$tau,
                       nrow_datalong = dim(dataset_long_margin2))
        
        
        
      }
      
      # This is the output in case of binary non-survival margins
      if( NonSurv_Margin %in% c("logit", "probit", "cloglog", "GEVlink") ){
        
        # Evaluate the fitted model:
        # --- > overall coefficients
        coefficients_nonsurv_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ]
        
        coefficients_survival_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
        
        coefficients_copula_parameter <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[3]):(length(coef(res$value)))]
        
        
        
        # Survival / margin
        

        # 1: Create  sequence of time points for the splines
        # 2: Use predict(, type = "terms")
        # 3: Extract the prediction of only the log( baseline hazard )
        # 4: Add the intercept to all observations
        # 5: Transform into hazard rate, 
        # 6: Obtain original interval lengths (all equidistant)  
        # 7: Obtain the cumu hazard, 
        # 8: Transform into survival function.
        # Step 1: 
        time_synth <- 0:number_of_ints
        time_synth2 <- 0:number_of_ints
        
        dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
        
        dat_ped_new$timeInt <- time_synth
        dat_ped_new$timeInt_margin2 <- time_synth
        
        dat_ped_ready <- dat_ped_new %>% 
          mutate(x1 = 0,
                 x2 = 0,
                 x3 = 0,
                 x5 = 0,
                 x4 = 0)
        
        # Step 2 + 3 + 4:
        # Intercept is added
        baseline_link_scale <-  predict(res$value,
                                     eq = 2,
                                     newdata = dat_ped_ready,
                                     type = "terms")[,3] +
          coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]

        # Step 5:
        baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )

        # Step 6: not needed in DTS

        # Step 7:
        cumuhazard_justcumsum <- cumsum( baseline_hazard  )

        cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
        
        # Step 8:
        survivalfunction <- cumprod( 1 - baseline_hazard )
        # 
        # 
        ###########################
        ###########################
        
        estimated_kendall_tau <- res$value$tau
        
        # Copula / dependence part 
        # --- > intercept of model of copula parameter
        # --- > copula parameter (in copula parameter scale)
        # --- > kendall´s tau (pred.mvt) with confidence interval
        copula_parameter_intercept <- tail(coef(res$value),1)
        
        copula_parameter <- res$value$theta
        
        # Check fitted bivariate distribution in the MBS model to 
        # compute the correct Kendall's tau:
        #GAUSS copula
        if(res$value$BivD == "N"){
          
          tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
          
        }
        
        # GUMBEL copula
        if(res$value$BivD == "G0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED GUMBEL copula (90)
        if(res$value$BivD == "G90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          
          tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
          
        }
        
        # CLAYTON copula
        if(res$value$BivD == "C0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED CLAYTON copula (90)
        if(res$value$BivD == "C90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- - theta_coppar
          
          tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
          
        }
        
        # FRANK copula
        if(copula_class == "F"){
          
          
          signs <- sign(copula_parameter) 
          theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
          theta_coppar <- theta_coppar*signs 
          
          
          tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
          
        }
        
        # JOE copula
        if(res$value$BivD == "J0"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # ROTATED JOE (90)
        if(res$value$BivD == "J90"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
        #        Object Vb 
        #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
        #        function of the mvt normal distr. is used to sample from them!
        #        Obtain the following coverages: 90% ,     95%,        99%
        #                                       (1-0.05),  (1-0.025)   (1-0.005)
        
        # Confidence intervals of all coefficients will be obtained via simulations
        # For transformations of the linear predictor (i.e. survival function, etc): 
        # simulation as well as direct transformation of the linear predictor
        
        # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
        # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
        # Compute quantiles from this sample of size R.  
        # Set the number of simulations from the posterior to: 500, default = 200.
        
        # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
        # Extract coeffs again
        coefficient_vec <- coef(res$value)
        
        # Extract coeffs
        coeff_cov_mat <- res$value$Vb
        
        n.sim <- n.sim
        
        # Samples from the asymptotic distribution of of the coefficient vector
        bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
        
        
        # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
        # using the typical levels
        prob_levels <- c(0.01, 0.05, 0.1)
        
        confints_list <- sapply(prob_levels, 
                                function(i) matrixStats:::colQuantiles(bs, 
                                                                       probs = c(i/2, 
                                                                                 1 - i/2),
                                                                       na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # For the specific splines:
        # Recover the synthetic values of the covariates:
        # remove other covariates values from the linear predictor: 
        dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
        
        # Obtain various additive predictors: 
        Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)

        Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
        
        # Compute xbeta for first margin: binary
        fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])

        # # Compute xbeta for second margin: PWE
        fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] )
        
        # Compute xbeta for copula parameter:
        fitCopParSim <- bs[,length(coefficient_vec)]
        
        
        
        # # Survival margin:
        confints_linkscalehazard <- sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2Sim,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)



        confints_hazard <- sapply(prob_levels,
                                  function(i)
                                    matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ),
                                                               probs = c(i/2, 1 - i/2),
                                                               na.rm = TRUE),
                                  simplify = FALSE)


        # # Compute the cumulative sum correctly:
        fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                 function(i)
                                   cumsum( (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                                 simplify = TRUE)
        
        
        fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                 function(i)
                                   -cumsum( log(1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ) ),
                                 simplify = TRUE)
        
        
        fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                           function(i)
                                             cumprod( 1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                                           simplify = TRUE)

        # # Compute quantiles
        confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                       function(i)
                                         matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                    probs = c(i/2, 1 - i/2),
                                                                    na.rm = TRUE),
                                       simplify = FALSE)

        confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                              function(i)
                                                matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                           probs = c(i/2, 1 - i/2),
                                                                           na.rm = TRUE),
                                              simplify = FALSE)
        
        confints_survival <-  sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)

        
        
        # Compute confidence intervals for the copula parameter:
        # GAUSS COPULA
        if(res$value$BivD == "N"){
          
          # just a vector of values, since the model is currently has only an intercept:
          fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                  sign(fitCopParSim)*8.75, 
                                  fitCopParSim)
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- tanh(fitCopParSim) 
          
          # computation of TAU:
          fitTauSim <-  2 / pi * asin(fitCopParSim) 
          # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
          
        }
        
        
        # CLAYTON COPULA
        if(res$value$BivD == "C0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
          
        }
        
        
        # ROTATED CLAYTON COPULA (90)
        if(res$value$BivD == "C90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <-  -( exp( fitCopParSim ) )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
          
          
          
        }
        
        
        # GUMBEL COPULA 
        if(res$value$BivD == "G0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim ) + 1   
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <-  1 - 1 / fitTauSim 
          
        }
        
        
        # ROTATED GUMBEL COPULA (90)
        if(res$value$BivD == "G90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- -( exp( fitCopParSim ) + 1  )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
          
        }
        
        
        # JOE COPULA
        if(res$value$BivD == "J0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp(fitCopParSim) + 1
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          
          fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
          
          
        }
        
        
        # ROTATED JOE COPULA (90)
        if(res$value$BivD == "J90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- - ( exp(fitCopParSim) + 1 )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- - fitTauSim
          
          fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
          
          
        }
        
        
        # FRANK COPULA
        if(res$value$BivD == "F"){
          
          epsilon <- c(sqrt(.Machine$double.eps))
          
          fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                  epsilon, 
                                  fitCopParSim )     
          
          
          signs <- sign(fitCopParSim) 
          
          fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                 35, 
                                 abs(fitCopParSim)) # 
          
          fitCopParSim <- fitCopParSim*signs
          
          fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
          
          
        }
        
        
        
        
        
        confints_copulaparam <-  sapply(prob_levels,
                                        function(i)
                                          quantile(fitCopParSim,
                                                   probs = c(i/2, 1 - i/2),
                                                   na.rm = TRUE),
                                        simplify = FALSE)
        
        
        # intervals for KENDALLs TAU:
        confints_tau <-  sapply(prob_levels,
                                function(i)
                                  quantile(fitTauSim,
                                           probs = c(i/2, 1 - i/2),
                                           na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # Compute the coverages:
        coverage_copula_param <- sapply(confints_copulaparam, function(i) 
          
          lies_in_interval(original_data_object$true_copula_param, i)
          
        )
        
        coverage_tau <- sapply(confints_tau, function(i) 
          
          lies_in_interval(original_data_object$original_tau, i)
          
        )
        
        
        # extract coefficients of nonsurvival margin
        beta_nonsurv_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
        
        surv_beta_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
        
        
        # This returns a list with the 99% confidence intervals
        surv_marg_confints1 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        surv_marg_confints2 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        surv_marg_confints3 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        
        # Now for the nonsurvival margin:
        
        nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # Compute coverages:
        coverage1_surv_margin <- sapply(surv_marg_confints1, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        coverage2_surv_margin <- sapply(surv_marg_confints2, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        coverage3_surv_margin <- sapply(surv_marg_confints3, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        
        ########### now for the nonsurvival margin:
        coverage1_nonsurv_margin <- sapply(nonsurv_marg_confints1, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          
        )
        
        coverage2_nonsurv_margin <- sapply(nonsurv_marg_confints2, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          
        )
        
        coverage3_nonsurv_margin <- sapply(nonsurv_marg_confints3, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          
        )
        
        
        
        names(coverage_tau) <- c("99%", "95%", "90%")
        names(coverage_copula_param) <- c("99%", "95%", "90%")
        
        
        
        
        confint_materials <- list(all_coefficients  = confints_list,
                                  #binary_spline = confints_binary_spline,
                                  linkscale_hazard = confints_linkscalehazard,
                                  hazard = confints_hazard,
                                  cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                  cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                  survival = confints_survival,
                                  copula_param = confints_copulaparam,
                                  kendall_tau = confints_tau, 
                                  #
                                  coverage_beta_nonsurv_margin = list(coverage1_nonsurv_margin,
                                                             coverage2_nonsurv_margin,
                                                             coverage3_nonsurv_margin),
                                  #
                                  coverage_beta_survival_margin = list(coverage1_surv_margin,
                                                              coverage2_surv_margin,
                                                              coverage3_surv_margin),
                                  coverage_tau = coverage_tau,
                                  coverage_copula_parameter = coverage_copula_param
                                  )
        
        
        
        # Put everything together
        output <- list(
          # Coefficients
          coefficients_nonsurv = coefficients_nonsurv_margin,
          coefficients_survival = coefficients_survival_margin,
          copula_parameter_intercept = copula_parameter_intercept,
          #
          # Smooth functions
          linkscale_baseline = baseline_link_scale,
          baseline = baseline_hazard,
          cumu_hazard = cumuhazard_justcumsum,
          cumu_hazard_logoneminus = cumuhazard_logoneminus,
          survival = survivalfunction,
          #
          # copula parameter and dependence
          copula_parameter = copula_parameter,
          tau_of_kendall = tau_of_kendall,
          #
          # Big matrix of coefficient's confidence intervals:
          confint_materials = confint_materials,
          #
          # Various summaries
          survival_data_n = nrow(dataset_long_margin2),
          original_data_n = nrow(original_data),
          edf_nonsurvival_margin = res$value$edf[[1]],
          edf_survival_margin = res$value$edf[[2]],
          #
          #
          #
          # Stuff regarding estimated kendall taus between some quantities 
          estimated_kendall = res$value$tau,
          copula_parameter_estimate = res$value$theta,
          # some other diagnostics
          cuts_placement_intime = the_used_cuts,
          the_unique_tends = the_unique_tends,
          the_warning = res$warning,
          the_error = res$error,
          model_runtime = model_runtime
        )

        
        
        
        
    
      
      }
      
      # This is the output in case of discrete non-survival margins
      if(  NonSurv_Margin == "PO" ){
        
        # Evaluate the fitted model:
        # --- > overall coefficients
        coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)]
        
        coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
        
        coefficients_copula_parameter <- coef(res$value)[length(coef(res$value))]
        
        
        
        # Survival / margin
        # --- > 
        
        # 1: Create rich sequence of time points for the splines
        # 2: Use predict(, type = "terms")
        # 3: Extract the prediction of only the log( baseline hazard )
        # 4: Add the intercept to all observations
        # 5: Transform into hazard rate, 
        # 6: Obtain original interval lengths (all equidistant)  
        # 7: Obtain the cumu hazard, 
        # 8: Transform into survival function.
        # Step 1: 
        time_synth <- 0:number_of_ints
        time_synth2 <- 0:number_of_ints
        
        dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
        
        dat_ped_new$timeInt <- time_synth
        dat_ped_new$timeInt_margin2 <- time_synth
        
        dat_ped_ready <- dat_ped_new %>% 
          mutate(x1 = 0,
                 x2 = 0,
                 x3 = 0,
                 x5 = 0,
                 x4 = 0)
        
        # Step 2 + 3 + 4:
        # Intercept is added
        baseline_link_scale <-  predict(res$value,
                                        eq = 1,
                                        newdata = dat_ped_ready,
                                        type = "terms")[,3] +
          coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
        
        # Step 5:
        baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
        
        # Step 6: not needed in DTS
        
        # Step 7:
        cumuhazard_justcumsum <- cumsum( baseline_hazard  )
        
        cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
        
        # Step 8:
        survivalfunction <- cumprod( 1 - baseline_hazard )
        # 
        # 
        ###########################
        ###########################
        
        estimated_kendall_tau <- res$value$tau
        
        # Copula / dependence part 
        # --- > intercept of model of copula parameter
        # --- > copula parameter (in copula parameter scale)
        # --- > kendall´s tau (pred.mvt) with confidence interval
        copula_parameter_intercept <- tail(coef(res$value),1)
        
        copula_parameter <- res$value$theta
        
        # Check fitted bivariate distribution in the MBS model to 
        # compute the correct Kendall's tau:
        #GAUSS copula
        if(res$value$BivD == "N"){
          
          tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
          
        }
        
        # GUMBEL copula
        if(res$value$BivD == "G0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED GUMBEL copula (90)
        if(res$value$BivD == "G90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          
          tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
          
        }
        
        # CLAYTON copula
        if(res$value$BivD == "C0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED CLAYTON copula (90)
        if(res$value$BivD == "C90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- - theta_coppar
          
          tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
          
        }
        
        # FRANK copula
        if(copula_class == "F"){
          
          
          signs <- sign(copula_parameter) 
          theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
          theta_coppar <- theta_coppar*signs 
          
          
          tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
          
        }
        
        # JOE copula
        if(res$value$BivD == "J0"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # ROTATED JOE (90)
        if(res$value$BivD == "J90"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
        #        Object Vb 
        #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
        #        function of the mvt normal distr. is used to sample from them!
        #        Obtain the following coverages: 90% ,     95%,        99%
        #                                       (1-0.05),  (1-0.025)   (1-0.005)
        
        # Confidence intervals of all coefficients will be obtained via simulations
        # For transformations of the linear predictor (i.e. survival function, etc): 
        # simulation as well as direct transformation of the linear predictor
        
        # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
        # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
        # Compute quantiles from this sample of size R.  
        # Set the number of simulations from the posterior to: 500, default = 200.
        
        # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
        # Extract coeffs again
        coefficient_vec <- coef(res$value)
        
        # Extract coeffs
        coeff_cov_mat <- res$value$Vb
        
        n.sim <- n.sim
        
        # Samples from the asymptotic distribution of of the coefficient vector
        bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
        
        
        # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
        # using the typical levels
        prob_levels <- c(0.01, 0.05, 0.1)
        
        confints_list <- sapply(prob_levels, 
                                function(i) matrixStats:::colQuantiles(bs, 
                                                                       probs = c(i/2, 
                                                                                 1 - i/2),
                                                                       na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # For the specific splines:
        # Recover the synthetic values of the covariates:
        # remove other covariates values from the linear predictor: 
        dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
        
        # Obtain various additive predictors: 
        Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
        
        Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
        
        # Compute xbeta for first margin: 
        fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
        
        # # Compute xbeta for second margin: 
        fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] )
        
        # Compute xbeta for copula parameter:
        fitCopParSim <- bs[,length(coefficient_vec)]
        
        # Compute now transformation of this: 
        # Binary margin: just the spline: 
        # confints_binary_spline <-sapply(prob_levels,
        #                                 function(i)
        #                                   matrixStats:::rowQuantiles(fit1Sim,
        #                                                              probs = c(i/2, 1 - i/2),
        #                                                              na.rm = TRUE),
        #                                 simplify = FALSE)
        
        # # Survival margin:
        confints_linkscalehazard <- sapply(prob_levels,
                                           function(i)
                                             matrixStats:::rowQuantiles(fit1Sim,
                                                                        probs = c(i/2, 1 - i/2),
                                                                        na.rm = TRUE),
                                           simplify = FALSE)
        
        
        
        confints_hazard <- sapply(prob_levels,
                                  function(i)
                                    matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                               probs = c(i/2, 1 - i/2),
                                                               na.rm = TRUE),
                                  simplify = FALSE)
        
        
        # # Compute the cumulative sum correctly:
        fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                 function(i)
                                   cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                 simplify = TRUE)
        
        
        fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                           function(i)
                                             -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                           simplify = TRUE)
        
        
        fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                  function(i)
                                    cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                  simplify = TRUE)
        
        # # Compute quantiles
        confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                              function(i)
                                                matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                           probs = c(i/2, 1 - i/2),
                                                                           na.rm = TRUE),
                                              simplify = FALSE)
        
        confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                   function(i)
                                                     matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                                probs = c(i/2, 1 - i/2),
                                                                                na.rm = TRUE),
                                                   simplify = FALSE)
        
        confints_survival <-  sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
        
        
        
        # Compute confidence intervals for the copula parameter:
        # GAUSS COPULA
        if(res$value$BivD == "N"){
          
          # just a vector of values, since the model is currently has only an intercept:
          fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                  sign(fitCopParSim)*8.75, 
                                  fitCopParSim)
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- tanh(fitCopParSim) 
          
          # computation of TAU:
          fitTauSim <-  2 / pi * asin(fitCopParSim) 
          # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
          
        }
        
        
        # CLAYTON COPULA
        if(res$value$BivD == "C0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
          
        }
        
        
        # ROTATED CLAYTON COPULA (90)
        if(res$value$BivD == "C90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <-  -( exp( fitCopParSim ) )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
          
          
          
        }
        
        
        # GUMBEL COPULA 
        if(res$value$BivD == "G0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim ) + 1   
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <-  1 - 1 / fitTauSim 
          
        }
        
        
        # ROTATED GUMBEL COPULA (90)
        if(res$value$BivD == "G90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- -( exp( fitCopParSim ) + 1  )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
          
        }
        
        
        # JOE COPULA
        if(res$value$BivD == "J0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp(fitCopParSim) + 1
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          
          fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
          
          
        }
        
        
        # ROTATED JOE COPULA (90)
        if(res$value$BivD == "J90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- - ( exp(fitCopParSim) + 1 )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- - fitTauSim
          
          fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
          
          
        }
        
        
        # FRANK COPULA
        if(res$value$BivD == "F"){
          
          epsilon <- c(sqrt(.Machine$double.eps))
          
          fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                  epsilon, 
                                  fitCopParSim )     
          
          
          signs <- sign(fitCopParSim) 
          
          fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                 35, 
                                 abs(fitCopParSim)) # 
          
          fitCopParSim <- fitCopParSim*signs
          
          fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
          
          
        }
        
        
        
        
        
        confints_copulaparam <-  sapply(prob_levels,
                                        function(i)
                                          quantile(fitCopParSim,
                                                   probs = c(i/2, 1 - i/2),
                                                   na.rm = TRUE),
                                        simplify = FALSE)
        
        
        # intervals for KENDALLs TAU:
        confints_tau <-  sapply(prob_levels,
                                function(i)
                                  quantile(fitTauSim,
                                           probs = c(i/2, 1 - i/2),
                                           na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # Compute the coverages:
        coverage_copula_param <- sapply(confints_copulaparam, function(i) 
          
          lies_in_interval(original_data_object$true_copula_param, i)
          
        )
        
        coverage_tau <- sapply(confints_tau, function(i) 
          
          lies_in_interval(original_data_object$original_tau, i)
          
        )
        
        
        # extract coefficients of nonsurvival margin
        beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
        
        surv_beta_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
        
        
        # This returns a list with the 99% confidence intervals
        surv_marg_confints1 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        surv_marg_confints2 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        surv_marg_confints3 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        
        # Now for the nonsurvival margin:
        
        nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # Compute coverages:
        coverage1_surv_margin <- sapply(surv_marg_confints1, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        coverage2_surv_margin <- sapply(surv_marg_confints2, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        coverage3_surv_margin <- sapply(surv_marg_confints3, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        
        ########### now for the nonsurvival margin:
        coverage1_nonsurv_margin <- sapply(nonsurv_marg_confints1, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          
        )
        
        coverage2_nonsurv_margin <- sapply(nonsurv_marg_confints2, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          
        )
        
        coverage3_nonsurv_margin <- sapply(nonsurv_marg_confints3, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          
        )
        
        
        
        names(coverage_tau) <- c("99%", "95%", "90%")
        names(coverage_copula_param) <- c("99%", "95%", "90%")
        
        
        
        
        confint_materials <- list(all_coefficients  = confints_list,
                                  linkscale_hazard = confints_linkscalehazard,
                                  hazard = confints_hazard,
                                  cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                  cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                  survival = confints_survival,
                                  copula_param = confints_copulaparam,
                                  kendall_tau = confints_tau, 
                                  #
                                  coverage_beta_nonsurv_margin = list(coverage1_nonsurv_margin,
                                                                      coverage2_nonsurv_margin,
                                                                      coverage3_nonsurv_margin),
                                  #
                                  coverage_beta_survival_margin = list(coverage1_surv_margin,
                                                                       coverage2_surv_margin,
                                                                       coverage3_surv_margin),
                                  coverage_tau = coverage_tau,
                                  coverage_copula_parameter = coverage_copula_param
        )
        
        
        # Put everything together
        output <- list(
          # Coefficients
          coefficients_nonsurv = coefficients_nonsurv_margin,
          coefficients_survival = coefficients_survival_margin,
          copula_parameter_intercept = copula_parameter_intercept,
          #
          # Smooth functions
          linkscale_baseline = baseline_link_scale,
          baseline = baseline_hazard,
          cumu_hazard = cumuhazard_justcumsum,
          cumu_hazard_logoneminus = cumuhazard_logoneminus,
          survival = survivalfunction,
          #
          # copula parameter and dependence
          copula_parameter = copula_parameter,
          tau_of_kendall = tau_of_kendall,
          #
          # Big matrix of coefficient's confidence intervals:
          confint_materials = confint_materials,
          #
          # Various summaries
          survival_data_n = nrow(dataset_long_margin2),
          original_data_n = nrow(original_data),
          edf_nonsurvival_margin = res$value$edf[[2]],
          edf_survival_margin = res$value$edf[[1]],
          #
          #
          #
          # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
          estimated_kendall = res$value$tau,
          copula_parameter_estimate = res$value$theta,
          # some other diagnostics
          cuts_placement_intime = the_used_cuts,
          the_unique_tends = the_unique_tends,
          the_warning = res$warning,
          the_error = res$error,
          model_runtime = model_runtime
        )
        
        
        
       
        
        
        
      }
      
      if( NonSurv_Margin %in% c("NBI", "NBII") ){
        
        # Evaluate the fitted model:
        
        model_coefficients <- coef(res$value)
        
        # Edges of covariate space are not considered here!
        x_synth <- seq(-0.999, +0.999, length.out = 200)
        
        # insert this synthetic covariate in the original dataset (used for binary margin)
        dat_new <- original_data[1:length(x_synth), ]
        
        # x3 is the covariate used for the spline
        dat_new$x3 <- x_synth
        
        
        
        
        # Survival / margin
        
        # CODE FOR EXTRACTING THINGS FROM SURV MARGIN:
        
        
        ###########################
        ###########################
        
        # 1: Create rich sequence of time points for the splines
        # 2: Use predict(, type = "terms")
        # 3: Extract the prediction of only the log( baseline hazard )
        # 4: Add the intercept to all observations
        # 5: Transform into hazard rate, 
        # 6: Obtain original interval lengths (all equidistant)  
        # 7: Obtain the cumu hazard, 
        # 8: Transform into survival function.
        # Step 1: 
        time_synth <- seq(0, 19.5, length.out = 100)
        time_synth2 <- seq(0, 11, length.out = 100)
        
        dat_ped_new <- dataset_long_margin2[1:100, ]
        
        dat_ped_new$timeInt <- time_synth
        dat_ped_new$timeInt_margin2 <- time_synth
        
        dat_ped_ready <- dat_ped_new %>% 
          mutate(x1 = 0,
                 x2 = 0,
                 x3 = 0,
                 x5 = 0,
                 x4 = 0)
        
        
        ###########################
        ###########################
        
        kendall_binary_PWE <- res$value$tau
        
        # Copula / dependence part 
        # --- > intercept of model of copula parameter
        # --- > copula parameter (in copula parameter scale)
        # --- > kendall´s tau (pred.mvt) with confidence interval
        copula_parameter_intercept <- tail(coef(res$value),1)
        copula_parameter <- res$value$theta
        
        # Check fitted bivariate distribution in the MBS model to 
        # compute the correct Kendall's tau:
        #GAUSS copula
        if(res$value$BivD == "N"){
          
          tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
          
        }
        
        # GUMBEL copula
        if(res$value$BivD == "G0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED GUMBEL copula (90)
        if(res$value$BivD == "G90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          
          tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
          
        }
        
        # CLAYTON copula
        if(res$value$BivD == "C0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED CLAYTON copula (90)
        if(res$value$BivD == "C90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- - theta_coppar
          
          tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
          
        }
        
        # FRANK copula
        if(copula_class == "F"){
          
          
          signs <- sign(copula_parameter) 
          theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
          theta_coppar <- theta_coppar*signs 
          
          
          tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
          
        }
        
        # JOE copula
        if(res$value$BivD == "J0"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # ROTATED JOE (90)
        if(res$value$BivD == "J90"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
        #        Object Vb 
        #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
        #        function of the mvt normal distr. is used to sample from them!
        #        Obtain the following coverages: 90% ,     95%,        99%
        #                                       (1-0.05),  (1-0.025)   (1-0.005)
        
        # Confidence intervals of all coefficients will be obtained via simulations
        # For transformations of the linear predictor (i.e. survival function, etc): 
        # simulation as well as direct transformation of the linear predictor
        
        # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
        # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
        # Compute quantiles from this sample of size R.  
        # Set the number of simulations from the posterior to: 500, default = 200.
        
        # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
        # Extract coeffs again
        coefficient_vec <- coef(res$value)
        
        # Extract coeffs
        coeff_cov_mat <- res$value$Vb
        
        n.sim <- 200
        
        # Samples from the asymptotic distribution of of the coefficient vector
        bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
        
        
        # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
        # using the typical levels
        prob_levels <- c(0.01, 0.05, 0.1)
        
        confints_list <- sapply(prob_levels, 
                                function(i) matrixStats:::colQuantiles(bs, 
                                                                       probs = c(i/2, 
                                                                                 1 - i/2),
                                                                       na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # For the specific splines:
        # Recover the synthetic values of the covariates:
        # remove other covariates values from the linear predictor: 
        dat_new <- dat_new %>% mutate(x1 = 0, 
                                      x2 = 0)
        
        # Obtain various additive predictors: 
        
        # Compute xbeta for copula parameter:
        fitCopParSim <- bs[,length(coefficient_vec)]
        
        
        
        
        # Compute confidence intervals for the copula parameter:
        # GAUSS COPULA
        if(res$value$BivD == "N"){
          
          # just a vector of values, since the model is currently has only an intercept:
          fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                  sign(fitCopParSim)*8.75, 
                                  fitCopParSim)
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- tanh(fitCopParSim) 
          
          # computation of TAU:
          fitTauSim <-  2 / pi * asin(fitCopParSim) 
          # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
          
        }
        
        
        # CLAYTON COPULA
        if(res$value$BivD == "C0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
          
        }
        
        
        # ROTATED CLAYTON COPULA (90)
        if(res$value$BivD == "C90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <-  -( exp( fitCopParSim ) )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
          
          
          
        }
        
        
        # GUMBEL COPULA 
        if(res$value$BivD == "G0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim ) + 1   
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <-  1 - 1 / fitTauSim 
          
        }
        
        
        # ROTATED GUMBEL COPULA (90)
        if(res$value$BivD == "G90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- -( exp( fitCopParSim ) + 1  )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
          
        }
        
        
        # JOE COPULA
        if(res$value$BivD == "J0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp(fitCopParSim) + 1
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          
          fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
          
          
        }
        
        
        # ROTATED JOE COPULA (90)
        if(res$value$BivD == "J90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- - ( exp(fitCopParSim) + 1 )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- - fitTauSim
          
          fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
          
          
        }
        
        
        # FRANK COPULA
        if(res$value$BivD == "F"){
          
          epsilon <- c(sqrt(.Machine$double.eps))
          
          fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                  epsilon, 
                                  fitCopParSim )     
          
          
          signs <- sign(fitCopParSim) 
          
          fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                 35, 
                                 abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
          
          fitCopParSim <- fitCopParSim*signs
          
          fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
          
          
        }
        
        
        
        
        
        confints_copulaparam <-  sapply(prob_levels,
                                        function(i)
                                          quantile(fitCopParSim,
                                                   probs = c(i/2, 1 - i/2),
                                                   na.rm = TRUE),
                                        simplify = FALSE)
        
        
        # intervals for KENDALLs TAU:
        confints_tau <-  sapply(prob_levels,
                                function(i)
                                  quantile(fitTauSim,
                                           probs = c(i/2, 1 - i/2),
                                           na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # Compute the coverages:
        coverage_copula_param <- sapply(confints_copulaparam, function(i) 
          
          lies_in_interval(original_data_object$true_copula_param, i)
          
        )
        
        coverage_tau <- sapply(confints_tau, function(i) 
          
          lies_in_interval(original_data_object$original_tau, i)
          
        )
        
        
        # extract coefficients of survival margin
        surv_beta_vector <- bs[,2:3]
        
        
        # This returns a list with the 99% confidence intervals
        surv_marg_confints1 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        surv_marg_confints2 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        surv_marg_confints3 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        
        # These are for mu, sigma, and copula parameter
        beta_nonsurv_vector <- bs[,which(names(coef(res$value)) == "(Intercept)")[2]:(ncol(bs)-1) ]
        
        
        nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        coverage1_surv_margin <- sapply(surv_marg_confints1, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        coverage2_surv_margin <- sapply(surv_marg_confints2, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        coverage3_surv_margin <- sapply(surv_marg_confints3, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        
        
        names(coverage_tau) <- c("99%", "95%", "90%")
        names(coverage_copula_param) <- c("99%", "95%", "90%")
        
        
        
        
        
        coverages_materials <-list(tau = coverage_tau,
                                   copula_parameter = coverage_copula_param,
                                   beta_nonsurv_margin = NULL,
                                   beta_surv_margin = NULL)
        
        
        
        
        output <- list(estimated_copula_parameter = res$value$theta,
                       estimated_kendall_tau = res$value$tau,
                       copula_type = copula_class,
                       coverages = coverages_materials,
                       correlation_materials = original_data_object$correlations_materials
        )
        
        
      }
      
        
      }else{ # For coefficients in the dependence parameter
        
        
        if(NonSurv_Margin == "N pero vieja"){
          
          # Evaluate the fitted model:
          
          model_coefficients <- coef(res$value)
          
          
          kendall_binary_PWE <- res$value$tau
          
          # Copula / dependence part 
          # --- > intercept of model of copula parameter
          # --- > copula parameter (in copula parameter scale)
          # --- > kendall´s tau (pred.mvt) with confidence interval
          copula_parameter_intercept <- tail(coef(res$value),1)
          copula_parameter <- res$value$theta
          
          # Check fitted bivariate distribution in the MBS model to 
          # compute the correct Kendall's tau:
          #GAUSS copula
          if(res$value$BivD == "N"){
            
            tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
            
          }
          
          # GUMBEL copula
          if(res$value$BivD == "G0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED GUMBEL copula (90)
          if(res$value$BivD == "G90"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            
            tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
            
          }
          
          # CLAYTON copula
          if(res$value$BivD == "C0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED CLAYTON copula (90)
          if(res$value$BivD == "C90"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- - theta_coppar
            
            tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
            
          }
          
          # FRANK copula
          if(copula_class == "F"){
            
            
            signs <- sign(copula_parameter) 
            theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
            theta_coppar <- theta_coppar*signs 
            
            
            tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
            
          }
          
          # JOE copula
          if(res$value$BivD == "J0"){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # ROTATED JOE (90)
          if(res$value$BivD == "J90"){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
          #        Object Vb 
          #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
          #        function of the mvt normal distr. is used to sample from them!
          #        Obtain the following coverages: 90% ,     95%,        99%
          #                                       (1-0.05),  (1-0.025)   (1-0.005)
          
          # Confidence intervals of all coefficients will be obtained via simulations
          # For transformations of the linear predictor (i.e. survival function, etc): 
          # simulation as well as direct transformation of the linear predictor
          
          # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
          # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
          # Compute quantiles from this sample of size R.  
          # Set the number of simulations from the posterior to: 500, default = 200.
          
          # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
          # Extract coeffs again
          coefficient_vec <- coef(res$value)
          
          # Extract coeffs
          coeff_cov_mat <- res$value$Vb
          
          n.sim <- 200
          
          # Samples from the asymptotic distribution of of the coefficient vector
          bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
          
          
          # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
          # using the typical levels
          prob_levels <- c(0.01, 0.05, 0.1)
          
          confints_list <- sapply(prob_levels, 
                                  function(i) matrixStats:::colQuantiles(bs, 
                                                                         probs = c(i/2, 
                                                                                   1 - i/2),
                                                                         na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          
          # Compute xbeta for copula parameter:
          fitCopParSim <- bs[,length(coefficient_vec)]
          
          
        
          
          
          # Compute confidence intervals for the copula parameter:
          # GAUSS COPULA
          if(res$value$BivD == "N"){
            
            # just a vector of values, since the model is currently has only an intercept:
            fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                    sign(fitCopParSim)*8.75, 
                                    fitCopParSim)
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- tanh(fitCopParSim) 
            
            # computation of TAU:
            fitTauSim <-  2 / pi * asin(fitCopParSim) 
            # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
            
          }
          
          
          # CLAYTON COPULA
          if(res$value$BivD == "C0"){
            
            
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
            
          }
          
          
          # ROTATED CLAYTON COPULA (90)
          if(res$value$BivD == "C90"){
            
            
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <-  -( exp( fitCopParSim ) )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
            
            
            
          }
          
          
          # GUMBEL COPULA 
          if(res$value$BivD == "G0"){
            
            
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim ) + 1   
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <-  1 - 1 / fitTauSim 
            
          }
          
          
          # ROTATED GUMBEL COPULA (90)
          if(res$value$BivD == "G90"){
            
            
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- -( exp( fitCopParSim ) + 1  )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
            
          }
          
          
          # JOE COPULA
          if(res$value$BivD == "J0"){
            
            
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp(fitCopParSim) + 1
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            
            fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
            
            
          }
          
          
          # ROTATED JOE COPULA (90)
          if(res$value$BivD == "J90"){
            
            
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- - ( exp(fitCopParSim) + 1 )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- - fitTauSim
            
            fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
            
            
          }
          
          
          # FRANK COPULA
          if(res$value$BivD == "F"){
            
            epsilon <- c(sqrt(.Machine$double.eps))
            
            fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                    epsilon, 
                                    fitCopParSim )     
            
            
            signs <- sign(fitCopParSim) 
            
            fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                   35, 
                                   abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            fitCopParSim <- fitCopParSim*signs
            
            fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
            
            
          }
          
          
          
          
          
          confints_copulaparam <-  sapply(prob_levels,
                                          function(i)
                                            quantile(fitCopParSim,
                                                     probs = c(i/2, 1 - i/2),
                                                     na.rm = TRUE),
                                          simplify = FALSE)
          
          
          # intervals for KENDALLs TAU:
          confints_tau <-  sapply(prob_levels,
                                  function(i)
                                    quantile(fitTauSim,
                                             probs = c(i/2, 1 - i/2),
                                             na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # Compute the coverages:
          coverage_copula_param <- sapply(confints_copulaparam, function(i) 
            
            lies_in_interval(original_data_object$true_copula_param, i)
            
          )
          
          coverage_tau <- sapply(confints_tau, function(i) 
            
            lies_in_interval(original_data_object$original_tau, i)
            
          )
          
          
          
          
          names(coverage_tau) <- c("99%", "95%", "90%")
          names(coverage_copula_param) <- c("99%", "95%", "90%")
          
          
          
          
          
          
          coverages_materials <-list(tau = coverage_tau,
                                     copula_parameter = coverage_copula_param,
                                     beta_nonsurv_margin = NULL,
                                     beta_surv_margin = NULL)
          
          
          output <- list(model_coefficients = model_coefficients,
                         confints = coverages_materials,
                         estimated_copula_parameter = res$value$theta,
                         estimated_kendall_tau = res$value$tau,
                         nrow_datalong = dim(dataset_long_margin2))
          
          
          
        }
        
        if((NonSurv_Margin == "N") & (varying_dependence) ){
          
          # extract Goodness of fit residuals from the survival margin: 
          residuals_materials <- compute_relevant_residuals(model = res$value, 
                                                            data_short = original_data, 
                                                            data_long = dataset_long_margin2, 
                                                            type = "DT", 
                                                            indices = INDCS_list, 
                                                            equation_survmodel = 1)
          
          # Evaluate the fitted model:
          # --- > overall coefficients
          coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)]
          
          coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
          
          coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
          
          
          
          # Survival / margin
          # --- > 
          
          # 1: Create rich sequence of time points for the splines
          # 2: Use predict(, type = "terms")
          # 3: Extract the prediction of only the log( baseline hazard )
          # 4: Add the intercept to all observations
          # 5: Transform into hazard rate, 
          # 6: Obtain original interval lengths (all equidistant)  
          # 7: Obtain the cumu hazard, 
          # 8: Transform into survival function.
          # Step 1: 
          time_synth <- 0:number_of_ints
          time_synth2 <- 0:number_of_ints
          
          dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
          
          dat_ped_new$timeInt <- time_synth
          dat_ped_new$timeInt_margin2 <- time_synth
          
          dat_ped_ready <- dat_ped_new %>% 
            mutate(x1 = 0,
                   x2 = 0,
                   x3 = 0,
                   x5 = 0,
                   x4 = 0)
          
          # Step 2 + 3 + 4:
          # Intercept is added
          baseline_link_scale <-  predict(res$value,
                                          eq = 1,
                                          newdata = dat_ped_ready,
                                          type = "terms")[,3] +
            coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
          
          # Step 5:
          baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
          
          # Step 6: not needed in DTS
          
          # Step 7:
          cumuhazard_justcumsum <- cumsum( baseline_hazard  )
          
          cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
          
          # Step 8:
          survivalfunction <- cumprod( 1 - baseline_hazard )
          # 
          # 
          ###########################
          ###########################
          
          estimated_kendall_tau <- res$value$tau
          
          # Copula / dependence part 
          # --- > intercept of model of copula parameter
          # --- > copula parameter (in copula parameter scale)
          # --- > kendall´s tau (pred.mvt) with confidence interval
          copula_parameter_intercept <- tail(coef(res$value),2)[1]
          
          copula_parameter <- res$value$theta
          
          # Check fitted bivariate distribution in the MBS model to 
          # compute the correct Kendall's tau:
          #GAUSS copula
          if(res$value$BivD == "N"){
            
            tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
            
          }
          
          # GUMBEL copula
          if(res$value$BivD == "G0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED GUMBEL copula (90)
          if(res$value$BivD %in% c("G90", "G270")){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            
            tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
            
          }
          
          # CLAYTON copula
          if(res$value$BivD == "C0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED CLAYTON copula (90)
          if(res$value$BivD %in% c("C90", "C270")){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- - theta_coppar
            
            tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
            
          }
          
          # FRANK copula
          if(copula_class == "F"){
            
            
            signs <- sign(copula_parameter) 
            theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
            theta_coppar <- theta_coppar*signs 
            
            
            tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
            
          }
          
          # JOE copula
          if(res$value$BivD == "J0"){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # ROTATED JOE (90)
          if(res$value$BivD %in% c("J90", "J270")){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
          #        Object Vb 
          #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
          #        function of the mvt normal distr. is used to sample from them!
          #        Obtain the following coverages: 90% ,     95%,        99%
          #                                       (1-0.05),  (1-0.025)   (1-0.005)
          
          # Confidence intervals of all coefficients will be obtained via simulations
          # For transformations of the linear predictor (i.e. survival function, etc): 
          # simulation as well as direct transformation of the linear predictor
          
          # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
          # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
          # Compute quantiles from this sample of size R.  
          # Set the number of simulations from the posterior to: 500, default = 200.
          
          # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
          # Extract coeffs again
          coefficient_vec <- coef(res$value)
          
          # Extract coeffs
          coeff_cov_mat <- res$value$Vb
          
          n.sim <- n.sim
          
          # Samples from the asymptotic distribution of of the coefficient vector
          bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
          
          
          # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
          # using the typical levels
          prob_levels <- c(0.01, 0.05, 0.1)
          
          confints_list <- sapply(prob_levels, 
                                  function(i) matrixStats:::colQuantiles(bs, 
                                                                         probs = c(i/2, 
                                                                                   1 - i/2),
                                                                         na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # For the specific splines:
          # Recover the synthetic values of the covariates:
          # remove other covariates values from the linear predictor: 
          dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
          
          # Obtain various additive predictors: 
          Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
          
          Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
          
          
          # Copula parameter and then into tau:
          dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
          
          XfitCopParam <- predict(res$value, eq = 4, type = "lpmatrix", newdata = dat_ped_ready_copparam)
          
          # Compute xbeta for first margin: 
          fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
          
          # # Compute xbeta for second margin: 
          fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 4)] )
          
          
          # Compute xbeta for copula parameter:
          fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
          
          
          
          
          # # Survival margin:
          confints_linkscalehazard <- sapply(prob_levels,
                                             function(i)
                                               matrixStats:::rowQuantiles(fit1Sim,
                                                                          probs = c(i/2, 1 - i/2),
                                                                          na.rm = TRUE),
                                             simplify = FALSE)
          
          
          
          confints_hazard <- sapply(prob_levels,
                                    function(i)
                                      matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                                 probs = c(i/2, 1 - i/2),
                                                                 na.rm = TRUE),
                                    simplify = FALSE)
          
          
          # # Compute the cumulative sum correctly:
          fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                   function(i)
                                     cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                   simplify = TRUE)
          
          
          fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                             function(i)
                                               -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                             simplify = TRUE)
          
          
          fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                    function(i)
                                      cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                    simplify = TRUE)
          
          # # Compute quantiles
          confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                                function(i)
                                                  matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                             probs = c(i/2, 1 - i/2),
                                                                             na.rm = TRUE),
                                                simplify = FALSE)
          
          confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                     function(i)
                                                       matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                                  probs = c(i/2, 1 - i/2),
                                                                                  na.rm = TRUE),
                                                     simplify = FALSE)
          
          confints_survival <-  sapply(prob_levels,
                                       function(i)
                                         matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                    probs = c(i/2, 1 - i/2),
                                                                    na.rm = TRUE),
                                       simplify = FALSE)
          
          
          
          
          
          # For the true value: 
          copparam_true_df <- data.frame(Intercept = 1,
                                         x5_true = seq(-1, +1, length.out = 200)
          )
          
          eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
          
          
          
          # Compute confidence intervals for the copula parameter:
          # GAUSS COPULA
          if(res$value$BivD == "N"){
            
            
            copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                     sign(eta_copparam_true) * 8.75, 
                                     eta_copparam_true)
            
            copparam_true <- tanh(copparam_true) 
            
            
            tau_true <-  2 / pi * asin(copparam_true) 
            
            
            ### FOR CONFIDENCE INTERVALS
            # just a vector of values, since the model is currently has only an intercept:
            fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                    sign(fitCopParSim)*8.75, 
                                    fitCopParSim)
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- tanh(fitCopParSim) 
            
            # computation of TAU:
            fitTauSim <-  2 / pi * asin(fitCopParSim) 
            # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
            
          }
          
          
          # CLAYTON COPULA
          if(res$value$BivD == "C0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true ) 
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true ) 
            
            copparam_true <- exp( eta_copparam_true )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                               28, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- tau_true / ( tau_true + 2 ) 
            
            
            
            
            ##############
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
            
          }
          
          
          # ROTATED CLAYTON COPULA (90)
          if(res$value$BivD %in% c("C90", "C270")){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <-  -( exp( eta_copparam_true ) )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                               28, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
            
            
            
            ###########################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <-  -( exp( fitCopParSim ) )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
            
            
            
          }
          
          
          # GUMBEL COPULA 
          if(res$value$BivD == "G0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp( eta_copparam_true ) + 1   
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                               17, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <-  1 - 1 / tau_true 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim ) + 1   
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <-  1 - 1 / fitTauSim 
            
          }
          
          
          # ROTATED GUMBEL COPULA (90)
          if(res$value$BivD %in% c("G90", "G270")){
            
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- -( exp( eta_copparam_true ) + 1  )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                               17, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <-  -( 1 - 1 / abs(tau_true) ) 
            
            
            #############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- -( exp( fitCopParSim ) + 1  )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
            
          }
          
          
          # JOE COPULA
          if(res$value$BivD == "J0"){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp(eta_copparam_true) + 1
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                               30, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            
            tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
            
            
            
            
            ################################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp(fitCopParSim) + 1
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            
            fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
            
            
          }
          
          
          # ROTATED JOE COPULA (90)
          if(res$value$BivD %in% c("J90", "J270")){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- - ( exp(eta_copparam_true) + 1 )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                               30, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- - tau_true
            
            tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- - ( exp(fitCopParSim) + 1 )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- - fitTauSim
            
            fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
            
            
          }
          
          
          # FRANK COPULA
          if(res$value$BivD == "F"){
            
            
            epsilon <- c(sqrt(.Machine$double.eps))
            
            eta_copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                         epsilon, 
                                         eta_copparam_true )     
            
            
            signs <- sign(eta_copparam_true) 
            
            eta_copparam_true <- ifelse(abs(eta_copparam_true) > 35, 
                                        35, 
                                        abs(eta_copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            copparam_true <- eta_copparam_true*signs
            
            tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
            
            
            #################
            epsilon <- c(sqrt(.Machine$double.eps))
            
            fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                    epsilon, 
                                    fitCopParSim )     
            
            
            signs <- sign(fitCopParSim) 
            
            fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                   35, 
                                   abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            fitCopParSim <- fitCopParSim*signs
            
            fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
            
            
          }
          
          
          
          
          
          confints_copulaparam <-  sapply(prob_levels,
                                          function(i)
                                            rowQuantiles(fitCopParSim,
                                                         probs = c(i/2, 1 - i/2),
                                                         na.rm = TRUE),
                                          simplify = FALSE)
          
          
          # intervals for KENDALLs TAU:
          confints_tau <-  sapply(prob_levels,
                                  function(i)
                                    rowQuantiles(fitTauSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # Compute the coverages:
          coverage_copula_param <- sapply(confints_copulaparam, function(i) 
            
            mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
            
          )
          
          
          
          coverage_tau <- sapply(confints_tau, function(i) 
            
            mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
            
          )
          
          
          # extract coefficients of nonsurvival margin
          beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 4) ]
          
          surv_beta_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
          
          copparam_beta_vector <- bs[, (ncol(bs)-1):ncol(bs) ]
          
          # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
          surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals  of each coefficient!
          surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals  of each coefficient!
          surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          
          # Now for the nonsurvival margin:
          nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals
          nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals
          nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          # Compute coverages:
          coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
            
          )
          
          coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
          )
          
          coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
          )
          
          
          
          ########### now for the nonsurvival margin:
          coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
            
          )
          
          coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
            
          )
          
          coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
            
          )
          
          
          
          names(coverage_tau) <- c("99%", "95%", "90%")
          names(coverage_copula_param) <- c("99%", "95%", "90%")
          
          
          
          
          confint_materials <- list(all_coefficients  = confints_list,
                                    linkscale_hazard = confints_linkscalehazard,
                                    hazard = confints_hazard,
                                    cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                    cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                    survival = confints_survival,
                                    copula_param = confints_copulaparam,
                                    kendall_tau = confints_tau, 
                                    #
                                    coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                        ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                        ninetyfive = coverage3_nonsurv_margin),
                                    #
                                    coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                         ninetyseven_pointfive = coverage2_surv_margin,
                                                                         ninetyfive = coverage3_surv_margin),
                                    coverage_tau = coverage_tau,
                                    coverage_copula_parameter = coverage_copula_param
          )
          
          
          
          
          # Put everything together
          output <- list(
            # Coefficients
            coefficients_nonsurv = coefficients_nonsurv_margin,
            coefficients_survival = coefficients_survival_margin,
            coefficients_copula_parameter = coefficients_copula_parameter,
            #
            #
            residuals_materials = residuals_materials,
            #
            # Smooth functions
            linkscale_baseline = baseline_link_scale,
            baseline = baseline_hazard,
            cumu_hazard = cumuhazard_justcumsum,
            cumu_hazard_logoneminus = cumuhazard_logoneminus,
            survival = survivalfunction,
            #
            # copula parameter and dependence
            copula_parameter = copula_parameter,
            tau_of_kendall = tau_of_kendall,
            #
            # Big matrix of coefficient's confidence intervals:
            confint_materials = confint_materials,
            #
            # Various summaries
            survival_data_n = nrow(dataset_long_margin2),
            original_data_n = nrow(original_data),
            edf_nonsurvival_margin = res$value$edf[[2]],
            edf_survival_margin = res$value$edf[[1]],
            #
            #
            #
            # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
            estimated_kendall = res$value$tau,
            copula_parameter_estimate = res$value$theta,
            # some other diagnostics
            cuts_placement_intime = the_used_cuts,
            the_unique_tends = the_unique_tends,
            the_warning = res$warning,
            the_error = res$error,
            model_runtime = model_runtime
          )
          
          
          
          
        }
        
        if(  NonSurv_Margin == "DAGUM" ){
          
          # extract Goodness of fit residuals from the survival margin: 
          residuals_materials <- compute_relevant_residuals(model = res$value, 
                                                            data_short = original_data, 
                                                            data_long = dataset_long_margin2, 
                                                            type = "DT", 
                                                            indices = INDCS_list, 
                                                            equation_survmodel = 1)
          
          # Evaluate the fitted model:
          # --- > overall coefficients
          coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)]
          
          coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
          
          coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
          
          
          
          # Survival / margin

          # 1: Create rich sequence of time points for the splines
          # 2: Use predict(, type = "terms")
          # 3: Extract the prediction of only the log( baseline hazard )
          # 4: Add the intercept to all observations
          # 5: Transform into hazard rate, 
          # 6: Obtain original interval lengths (all equidistant)  
          # 7: Obtain the cumu hazard, 
          # 8: Transform into survival function.
          # Step 1: 
          time_synth <- 0:number_of_ints
          time_synth2 <- 0:number_of_ints
          
          dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
          
          dat_ped_new$timeInt <- time_synth
          dat_ped_new$timeInt_margin2 <- time_synth
          
          dat_ped_ready <- dat_ped_new %>% 
            mutate(x1 = 0,
                   x2 = 0,
                   x3 = 0,
                   x5 = 0,
                   x4 = 0)
          
          # Step 2 + 3 + 4:
          # Intercept is added
          baseline_link_scale <-  predict(res$value,
                                          eq = 1,
                                          newdata = dat_ped_ready,
                                          type = "terms")[,3] +
            coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
          
          # Step 5:
          baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
          
          # Step 6: not needed in DTS
          
          # Step 7:
          cumuhazard_justcumsum <- cumsum( baseline_hazard  )
          
          cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
          
          # Step 8:
          survivalfunction <- cumprod( 1 - baseline_hazard )
          # 
          # 
          ###########################
          ###########################
          
          estimated_kendall_tau <- res$value$tau
          
          # Copula / dependence part 
          # --- > intercept of model of copula parameter
          # --- > copula parameter (in copula parameter scale)
          # --- > kendall´s tau (pred.mvt) with confidence interval
          copula_parameter_intercept <- tail(coef(res$value),2)[1]
          
          copula_parameter <- res$value$theta
          
          # Check fitted bivariate distribution in the MBS model to 
          # compute the correct Kendall's tau:
          #GAUSS copula
          if(res$value$BivD == "N"){
            
            tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
            
          }
          
          # GUMBEL copula
          if(res$value$BivD == "G0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED GUMBEL copula (90)
          if(res$value$BivD == "G90"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            
            tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
            
          }
          
          # CLAYTON copula
          if(res$value$BivD == "C0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED CLAYTON copula (90)
          if(res$value$BivD == "C90"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- - theta_coppar
            
            tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
            
          }
          
          # FRANK copula
          if(copula_class == "F"){
            
            
            signs <- sign(copula_parameter) 
            theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
            theta_coppar <- theta_coppar*signs 
            
            
            tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
            
          }
          
          # JOE copula
          if(res$value$BivD == "J0"){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # ROTATED JOE (90)
          if(res$value$BivD == "J90"){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
          #        Object Vb 
          #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
          #        function of the mvt normal distr. is used to sample from them!
          #        Obtain the following coverages: 90% ,     95%,        99%
          #                                       (1-0.05),  (1-0.025)   (1-0.005)
          
          # Confidence intervals of all coefficients will be obtained via simulations
          # For transformations of the linear predictor (i.e. survival function, etc): 
          # simulation as well as direct transformation of the linear predictor
          
          # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
          # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
          # Compute quantiles from this sample of size R.  
          # Set the number of simulations from the posterior to: 500, default = 200.
          
          # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
          # Extract coeffs again
          coefficient_vec <- coef(res$value)
          
          # Extract coeffs
          coeff_cov_mat <- res$value$Vb
          
          n.sim <- n.sim
          
          # Samples from the asymptotic distribution of of the coefficient vector
          bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
          
          
          # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
          # using the typical levels
          prob_levels <- c(0.01, 0.05, 0.1)
          
          confints_list <- sapply(prob_levels, 
                                  function(i) matrixStats:::colQuantiles(bs, 
                                                                         probs = c(i/2, 
                                                                                   1 - i/2),
                                                                         na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # For the specific splines:
          # Recover the synthetic values of the covariates:
          # remove other covariates values from the linear predictor: 
          dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
          
          # Obtain various additive predictors: 
          Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
          
          Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
          
          
          # Copula parameter and then into tau:
          dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
          
          XfitCopParam <- predict(res$value, eq = 4, type = "lpmatrix", newdata = dat_ped_ready_copparam)
          
          # Compute xbeta for first margin: 
          fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
          
          # # Compute xbeta for second margin: 
          fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 4)] )
          
          
          # Compute xbeta for copula parameter:
          fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
          
          
          # Compute now transformation of this: 
          
          
          # # Survival margin:
          confints_linkscalehazard <- sapply(prob_levels,
                                             function(i)
                                               matrixStats:::rowQuantiles(fit1Sim,
                                                                          probs = c(i/2, 1 - i/2),
                                                                          na.rm = TRUE),
                                             simplify = FALSE)
          
          
          
          confints_hazard <- sapply(prob_levels,
                                    function(i)
                                      matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                                 probs = c(i/2, 1 - i/2),
                                                                 na.rm = TRUE),
                                    simplify = FALSE)
          
          
          # # Compute the cumulative sum correctly:
          fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                   function(i)
                                     cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                   simplify = TRUE)
          
          
          fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                             function(i)
                                               -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                             simplify = TRUE)
          
          
          fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                    function(i)
                                      cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                    simplify = TRUE)
          
          # # Compute quantiles
          confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                                function(i)
                                                  matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                             probs = c(i/2, 1 - i/2),
                                                                             na.rm = TRUE),
                                                simplify = FALSE)
          
          confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                     function(i)
                                                       matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                                  probs = c(i/2, 1 - i/2),
                                                                                  na.rm = TRUE),
                                                     simplify = FALSE)
          
          confints_survival <-  sapply(prob_levels,
                                       function(i)
                                         matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                    probs = c(i/2, 1 - i/2),
                                                                    na.rm = TRUE),
                                       simplify = FALSE)
          
          
          
          
          
          # For the true value: 
          copparam_true_df <- data.frame(Intercept = 1,
                                         x5_true = seq(-1, +1, length.out = 200)
          )
          
          eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
          
          
          
          # Compute confidence intervals for the copula parameter:
          # GAUSS COPULA
          if(res$value$BivD == "N"){
            
            
            copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                     sign(eta_copparam_true) * 8.75, 
                                     eta_copparam_true)
            
            copparam_true <- tanh(copparam_true) 
            
            
            tau_true <-  2 / pi * asin(copparam_true) 
            
            
            ### FOR CONFIDENCE INTERVALS
            # just a vector of values, since the model is currently has only an intercept:
            fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                    sign(fitCopParSim)*8.75, 
                                    fitCopParSim)
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- tanh(fitCopParSim) 
            
            # computation of TAU:
            fitTauSim <-  2 / pi * asin(fitCopParSim) 
            # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
            
          }
          
          
          # CLAYTON COPULA
          if(res$value$BivD == "C0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true ) 
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true ) 
            
            copparam_true <- exp( eta_copparam_true )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                               28, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- tau_true / ( tau_true + 2 ) 
            
            
            
            
            ##############
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
            
          }
          
          
          # ROTATED CLAYTON COPULA (90)
          if(res$value$BivD == "C90"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <-  -( exp( eta_copparam_true ) )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                               28, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
            
            
            
            ###########################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <-  -( exp( fitCopParSim ) )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
            
            
            
          }
          
          
          # GUMBEL COPULA 
          if(res$value$BivD == "G0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp( eta_copparam_true ) + 1   
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                               17, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <-  1 - 1 / tau_true 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim ) + 1   
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <-  1 - 1 / fitTauSim 
            
          }
          
          
          # ROTATED GUMBEL COPULA (90)
          if(res$value$BivD == "G90"){
            
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- -( exp( eta_copparam_true ) + 1  )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                               17, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <-  -( 1 - 1 / abs(tau_true) ) 
            
            
            #############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- -( exp( fitCopParSim ) + 1  )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
            
          }
          
          
          # JOE COPULA
          if(res$value$BivD == "J0"){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp(eta_copparam_true) + 1
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                               30, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            
            tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
            
            
            
            
            ################################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp(fitCopParSim) + 1
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            
            fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
            
            
          }
          
          
          # ROTATED JOE COPULA (90)
          if(res$value$BivD == "J90"){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- - ( exp(eta_copparam_true) + 1 )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                               30, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- - tau_true
            
            tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- - ( exp(fitCopParSim) + 1 )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- - fitTauSim
            
            fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
            
            
          }
          
          
          # FRANK COPULA
          if(res$value$BivD == "F"){
            
            
            epsilon <- c(sqrt(.Machine$double.eps))
            
            eta_copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                         epsilon, 
                                         eta_copparam_true )     
            
            
            signs <- sign(eta_copparam_true) 
            
            eta_copparam_true <- ifelse(abs(eta_copparam_true) > 35, 
                                        35, 
                                        abs(eta_copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            copparam_true <- eta_copparam_true*signs
            
            tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
            
            
            #################
            epsilon <- c(sqrt(.Machine$double.eps))
            
            fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                    epsilon, 
                                    fitCopParSim )     
            
            
            signs <- sign(fitCopParSim) 
            
            fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                   35, 
                                   abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            fitCopParSim <- fitCopParSim*signs
            
            fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
            
            
          }
          
          
          
          
          
          confints_copulaparam <-  sapply(prob_levels,
                                          function(i)
                                            rowQuantiles(fitCopParSim,
                                                         probs = c(i/2, 1 - i/2),
                                                         na.rm = TRUE),
                                          simplify = FALSE)
          
          
          # intervals for KENDALLs TAU:
          confints_tau <-  sapply(prob_levels,
                                  function(i)
                                    rowQuantiles(fitTauSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # Compute the coverages:
          coverage_copula_param <- sapply(confints_copulaparam, function(i) 
            
            mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
            
          )
          
          
          
          coverage_tau <- sapply(confints_tau, function(i) 
            
            mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
            
          )
          
          
          # extract coefficients of nonsurvival margin
          beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 5) ]
          
          surv_beta_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
          
          copparam_beta_vector <- bs[, (ncol(bs)-1):ncol(bs) ]
          
          # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
          surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals  of each coefficient!
          surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals  of each coefficient!
          surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          
          # Now for the nonsurvival margin:
          nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals
          nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals
          nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          # Compute coverages:
          coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
            
          )
          
          coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
          )
          
          coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
          )
          
          
          
          ########### now for the nonsurvival margin:
          coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
            
          )
          
          coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
            
          )
          
          coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
            
          )
          
          
          
          names(coverage_tau) <- c("99%", "95%", "90%")
          names(coverage_copula_param) <- c("99%", "95%", "90%")
          
          
          
          
          confint_materials <- list(all_coefficients  = confints_list,
                                    linkscale_hazard = confints_linkscalehazard,
                                    hazard = confints_hazard,
                                    cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                    cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                    survival = confints_survival,
                                    copula_param = confints_copulaparam,
                                    kendall_tau = confints_tau, 
                                    #
                                    coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                        ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                        ninetyfive = coverage3_nonsurv_margin),
                                    #
                                    coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                         ninetyseven_pointfive = coverage2_surv_margin,
                                                                         ninetyfive = coverage3_surv_margin),
                                    coverage_tau = coverage_tau,
                                    coverage_copula_parameter = coverage_copula_param
          )
          
          
          
          
          # Put everything together
          output <- list(
            # Coefficients
            coefficients_nonsurv = coefficients_nonsurv_margin,
            coefficients_survival = coefficients_survival_margin,
            coefficients_copula_parameter = coefficients_copula_parameter,
            #
            #
            residuals_materials = residuals_materials,
            #
            # Smooth functions
            linkscale_baseline = baseline_link_scale,
            baseline = baseline_hazard,
            cumu_hazard = cumuhazard_justcumsum,
            cumu_hazard_logoneminus = cumuhazard_logoneminus,
            survival = survivalfunction,
            #
            # copula parameter and dependence
            copula_parameter = copula_parameter,
            tau_of_kendall = tau_of_kendall,
            #
            # Big matrix of coefficient's confidence intervals:
            confint_materials = confint_materials,
            #
            # Various summaries
            survival_data_n = nrow(dataset_long_margin2),
            original_data_n = nrow(original_data),
            edf_nonsurvival_margin = res$value$edf[[2]],
            edf_survival_margin = res$value$edf[[1]],
            #
            #
            #
            # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
            estimated_kendall = res$value$tau,
            copula_parameter_estimate = res$value$theta,
            # some other diagnostics
            cuts_placement_intime = the_used_cuts,
            the_unique_tends = the_unique_tends,
            the_warning = res$warning,
            the_error = res$error,
            model_runtime = model_runtime
          )
          
          
          
          
        }
        
        # This is the output in case of binary non-survival margins
        if( NonSurv_Margin %in% c("logit", "probit", "cloglog", "GEVlink") ){
          
          
          ### GBS: changed it here
          
          
          # extract Goodness of fit residuals from the survival margin: 
          residuals_materials <- compute_relevant_residuals(model = res$value, 
                                                            data_short = original_data, 
                                                            data_long = dataset_long_margin2, 
                                                            type = "DT", 
                                                            indices = INDCS_list, 
                                                            equation_survmodel = 2)
          
          # Evaluate the fitted model:
          # --- > overall coefficients
          coefficients_nonsurv_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ]
          
          coefficients_survival_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)] 
          
          coefficients_copula_parameter <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[3]):(length(coef(res$value)))]
          
          
          
          # Survival / margin
          # --- > 
          
          # 1: Create rich sequence of time points for the splines
          # 2: Use predict(, type = "terms")
          # 3: Extract the prediction of only the log( baseline hazard )
          # 4: Add the intercept to all observations
          # 5: Transform into hazard rate, 
          # 6: Obtain original interval lengths (all equidistant)  
          # 7: Obtain the cumu hazard, 
          # 8: Transform into survival function.
          # Step 1: 
          time_synth <- 0:number_of_ints
          time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
          
          dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
          
          dat_ped_new$timeInt <- time_synth
          dat_ped_new$timeInt_margin2 <- time_synth
          
          dat_ped_ready <- dat_ped_new %>% 
            mutate(x1 = 0,
                   x2 = 0,
                   x3 = 0,
                   x5 = 0,
                   x4 = 0)
          
          # Step 2 + 3 + 4:
          # Intercept is added
          baseline_link_scale <-  predict(res$value,
                                          eq = 2,
                                          newdata = dat_ped_ready,
                                          type = "terms")[,3] +
            coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]
          
          # Step 5:
          baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
          
          # Step 6: not needed in DTS
          
          # Step 7:
          cumuhazard_justcumsum <- cumsum( baseline_hazard  )
          
          cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
          
          # Step 8:
          survivalfunction <- cumprod( 1 - baseline_hazard )
          # 
          # 
          ###########################
          ###########################
          
          estimated_kendall_tau <- res$value$tau
          
          # Copula / dependence part 
          # --- > intercept of model of copula parameter
          # --- > copula parameter (in copula parameter scale)
          # --- > kendall´s tau (pred.mvt) with confidence interval
          copula_parameter_intercept <- tail(coef(res$value), 2)[1]
          
          copula_parameter <- res$value$theta
          
          # Check fitted bivariate distribution in the MBS model to 
          # compute the correct Kendall's tau:
          #GAUSS copula
          if(res$value$BivD == "N"){
            
            copula_parameter <- tanh(copula_parameter)
            
            tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
            
          }
          
          # GUMBEL copula
          if(res$value$BivD == "G0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED GUMBEL copula (90)
          if(res$value$BivD %in% c("G90", "G270")){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            
            tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
            
          }
          
          # CLAYTON copula
          if(res$value$BivD == "C0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED CLAYTON copula (90)
          if(res$value$BivD %in% c("C90", "C270")){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- - theta_coppar
            
            tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
            
          }
          
          # FRANK copula
          if(copula_class == "F"){
            
            
            signs <- sign(copula_parameter) 
            theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
            theta_coppar <- theta_coppar*signs 
            
            
            tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
            
          }
          
          # JOE copula
          if(res$value$BivD == "J0"){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # ROTATED JOE (90)
          if(res$value$BivD %in% c("J90", "J270")){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
          #        Object Vb 
          #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
          #        function of the mvt normal distr. is used to sample from them!
          #        Obtain the following coverages: 90% ,     95%,        99%
          #                                       (1-0.05),  (1-0.025)   (1-0.005)
          
          # Confidence intervals of all coefficients will be obtained via simulations
          # For transformations of the linear predictor (i.e. survival function, etc): 
          # simulation as well as direct transformation of the linear predictor
          
          # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
          # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
          # Compute quantiles from this sample of size R.  
          # Set the number of simulations from the posterior to: 500, default = 200.
          
          # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
          # Extract coeffs again
          coefficient_vec <- coef(res$value)
          
          # Extract coeffs
          coeff_cov_mat <- res$value$Vb
          
          n.sim <- n.sim
          
          # Samples from the asymptotic distribution of of the coefficient vector
          bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
          
          
          # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
          # using the typical levels
          prob_levels <- c(0.01, 0.05, 0.1)
          
          confints_list <- sapply(prob_levels, 
                                  function(i) matrixStats:::colQuantiles(bs, 
                                                                         probs = c(i/2, 
                                                                                   1 - i/2),
                                                                         na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # For the specific splines:
          # Recover the synthetic values of the covariates:
          # remove other covariates values from the linear predictor: 
          dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
          
          # Obtain various additive predictors: 
          Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
          
          Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
          
          
          # Copula parameter and then into tau:
          dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
          
          XfitCopParam <- predict(res$value, eq = 3, type = "lpmatrix", newdata = dat_ped_ready_copparam)
          
          # Compute xbeta for first margin: binary
          fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
          
          # # Compute xbeta for second margin: PWE
          fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)] )
          
          # Compute xbeta for copula parameter:
          fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
          
          
          # # Survival margin:
          confints_linkscalehazard <- sapply(prob_levels,
                                             function(i)
                                               matrixStats:::rowQuantiles(fit2Sim,
                                                                          probs = c(i/2, 1 - i/2),
                                                                          na.rm = TRUE),
                                             simplify = FALSE)
          
          
          
          confints_hazard <- sapply(prob_levels,
                                    function(i)
                                      matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ),
                                                                 probs = c(i/2, 1 - i/2),
                                                                 na.rm = TRUE),
                                    simplify = FALSE)
          
          
          # # Compute the cumulative sum correctly:
          fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                   function(i)
                                     cumsum( (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                                   simplify = TRUE)
          
          
          fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                             function(i)
                                               -cumsum( log(1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ) ),
                                             simplify = TRUE)
          
          
          fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                    function(i)
                                      cumprod( 1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                                    simplify = TRUE)
          
          # # Compute quantiles
          confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                                function(i)
                                                  matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                             probs = c(i/2, 1 - i/2),
                                                                             na.rm = TRUE),
                                                simplify = FALSE)
          
          confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                     function(i)
                                                       matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                                  probs = c(i/2, 1 - i/2),
                                                                                  na.rm = TRUE),
                                                     simplify = FALSE)
          
          confints_survival <-  sapply(prob_levels,
                                       function(i)
                                         matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                    probs = c(i/2, 1 - i/2),
                                                                    na.rm = TRUE),
                                       simplify = FALSE)
          
          
          
          # For the true value: 
          copparam_true_df <- data.frame(Intercept = 1,
                                         x5_true = seq(-1, +1, length.out = 200)
          )
          
          eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
          
          
          
          # Compute confidence intervals for the copula parameter:
          # GAUSS COPULA
          if(res$value$BivD == "N"){
            
            
            copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                     sign(eta_copparam_true) * 8.75, 
                                     eta_copparam_true)
            
            copparam_true <- tanh(copparam_true) 
            
            
            tau_true <-  2 / pi * asin(copparam_true) 
            
            
            ### FOR CONFIDENCE INTERVALS
            # just a vector of values, since the model is currently has only an intercept:
            fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                    sign(fitCopParSim)*8.75, 
                                    fitCopParSim)
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- tanh(fitCopParSim) 
            
            # computation of TAU:
            fitTauSim <-  2 / pi * asin(fitCopParSim) 
            # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
            
          }
          
          
          # CLAYTON COPULA
          if(res$value$BivD == "C0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true ) 
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true ) 
            
            copparam_true <- exp( eta_copparam_true )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                                28, 
                                abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- tau_true / ( tau_true + 2 ) 
            
            
            
            
            ##############
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
            
          }
          
          
          # ROTATED CLAYTON COPULA (90)
          if(res$value$BivD %in% c("C90", "C270")){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <-  -( exp( eta_copparam_true ) )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                                28, 
                                abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
            
            
            
            ###########################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <-  -( exp( fitCopParSim ) )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
            
            
            
          }
          
          
          # GUMBEL COPULA 
          if(res$value$BivD == "G0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp( eta_copparam_true ) + 1   
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                                17, 
                                abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <-  1 - 1 / tau_true 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim ) + 1   
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <-  1 - 1 / fitTauSim 
            
          }
          
          
          # ROTATED GUMBEL COPULA (90)
          if(res$value$BivD %in% c("G90", "G270")){
            
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- -( exp( eta_copparam_true ) + 1  )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                                17, 
                                abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <-  -( 1 - 1 / abs(tau_true) ) 
            
            
            #############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- -( exp( fitCopParSim ) + 1  )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
            
          }
          
          
          # JOE COPULA
          if(res$value$BivD == "J0"){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp(eta_copparam_true) + 1
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                                30, 
                                abs(copparam_true)) # based on BiCopPar2Tau 
            
            
            tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
            
            
            
            
            ################################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp(fitCopParSim) + 1
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            
            fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
            
            
          }
          
          
          # ROTATED JOE COPULA (90)
          if(res$value$BivD %in% c("J90", "J270")){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- - ( exp(eta_copparam_true) + 1 )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                                30, 
                                abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- - tau_true
            
            tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- - ( exp(fitCopParSim) + 1 )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- - fitTauSim
            
            fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
            
            
          }
          
          
          # FRANK COPULA
          if(res$value$BivD == "F"){
            
            
            epsilon <- c(sqrt(.Machine$double.eps))
            
            copparam_true <- eta_copparam_true
            
            copparam_true <- ifelse( abs(copparam_true) < epsilon, 
                                    epsilon, 
                                    copparam_true )     
            
            
            signs <- sign(copparam_true) 
            
            copparam_true <- ifelse(abs(copparam_true) > 35, 
                                   35, 
                                   abs(copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            copparam_true <- copparam_true*signs
            
            tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
            
            
            #################
            epsilon <- c(sqrt(.Machine$double.eps))
            
            fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                    epsilon, 
                                    fitCopParSim )     
            
            
            signs <- sign(fitCopParSim) 
            
            fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                   35, 
                                   abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            fitCopParSim <- fitCopParSim*signs
            
            fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
            
            
          }
          
          
          
          
          
          confints_copulaparam <-  sapply(prob_levels,
                                          function(i)
                                            rowQuantiles(fitCopParSim,
                                                     probs = c(i/2, 1 - i/2),
                                                     na.rm = TRUE),
                                          simplify = FALSE)
          
          
          # intervals for KENDALLs TAU:
          confints_tau <-  sapply(prob_levels,
                                  function(i)
                                    rowQuantiles(fitTauSim,
                                             probs = c(i/2, 1 - i/2),
                                             na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # Compute the coverages:
          coverage_copula_param <- sapply(confints_copulaparam, function(i) 
            
            mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
            
          )
          
          
          
          coverage_tau <- sapply(confints_tau, function(i) 
            
            mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
            
          )
          
          
          # extract coefficients of nonsurvival margin
          beta_nonsurv_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
          
          surv_beta_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
          
          copparam_beta_vector <- bs[, (ncol(bs)-1):ncol(bs) ]
          
          # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
          surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals  of each coefficient!
          surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals  of each coefficient!
          surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          
          # Now for the nonsurvival margin:
          nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals
          nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals
          nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          # Compute coverages:
          coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
            
          )
          
          coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
          )
          
          coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
          )
          
          
          
          ########### now for the nonsurvival margin:
          coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
            
          )
          
          coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
            
          )
          
          coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
            
          )
          
          
          
          names(coverage_tau) <- c("99%", "95%", "90%")
          names(coverage_copula_param) <- c("99%", "95%", "90%")
          
          
          
          
          confint_materials <- list(all_coefficients  = confints_list,
                                    linkscale_hazard = confints_linkscalehazard,
                                    hazard = confints_hazard,
                                    cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                    cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                    survival = confints_survival,
                                    copula_param = confints_copulaparam,
                                    kendall_tau = confints_tau, 
                                    #
                                    coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                        ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                        ninetyfive = coverage3_nonsurv_margin),
                                    #
                                    coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                         ninetyseven_pointfive = coverage2_surv_margin,
                                                                         ninetyfive = coverage3_surv_margin),
                                    coverage_tau = coverage_tau,
                                    coverage_copula_parameter = coverage_copula_param
          )
          
          
          
          # Put everything together
          output <- list(
            # Coefficients
            coefficients_nonsurv = coefficients_nonsurv_margin,
            coefficients_survival = coefficients_survival_margin,
            coefficients_copula_parameter = coefficients_copula_parameter,
            #
            #
            residuals_materials = residuals_materials,
            #
            # Smooth functions
            linkscale_baseline = baseline_link_scale,
            baseline = baseline_hazard,
            cumu_hazard = cumuhazard_justcumsum,
            cumu_hazard_logoneminus = cumuhazard_logoneminus,
            survival = survivalfunction,
            #
            # copula parameter and dependence
            copula_parameter = copula_parameter,
            tau_of_kendall = tau_of_kendall,
            #
            # Big matrix of coefficient's confidence intervals:
            confint_materials = confint_materials,
            #
            # Various summaries
            survival_data_n = nrow(dataset_long_margin2),
            original_data_n = nrow(original_data),
            edf_nonsurvival_margin = res$value$edf[[1]],
            edf_survival_margin = res$value$edf[[2]],
            #
            #
            #
            # Stuff regarding estimated kendall taus 
            estimated_kendall = res$value$tau,
            copula_parameter_estimate = res$value$theta,
            # some other diagnostics
            cuts_placement_intime = the_used_cuts,
            the_unique_tends = the_unique_tends,
            the_warning = res$warning,
            the_error = res$error,
            model_runtime = model_runtime
          )
          
          
          
          
          
          
        }
        
        # This is the output in case of discrete non-survival margins
        if(  NonSurv_Margin == "PO" ){
          
          # extract Goodness of fit residuals from the survival margin: 
          residuals_materials <- compute_relevant_residuals(model = res$value, 
                                                            data_short = original_data, 
                                                            data_long = dataset_long_margin2, 
                                                            type = "DT", 
                                                            indices = INDCS_list, 
                                                            equation_survmodel = 1)
          
          # Evaluate the fitted model:
          # --- > overall coefficients
          coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)]
          
          coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
          
          coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
          
          
          
          # Survival / margin
          # --- > 
          # 1: Create rich sequence of time points for the splines
          # 2: Use predict(, type = "terms")
          # 3: Extract the prediction of only the log( baseline hazard )
          # 4: Add the intercept to all observations
          # 5: Transform into hazard rate, 
          # 6: Obtain original interval lengths (all equidistant)  
          # 7: Obtain the cumu hazard, 
          # 8: Transform into survival function.
          # Step 1: 
          time_synth <- 0:number_of_ints
          time_synth2 <- 0:number_of_ints
          
          dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
          
          dat_ped_new$timeInt <- time_synth
          dat_ped_new$timeInt_margin2 <- time_synth
          
          dat_ped_ready <- dat_ped_new %>% 
            mutate(x1 = 0,
                   x2 = 0,
                   x3 = 0,
                   x5 = 0,
                   x4 = 0)
          
          # Step 2 + 3 + 4:
          # Intercept is added
          baseline_link_scale <-  predict(res$value,
                                          eq = 1,
                                          newdata = dat_ped_ready,
                                          type = "terms")[,3] +
            coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
          
          # Step 5:
          baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
          
          # Step 6: not needed in DTS
          
          # Step 7:
          cumuhazard_justcumsum <- cumsum( baseline_hazard  )
          
          cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
          
          # Step 8:
          survivalfunction <- cumprod( 1 - baseline_hazard )
          # 
          # 
          ###########################
          ###########################
          
          estimated_kendall_tau <- res$value$tau
          
          # Copula / dependence part 
          # --- > intercept of model of copula parameter
          # --- > copula parameter (in copula parameter scale)
          # --- > kendall´s tau (pred.mvt) with confidence interval
          copula_parameter_intercept <- tail(coef(res$value),2)[1]
          
          copula_parameter <- res$value$theta
          
          # Check fitted bivariate distribution in the MBS model to 
          # compute the correct Kendall's tau:
          #GAUSS copula
          if(res$value$BivD == "N"){
            
            tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
            
          }
          
          # GUMBEL copula
          if(res$value$BivD == "G0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED GUMBEL copula (90)
          if(res$value$BivD == "G90"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            
            tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
            
          }
          
          # CLAYTON copula
          if(res$value$BivD == "C0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED CLAYTON copula (90)
          if(res$value$BivD == "C90"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- - theta_coppar
            
            tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
            
          }
          
          # FRANK copula
          if(copula_class == "F"){
            
            
            signs <- sign(copula_parameter) 
            theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
            theta_coppar <- theta_coppar*signs 
            
            
            tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
            
          }
          
          # JOE copula
          if(res$value$BivD == "J0"){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # ROTATED JOE (90)
          if(res$value$BivD == "J90"){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
          #        Object Vb 
          #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
          #        function of the mvt normal distr. is used to sample from them!
          #        Obtain the following coverages: 90% ,     95%,        99%
          #                                       (1-0.05),  (1-0.025)   (1-0.005)
          
          # Confidence intervals of all coefficients will be obtained via simulations
          # For transformations of the linear predictor (i.e. survival function, etc): 
          # simulation as well as direct transformation of the linear predictor
          
          # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
          # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
          # Compute quantiles from this sample of size R.  
          # Set the number of simulations from the posterior to: 500, default = 200.
          
          # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
          # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
          # Extract coeffs again
          coefficient_vec <- coef(res$value)
          
          # Extract coeffs
          coeff_cov_mat <- res$value$Vb
          
          n.sim <- n.sim
          
          # Samples from the asymptotic distribution of of the coefficient vector
          bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
          
          
          # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
          # using the typical levels
          prob_levels <- c(0.01, 0.05, 0.1)
          
          confints_list <- sapply(prob_levels, 
                                  function(i) matrixStats:::colQuantiles(bs, 
                                                                         probs = c(i/2, 
                                                                                   1 - i/2),
                                                                         na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # For the specific splines:
          # Recover the synthetic values of the covariates:
          # remove other covariates values from the linear predictor: 
          dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
          
          # Obtain various additive predictors: 
          Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
          
          Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
          
          
          # Copula parameter and then into tau:
          dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
          
          XfitCopParam <- predict(res$value, eq = 3, type = "lpmatrix", newdata = dat_ped_ready_copparam)
          
          # Compute xbeta for first margin: 
          fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
          
          # # Compute xbeta for second margin: 
          fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)] )
          
          
          # Compute xbeta for copula parameter:
          fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
          
          
          # Compute now transformation of this: 
          # Binary margin: just the spline: 
          # confints_binary_spline <-sapply(prob_levels,
          #                                 function(i)
          #                                   matrixStats:::rowQuantiles(fit1Sim,
          #                                                              probs = c(i/2, 1 - i/2),
          #                                                              na.rm = TRUE),
          #                                 simplify = FALSE)
          
          # # Survival margin:
          confints_linkscalehazard <- sapply(prob_levels,
                                             function(i)
                                               matrixStats:::rowQuantiles(fit1Sim,
                                                                          probs = c(i/2, 1 - i/2),
                                                                          na.rm = TRUE),
                                             simplify = FALSE)
          
          
          
          confints_hazard <- sapply(prob_levels,
                                    function(i)
                                      matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                                 probs = c(i/2, 1 - i/2),
                                                                 na.rm = TRUE),
                                    simplify = FALSE)
          
          
          # # Compute the cumulative sum correctly:
          fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                   function(i)
                                     cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                   simplify = TRUE)
          
          
          fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                             function(i)
                                               -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                             simplify = TRUE)
          
          
          fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                    function(i)
                                      cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                    simplify = TRUE)
          
          # # Compute quantiles
          confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                                function(i)
                                                  matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                             probs = c(i/2, 1 - i/2),
                                                                             na.rm = TRUE),
                                                simplify = FALSE)
          
          confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                     function(i)
                                                       matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                                  probs = c(i/2, 1 - i/2),
                                                                                  na.rm = TRUE),
                                                     simplify = FALSE)
          
          confints_survival <-  sapply(prob_levels,
                                       function(i)
                                         matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                    probs = c(i/2, 1 - i/2),
                                                                    na.rm = TRUE),
                                       simplify = FALSE)
          
          
          
          
          
          # For the true value: 
          copparam_true_df <- data.frame(Intercept = 1,
                                         x5_true = seq(-1, +1, length.out = 200)
          )
          
          eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
          
          
          
          # Compute confidence intervals for the copula parameter:
          # GAUSS COPULA
          if(res$value$BivD == "N"){
            
            
            copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                     sign(eta_copparam_true) * 8.75, 
                                     eta_copparam_true)
            
            copparam_true <- tanh(copparam_true) 
            
            
            tau_true <-  2 / pi * asin(copparam_true) 
            
            
            ### FOR CONFIDENCE INTERVALS
            # just a vector of values, since the model is currently has only an intercept:
            fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                    sign(fitCopParSim)*8.75, 
                                    fitCopParSim)
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- tanh(fitCopParSim) 
            
            # computation of TAU:
            fitTauSim <-  2 / pi * asin(fitCopParSim) 
            # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
            
          }
          
          
          # CLAYTON COPULA
          if(res$value$BivD == "C0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true ) 
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true ) 
            
            copparam_true <- exp( eta_copparam_true )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                               28, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- tau_true / ( tau_true + 2 ) 
            
            
            
            
            ##############
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
            
          }
          
          
          # ROTATED CLAYTON COPULA (90)
          if(res$value$BivD == "C90"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <-  -( exp( eta_copparam_true ) )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                               28, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
            
            
            
            ###########################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <-  -( exp( fitCopParSim ) )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
            
            
            
          }
          
          
          # GUMBEL COPULA 
          if(res$value$BivD == "G0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp( eta_copparam_true ) + 1   
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                               17, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <-  1 - 1 / tau_true 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim ) + 1   
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <-  1 - 1 / fitTauSim 
            
          }
          
          
          # ROTATED GUMBEL COPULA (90)
          if(res$value$BivD == "G90"){
            
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- -( exp( eta_copparam_true ) + 1  )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                               17, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <-  -( 1 - 1 / abs(tau_true) ) 
            
            
            #############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- -( exp( fitCopParSim ) + 1  )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
            
          }
          
          
          # JOE COPULA
          if(res$value$BivD == "J0"){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp(eta_copparam_true) + 1
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                               30, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            
            tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
            
            
            
            
            ################################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp(fitCopParSim) + 1
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            
            fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
            
            
          }
          
          
          # ROTATED JOE COPULA (90)
          if(res$value$BivD == "J90"){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- - ( exp(eta_copparam_true) + 1 )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                               30, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- - tau_true
            
            tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- - ( exp(fitCopParSim) + 1 )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- - fitTauSim
            
            fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
            
            
          }
          
          
          # FRANK COPULA
          if(res$value$BivD == "F"){
            
            
            epsilon <- c(sqrt(.Machine$double.eps))
            
            eta_copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                     epsilon, 
                                     eta_copparam_true )     
            
            
            signs <- sign(eta_copparam_true) 
            
            eta_copparam_true <- ifelse(abs(eta_copparam_true) > 35, 
                                    35, 
                                    abs(eta_copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            copparam_true <- eta_copparam_true*signs
            
            tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
            
            
            #################
            epsilon <- c(sqrt(.Machine$double.eps))
            
            fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                    epsilon, 
                                    fitCopParSim )     
            
            
            signs <- sign(fitCopParSim) 
            
            fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                   35, 
                                   abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            fitCopParSim <- fitCopParSim*signs
            
            fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
            
            
          }
          
          
          
          
          
          confints_copulaparam <-  sapply(prob_levels,
                                          function(i)
                                            rowQuantiles(fitCopParSim,
                                                         probs = c(i/2, 1 - i/2),
                                                         na.rm = TRUE),
                                          simplify = FALSE)
          
          
          # intervals for KENDALLs TAU:
          confints_tau <-  sapply(prob_levels,
                                  function(i)
                                    rowQuantiles(fitTauSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # Compute the coverages:
          coverage_copula_param <- sapply(confints_copulaparam, function(i) 
            
            mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
            
          )
          
          
          
          coverage_tau <- sapply(confints_tau, function(i) 
            
            mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
            
          )
          
          
          # extract coefficients of nonsurvival margin
          beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
          
          surv_beta_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
          
          copparam_beta_vector <- bs[, (ncol(bs)-1):ncol(bs) ]
          
          # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
          surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals  of each coefficient!
          surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals  of each coefficient!
          surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          
          # Now for the nonsurvival margin:
          nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals
          nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals
          nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          # Compute coverages:
          coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
            
          )
          
          coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
          )
          
          coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
          )
          
          
          
          ########### now for the nonsurvival margin:
          coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
            
          )
          
          coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
            
          )
          
          coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
            
          )
          
          
          
          names(coverage_tau) <- c("99%", "95%", "90%")
          names(coverage_copula_param) <- c("99%", "95%", "90%")
          
          
          
          
          confint_materials <- list(all_coefficients  = confints_list,
                                    linkscale_hazard = confints_linkscalehazard,
                                    hazard = confints_hazard,
                                    cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                    cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                    survival = confints_survival,
                                    copula_param = confints_copulaparam,
                                    kendall_tau = confints_tau, 
                                    #
                                    coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                        ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                        ninetyfive = coverage3_nonsurv_margin),
                                    #
                                    coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                         ninetyseven_pointfive = coverage2_surv_margin,
                                                                         ninetyfive = coverage3_surv_margin),
                                    coverage_tau = coverage_tau,
                                    coverage_copula_parameter = coverage_copula_param
          )
          
          
          
          
          # Put everything together
          output <- list(
            # Coefficients
            coefficients_nonsurv = coefficients_nonsurv_margin,
            coefficients_survival = coefficients_survival_margin,
            coefficients_copula_parameter = coefficients_copula_parameter,
            #
            #
            residuals_materials = residuals_materials,
            #
            # Smooth functions
            #binary_spline = binary_pred_spline,
            linkscale_baseline = baseline_link_scale,
            baseline = baseline_hazard,
            cumu_hazard = cumuhazard_justcumsum,
            cumu_hazard_logoneminus = cumuhazard_logoneminus,
            survival = survivalfunction,
            #
            # copula parameter and dependence
            copula_parameter = copula_parameter,
            tau_of_kendall = tau_of_kendall,
            #
            # Big matrix of coefficient's confidence intervals:
            confint_materials = confint_materials,
            #
            # Various summaries
            survival_data_n = nrow(dataset_long_margin2),
            original_data_n = nrow(original_data),
            edf_nonsurvival_margin = res$value$edf[[2]],
            edf_survival_margin = res$value$edf[[1]],
            #
            #
            #
            # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
            estimated_kendall = res$value$tau,
            copula_parameter_estimate = res$value$theta,
            # some other diagnostics
            cuts_placement_intime = the_used_cuts,
            the_unique_tends = the_unique_tends,
            the_warning = res$warning,
            the_error = res$error,
            model_runtime = model_runtime
          )
          
          
          
          
        }
        
        # This is the output in case of discrete non-survival margins
        if(  NonSurv_Margin %in% c("NBII", "NBI") ){
          
          # extract Goodness of fit residuals from the survival margin: 
          residuals_materials <- compute_relevant_residuals(model = res$value, 
                                                            data_short = original_data, 
                                                            data_long = dataset_long_margin2, 
                                                            type = "DT", 
                                                            indices = INDCS_list, 
                                                            equation_survmodel = 1)
          
          # Evaluate the fitted model:
          # --- > overall coefficients
          coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)]
          
          coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
          
          coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
          
          
          
          # Survival / margin
          # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
          
          # 1: Create rich sequence of time points for the splines
          # 2: Use predict(, type = "terms")
          # 3: Extract the prediction of only the log( baseline hazard )
          # 4: Add the intercept to all observations
          # 5: Transform into hazard rate, 
          # 6: Obtain original interval lengths (all equidistant)  
          # 7: Obtain the cumu hazard, 
          # 8: Transform into survival function.
          # Step 1: 
          time_synth <- 0:number_of_ints
          time_synth2 <- 0:number_of_ints
          
          dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
          
          dat_ped_new$timeInt <- time_synth
          dat_ped_new$timeInt_margin2 <- time_synth
          
          dat_ped_ready <- dat_ped_new %>% 
            mutate(x1 = 0,
                   x2 = 0,
                   x3 = 0,
                   x5 = 0,
                   x4 = 0)
          
          # Step 2 + 3 + 4:
          # Intercept is added
          baseline_link_scale <-  predict(res$value,
                                          eq = 1,
                                          newdata = dat_ped_ready,
                                          type = "terms")[,3] +
            coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
          
          # Step 5:
          baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
          
          # Step 6: not needed in DTS
          
          # Step 7:
          cumuhazard_justcumsum <- cumsum( baseline_hazard  )
          
          cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
          
          # Step 8:
          survivalfunction <- cumprod( 1 - baseline_hazard )
          # 
          # 
          ###########################
          ###########################
          
          estimated_kendall_tau <- res$value$tau
          
          # Copula / dependence part 
          # --- > intercept of model of copula parameter
          # --- > copula parameter (in copula parameter scale)
          # --- > kendall´s tau (pred.mvt) with confidence interval
          copula_parameter_intercept <- tail(coef(res$value),2)[1]
          
          copula_parameter <- res$value$theta
          
          # Check fitted bivariate distribution in the MBS model to 
          # compute the correct Kendall's tau:
          #GAUSS copula
          if(res$value$BivD == "N"){
            
            tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
            
          }
          
          # GUMBEL copula
          if(res$value$BivD == "G0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED GUMBEL copula (90)
          if(res$value$BivD %in% c("G90", "G270")){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            
            tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
            
          }
          
          # CLAYTON copula
          if(res$value$BivD == "C0"){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
            
          }
          
          # ROTATED CLAYTON copula (90)
          if(res$value$BivD %in% c("C90", "C270")){
            
            theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- - theta_coppar
            
            tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
            
          }
          
          # FRANK copula
          if(copula_class == "F"){
            
            
            signs <- sign(copula_parameter) 
            theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
            theta_coppar <- theta_coppar*signs 
            
            
            tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
            
          }
          
          # JOE copula
          if(res$value$BivD == "J0"){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # ROTATED JOE (90)
          if(res$value$BivD %in% c("J90", "J270")){
            
            
            theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                   30, 
                                   abs(copula_parameter)) # based on BiCopPar2Tau 
            
            theta_coppar <- -theta_coppar
            
            tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
            
            
          }
          
          # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
          #        Object Vb 
          #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
          #        function of the mvt normal distr. is used to sample from them!
          #        Obtain the following coverages: 90% ,     95%,        99%
          #                                       (1-0.05),  (1-0.025)   (1-0.005)
          
          # Confidence intervals of all coefficients will be obtained via simulations
          # For transformations of the linear predictor (i.e. survival function, etc): 
          # simulation as well as direct transformation of the linear predictor
          
          # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
          # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
          # Compute quantiles from this sample of size R.  
          # Set the number of simulations from the posterior to: 500, default = 200.
          
          # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
          # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
          # Extract coeffs again
          coefficient_vec <- coef(res$value)
          
          # Extract coeffs
          coeff_cov_mat <- res$value$Vb
          
          n.sim <- n.sim
          
          # Samples from the asymptotic distribution of of the coefficient vector
          bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
          
          
          # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
          # using the typical levels
          prob_levels <- c(0.01, 0.05, 0.1)
          
          confints_list <- sapply(prob_levels, 
                                  function(i) matrixStats:::colQuantiles(bs, 
                                                                         probs = c(i/2, 
                                                                                   1 - i/2),
                                                                         na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # For the specific splines:
          # Recover the synthetic values of the covariates:
          # remove other covariates values from the linear predictor: 
          dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
          
          # Obtain various additive predictors: 
          Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
          
          Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
          
          
          # Copula parameter and then into tau:
          dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
          
          XfitCopParam <- predict(res$value, eq = 4, type = "lpmatrix", newdata = dat_ped_ready_copparam)
          
          # Compute xbeta for first margin: 
          fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
          
          # # Compute xbeta for second margin: 
          fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 4)] )
          
          
          # Compute xbeta for copula parameter:
          fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
          
          
          # Compute now transformation of this: 
          # Binary margin: just the spline: 
          # confints_binary_spline <-sapply(prob_levels,
          #                                 function(i)
          #                                   matrixStats:::rowQuantiles(fit1Sim,
          #                                                              probs = c(i/2, 1 - i/2),
          #                                                              na.rm = TRUE),
          #                                 simplify = FALSE)
          
          # # Survival margin:
          confints_linkscalehazard <- sapply(prob_levels,
                                             function(i)
                                               matrixStats:::rowQuantiles(fit1Sim,
                                                                          probs = c(i/2, 1 - i/2),
                                                                          na.rm = TRUE),
                                             simplify = FALSE)
          
          
          
          confints_hazard <- sapply(prob_levels,
                                    function(i)
                                      matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                                 probs = c(i/2, 1 - i/2),
                                                                 na.rm = TRUE),
                                    simplify = FALSE)
          
          
          # # Compute the cumulative sum correctly:
          fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                   function(i)
                                     cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                   simplify = TRUE)
          
          
          fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                             function(i)
                                               -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                             simplify = TRUE)
          
          
          fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                    function(i)
                                      cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                    simplify = TRUE)
          
          # # Compute quantiles
          confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                                function(i)
                                                  matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                             probs = c(i/2, 1 - i/2),
                                                                             na.rm = TRUE),
                                                simplify = FALSE)
          
          confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                     function(i)
                                                       matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                                  probs = c(i/2, 1 - i/2),
                                                                                  na.rm = TRUE),
                                                     simplify = FALSE)
          
          confints_survival <-  sapply(prob_levels,
                                       function(i)
                                         matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                    probs = c(i/2, 1 - i/2),
                                                                    na.rm = TRUE),
                                       simplify = FALSE)
          
          
          
          
          
          # For the true value: 
          copparam_true_df <- data.frame(Intercept = 1,
                                         x5_true = seq(-1, +1, length.out = 200)
          )
          
          eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
          
          
          
          # Compute confidence intervals for the copula parameter:
          # GAUSS COPULA
          if(res$value$BivD == "N"){
            
            
            copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                     sign(eta_copparam_true) * 8.75, 
                                     eta_copparam_true)
            
            copparam_true <- tanh(copparam_true) 
            
            
            tau_true <-  2 / pi * asin(copparam_true) 
            
            
            ### FOR CONFIDENCE INTERVALS
            # just a vector of values, since the model is currently has only an intercept:
            fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                    sign(fitCopParSim)*8.75, 
                                    fitCopParSim)
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- tanh(fitCopParSim) 
            
            # computation of TAU:
            fitTauSim <-  2 / pi * asin(fitCopParSim) 
            # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
            
          }
          
          
          # CLAYTON COPULA
          if(res$value$BivD == "C0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true ) 
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true ) 
            
            copparam_true <- exp( eta_copparam_true )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                               28, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- tau_true / ( tau_true + 2 ) 
            
            
            
            
            ##############
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
            
          }
          
          
          # ROTATED CLAYTON COPULA (90)
          if(res$value$BivD %in% c("C90", "C270")){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <-  -( exp( eta_copparam_true ) )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 28, 
                               28, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
            
            
            
            ###########################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <-  -( exp( fitCopParSim ) )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                                28, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
            
            
            
          }
          
          
          # GUMBEL COPULA 
          if(res$value$BivD == "G0"){
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp( eta_copparam_true ) + 1   
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                               17, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <-  1 - 1 / tau_true 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp( fitCopParSim ) + 1   
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <-  1 - 1 / fitTauSim 
            
          }
          
          
          # ROTATED GUMBEL COPULA (90)
          if(res$value$BivD %in% c("G90", "G270")){
            
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- -( exp( eta_copparam_true ) + 1  )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 17, 
                               17, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- -tau_true
            
            tau_true <-  -( 1 - 1 / abs(tau_true) ) 
            
            
            #############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- -( exp( fitCopParSim ) + 1  )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                                17, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- -fitTauSim
            
            fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
            
          }
          
          
          # JOE COPULA
          if(res$value$BivD == "J0"){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- exp(eta_copparam_true) + 1
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                               30, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            
            tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
            
            
            
            
            ################################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- exp(fitCopParSim) + 1
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            
            fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
            
            
          }
          
          
          # ROTATED JOE COPULA (90)
          if(res$value$BivD %in% c("J90", "J270")){
            
            
            eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                         20, 
                                         eta_copparam_true )     # 709, maximum allowed # these values look fine
            
            eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                         -17, 
                                         eta_copparam_true )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            copparam_true <- - ( exp(eta_copparam_true) + 1 )
            
            # computation of TAU:
            tau_true <- ifelse(abs(copparam_true) > 30, 
                               30, 
                               abs(copparam_true)) # based on BiCopPar2Tau 
            
            tau_true <- - tau_true
            
            tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
            
            
            ##############################
            fitCopParSim <- ifelse( fitCopParSim > 20, 
                                    20, 
                                    fitCopParSim )     # 709, maximum allowed # these values look fine
            
            fitCopParSim <- ifelse( fitCopParSim < -17, 
                                    -17, 
                                    fitCopParSim )   # -20                  # 
            
            
            # compute copula parameter from the additive predictor of
            # the copula parameter:
            fitCopParSim <- - ( exp(fitCopParSim) + 1 )
            
            # computation of TAU:
            fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                                30, 
                                abs(fitCopParSim)) # based on BiCopPar2Tau 
            
            fitTauSim <- - fitTauSim
            
            fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
            
            
          }
          
          
          # FRANK COPULA
          if(res$value$BivD == "F"){
            
            
            epsilon <- c(sqrt(.Machine$double.eps))
            
            eta_copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                         epsilon, 
                                         eta_copparam_true )     
            
            
            signs <- sign(eta_copparam_true) 
            
            eta_copparam_true <- ifelse(abs(eta_copparam_true) > 35, 
                                        35, 
                                        abs(eta_copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            copparam_true <- eta_copparam_true*signs
            
            tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
            
            
            #################
            epsilon <- c(sqrt(.Machine$double.eps))
            
            fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                    epsilon, 
                                    fitCopParSim )     
            
            
            signs <- sign(fitCopParSim) 
            
            fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                   35, 
                                   abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
            
            fitCopParSim <- fitCopParSim*signs
            
            fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
            
            
          }
          
          
          
          
          
          confints_copulaparam <-  sapply(prob_levels,
                                          function(i)
                                            rowQuantiles(fitCopParSim,
                                                         probs = c(i/2, 1 - i/2),
                                                         na.rm = TRUE),
                                          simplify = FALSE)
          
          
          # intervals for KENDALLs TAU:
          confints_tau <-  sapply(prob_levels,
                                  function(i)
                                    rowQuantiles(fitTauSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                  simplify = FALSE)
          
          
          
          # Compute the coverages:
          coverage_copula_param <- sapply(confints_copulaparam, function(i) 
            
            mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
            
          )
          
          
          
          coverage_tau <- sapply(confints_tau, function(i) 
            
            mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
            
          )
          
          
          # extract coefficients of nonsurvival margin
          beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 4) ]
          
          surv_beta_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
          
          copparam_beta_vector <- bs[, (ncol(bs)-1):ncol(bs) ]
          
          # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
          surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals  of each coefficient!
          surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals  of each coefficient!
          surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
            quantile(surv_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          
          # Now for the nonsurvival margin:
          nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          # This returns a list with the 95% confidence intervals
          nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          # This returns a list with the 90% confidence intervals
          nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
            quantile(beta_nonsurv_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.01/2, 1 - 0.01/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.05/2, 1 - 0.05/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
            quantile(copparam_beta_vector[,i],
                     probs = c(0.10/2, 1 - 0.10/2),
                     na.rm = TRUE),
            simplify = FALSE
          )
          
          
          
          # Compute coverages:
          coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
            
          )
          
          coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
          )
          
          coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                    surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
          )
          
          
          
          ########### now for the nonsurvival margin:
          coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
            
          )
          
          coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
            
          )
          
          coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
            
            #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
            1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                    nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
            
          )
          
          
          
          names(coverage_tau) <- c("99%", "95%", "90%")
          names(coverage_copula_param) <- c("99%", "95%", "90%")
          
          
          
          
          confint_materials <- list(all_coefficients  = confints_list,
                                    linkscale_hazard = confints_linkscalehazard,
                                    hazard = confints_hazard,
                                    cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                    cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                    survival = confints_survival,
                                    copula_param = confints_copulaparam,
                                    kendall_tau = confints_tau, 
                                    #
                                    coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                        ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                        ninetyfive = coverage3_nonsurv_margin),
                                    #
                                    coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                         ninetyseven_pointfive = coverage2_surv_margin,
                                                                         ninetyfive = coverage3_surv_margin),
                                    coverage_tau = coverage_tau,
                                    coverage_copula_parameter = coverage_copula_param
          )
          
          
          
          
          # Put everything together
          output <- list(
            # Coefficients
            coefficients_nonsurv = coefficients_nonsurv_margin,
            coefficients_survival = coefficients_survival_margin,
            coefficients_copula_parameter = coefficients_copula_parameter,
            #
            #
            residuals_materials = residuals_materials,
            #
            # Smooth functions
            #binary_spline = binary_pred_spline,
            linkscale_baseline = baseline_link_scale,
            baseline = baseline_hazard,
            cumu_hazard = cumuhazard_justcumsum,
            cumu_hazard_logoneminus = cumuhazard_logoneminus,
            survival = survivalfunction,
            #
            # copula parameter and dependence
            copula_parameter = copula_parameter,
            tau_of_kendall = tau_of_kendall,
            #
            # Big matrix of coefficient's confidence intervals:
            confint_materials = confint_materials,
            #
            # Various summaries
            survival_data_n = nrow(dataset_long_margin2),
            original_data_n = nrow(original_data),
            edf_nonsurvival_margin = res$value$edf[[2]],
            edf_survival_margin = res$value$edf[[1]],
            #
            #
            #
            # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
            estimated_kendall = res$value$tau,
            copula_parameter_estimate = res$value$theta,
            # some other diagnostics
            cuts_placement_intime = the_used_cuts,
            the_unique_tends = the_unique_tends,
            the_warning = res$warning,
            the_error = res$error,
            model_runtime = model_runtime
          )
          
          
          
          
        }
        
        
      }
      
      
    }else{
      
      output <- list(the_warning = res$warning,
                     the_error = res$error)
      
    }
  
  rm(res)
  
  return(output)
}




# The fitting function:
fit_MXS_PWE <- function(original_data_object, 
                    copula_class = "N", 
                    # non-survival marginal response
                    NonSurv_Margin = "N",
                    # cuts / intervals
                    number_of_ints = 15, 
                    #
                    maximum_time_cut = 4.6,
                    #
                    varying_dependence = FALSE,
                    # smooth the baseline function of time on time scale or log(time) scale
                    baseline_smooth = "log",
                    # for confidence intervals
                    n.sim = 500,
                    # further arguments
                    hess_reg = "t"
){
  
  original_data <- original_data_object$dataset
  
  # extra reg settings:
  extra.regularization <- hess_reg
  
  
  the_used_cuts <- seq(from = 0,  
                       to = maximum_time_cut, 
                       length.out = number_of_ints)
  
  
  # Create augmented dataset for piecewise exponential margin!
  dat_ped <- as_ped(Surv(time, status) ~ x1 + x2 + x3 + x4 + x5, 
                    cut = seq(from = 0, 
                              #to = max(original_data$time), 
                              to = maximum_time_cut, 
                              length.out = number_of_ints),
                    data = original_data)
  
  the_used_cuts <- seq(from = 0, 
                       to = maximum_time_cut, 
                       length.out = number_of_ints)
  
  the_unique_tends <- unique(dat_ped$tend)
  
  
  # declare IDs as factor:
  dat_ped$id <- factor(dat_ped$id)
  
  # Create list of indices: (ABSOLUTELY NECESSARY FOR MBS)
  INDCS_list <- sapply(levels(dat_ped$id), 
                       function(i) which(dat_ped$id == i), 
                       simplify = FALSE)
  
  
  # attach ped_status in the model:
  # this is to trick GJRM into fitting!
  original_data$ped_status <- unlist(lapply(INDCS_list, function(i) tail(i, 1)))
  original_data$tend <- dat_ped$tend[original_data$ped_status]
  
  dataset_long_margin2 <- dat_ped
  
  
  
  ###########################################################################################################
  # PWE formula, i.e. smooth baseline hazard using splines
  PWE_formula <- as.formula(ped_status ~ s(tend, bs = "ps", m = 2, k = 10) 
                            + x2 
                            + x4
                            #+ s(x4, bs = "ps", m = 2, k = 20) 
  )
  
  # smooth time on the log() scale (for smoother results)
  PWE_log_formula <- as.formula(ped_status ~ s(log(tend), bs = "ps", m = 2, k = 10) 
                                + x2 
                                + x4
                                #+ s(x4, bs = "ps", m = 2, k = 20) 
  )
  
  
  # Formula for dependence parameter (necessary in some cases)
  if(varying_dependence){
    
    Copula_param_formula <- as.formula( ~ 1 + x5)
    
  }else{
    
    Copula_param_formula <- as.formula( ~ 1)
  }
  
  
  #### CONTINUOUS
  # Gaussian
  if(NonSurv_Margin == "N"){
    
    MXS_margins <- c("PO", "N")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(PWE_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(PWE_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
    }
    
  }
  

  
  # Log-normal
  if(NonSurv_Margin == "LN"){
    MXS_margins <- c("PO", "LN")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(PWE_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(PWE_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
    }
    
  }
  
  # Logistic
  if(NonSurv_Margin == "LO"){
    
    MXS_margins <- c("PO", "LO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(PWE_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(PWE_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
    }
    
  }
  
  # Beta
  if(NonSurv_Margin == "BE"){
    
    MXS_margins <- c("PO", "BE")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(PWE_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(PWE_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
    }
    
  }
  
  # Log-logistic
  if(NonSurv_Margin == "FISK"){
    
    MXS_margins <- c("PO", "FISK")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(PWE_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(PWE_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
    }
    
  }
  
  # Dagum
  if(NonSurv_Margin == "DAGUM"){
    
    MXS_margins <- c("PO", "DAGUM")
    
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    NonSurv_Mar_Param3_formula <- as.formula( ~ 1)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          NonSurv_Mar_Param3_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          NonSurv_Mar_Param3_formula,
                          Copula_param_formula)
      
    }
    
    
  }
  
  
  #### DISCRETE 
  # Poisson
  if(NonSurv_Margin == "PO"){
    
    MXS_margins <- c("PO", "PO")
    
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(PWE_log_formula,
                          NonSurv_Mar_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(PWE_formula,
                          NonSurv_Mar_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Negative binomial I 
  if(NonSurv_Margin == "NBI"){
    
    MXS_margins <- c("PO", "NBI")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~ x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(PWE_log_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(PWE_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
    
  }
  
  # Negative binomial II
  if(NonSurv_Margin == "NBII"){
   
    MXS_margins <- c("PO", "NBII")
    
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~ x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(PWE_log_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(PWE_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
    
  }
  
  
  #### BINARY 
  # Logit
  if(NonSurv_Margin == "logit"){
    
    MXS_margins <- c("logit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          PWE_log_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          PWE_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Probit
  if(NonSurv_Margin == "probit"){
    
    MXS_margins <- c("probit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          PWE_log_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          PWE_formula,
                          Copula_param_formula)
      
    }
    
  }
  
  # Clog log 
  if(NonSurv_Margin == "cloglog"){
    
    MXS_margins <- c("cloglog", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          PWE_log_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          PWE_formula,
                          Copula_param_formula)
      
    }
  }
  
  # GEV link
  if(NonSurv_Margin == "GEVlink"){
    
    MXS_margins <- c("GEVlink", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula,
                          Copula_param_formula)
      
    }
  }
  
  
  
  # FIT:
  # Control for the computation time as well 
  model_runtime <- system.time(
    res <- myTryCatch(
      gjrm(
        MXS_formula, 
        data = original_data, 
        BivD = copula_class,      
        # This is MBS with either DTS or PWE margin
        margins = MXS_margins,# Combination of margins
        Model = "B",
        # List of subject ids
        ListOfIDs = INDCS_list,
        # PWE format dataset (long)
        PAMM_dataset = dataset_long_margin2,
        # Offset for PWE margin
        PAMM_offset = dataset_long_margin2$offset,
        # further arguments
        gc.l = FALSE,
        extra.regI = extra.regularization)
    )
  )
  
  
  
  # Check if the model was actually fitted and there is an output!
  if(!is.null(res$value)){
    
    if( !(varying_dependence) ){
    
    if(NonSurv_Margin == "N"){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      # --- > all prediction points of the spline in 100, equidistant points!
      
      #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      model_coefficients <- coef(res$value)
      
      
      kendall_binary_PWE <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- 200
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels, 
      #                                 function(i) 
      #                                   matrixStats:::rowQuantiles(fit1Sim, 
      #                                                              probs = c(i/2, 1 - i/2), 
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      # 
      # # PWE margin:
      # confints_loghazard <- sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(fit2Sim, 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      # 
      # 
      # confints_hazard <- sapply(prob_levels, 
      #                           function(i) 
      #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
      #                                                        probs = c(i/2, 1 - i/2), 
      #                                                        na.rm = TRUE),
      #                           simplify = FALSE)
      # 
      # 
      # # Compute the cumulative sum correctily:
      # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
      #                          function(i) 
      #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
      #                          simplify = TRUE)
      # 
      # # Compute quantiles
      # confints_cumuhazard <-  sapply(prob_levels, 
      #                                function(i) 
      #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
      #                                                             probs = c(i/2, 1 - i/2), 
      #                                                             na.rm = TRUE),
      #                                simplify = FALSE)
      # 
      # 
      # confints_survival <-  sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      # confint_materials <- list(all_coefficients  = confints_list, 
      #                           binary_spline = confints_binary_spline, 
      #                           loghazard = confints_loghazard, 
      #                           hazard = confints_loghazard, 
      #                           cumuhazard = confints_cumuhazard, 
      #                           survival = confints_survival,
      #                           copula_param = confints_copulaparam,
      #                           kendall_tau = confints_tau)
      
      coverages_materials <-list(tau = coverage_tau,
                                 copula_parameter = coverage_copula_param,
                                 beta_nonsurv_margin = NULL,
                                 beta_surv_margin = NULL)
      
      
      output <- list(model_coefficients = model_coefficients,
                     confints = coverages_materials,
                     estimated_copula_parameter = res$value$theta,
                     estimated_kendall_tau = res$value$tau, 
                     nrow_datalong = dim(dataset_long_margin2))
      
      
      
    }
    
    # This is the output in case of binary non-survival margins
    if( NonSurv_Margin %in% c("logit", "probit", "cloglog", "GEVlink") ){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ]
      
      coefficients_survival_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      
      copula_parameter_intercept <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[3]):(length(coef(res$value)))]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <-  seq(from = 0, 
                         to = maximum_time_cut, 
                         length.out = number_of_ints)
      
      time_synth2 <-  seq(from = 0, 
                          to = maximum_time_cut, 
                          length.out = number_of_ints)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$tend <- time_synth
      dat_ped_new$tend_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0)
      
      # Remove the zero here!!!
      dat_ped_ready <- make_newdata(dataset_long_margin2,
                                       tend = time_synth[-1]) %>%  mutate(x1 = 0,
                                                                          x2 = 0,
                                                                          x3 = 0,
                                                                          x5 = 0,
                                                                          x4 = 0)
      
      dat_ped_ready2 <- dat_ped_ready
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <-  predict(res$value,
                                      eq = 2,
                                      newdata = dat_ped_ready2,
                                      type = "terms")[,3] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]
      
      # Step 5:
      baseline_hazard <- exp( baseline_link_scale )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard * exp(dat_ped_ready2$offset)  )
      
      cumuhazard_logoneminus <- NULL
      
      # Step 8:
      survivalfunction <- exp(- cumuhazard_justcumsum )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_ready %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] )
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit2Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles( exp( fit2Sim ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                               function(i)
                                 cumsum( exp(fit2Sim[,i] ) * exp(dat_new$offset)  ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- NULL
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                function(i)
                                 exp( -  cumsum( exp(fit2Sim[,i] ) * exp(dat_new$offset)  ) ),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <- NULL
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      surv_beta_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
      
      
      # This returns a list with the 99% confidence intervals
      surv_marg_confints1 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      surv_marg_confints2 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      surv_marg_confints3 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(surv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage2_surv_margin <- sapply(surv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage3_surv_margin <- sapply(surv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(nonsurv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage2_nonsurv_margin <- sapply(nonsurv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage3_nonsurv_margin <- sapply(nonsurv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                #binary_spline = confints_binary_spline,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                #
                                coverage_beta_nonsurv_margin = list(coverage1_nonsurv_margin,
                                                                    coverage2_nonsurv_margin,
                                                                    coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(coverage1_surv_margin,
                                                                     coverage2_surv_margin,
                                                                     coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      # coverages_materials <-list(tau = coverage_tau,
      #                            copula_parameter = coverage_copula_param,
      #                            beta_nonsurv_margin = NULL,
      #                            beta_surv_margin = NULL)
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        copula_parameter_intercept = copula_parameter_intercept,
        #
        # Smooth functions
        #binary_spline = binary_pred_spline,
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
      
      # output <- list(estimated_copula_parameter = res$value$theta,
      #                estimated_kendall_tau = res$value$tau,
      #                copula_type = copula_class,
      #                coverages = coverages_materials,
      #                correlation_materials = original_data_object$correlations_materials
      # )
      
      
      
    }
    
    
    # This is the output in case of count non-survival margins
    if( NonSurv_Margin == "PO" ){
        
        # Evaluate the fitted model:
        # --- > overall coefficients
        coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)]
        
        coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
        
        copula_parameter_intercept <- coef(res$value)[length(coef(res$value))]
        
        
        
        # Survival / margin
        # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
        
        # 1: Create rich sequence of time points for the splines
        # 2: Use predict(, type = "terms")
        # 3: Extract the prediction of only the log( baseline hazard )
        # 4: Add the intercept to all observations
        # 5: Transform into hazard rate, 
        # 6: Obtain original interval lengths (all equidistant)  
        # 7: Obtain the cumu hazard, 
        # 8: Transform into survival function.
        # Step 1: 
        time_synth <-  seq(from = 0, 
                           to = maximum_time_cut, 
                           length.out = number_of_ints)
        
        time_synth2 <-  seq(from = 0, 
                            to = maximum_time_cut, 
                            length.out = number_of_ints)
        
        dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
        
        dat_ped_new$tend <- time_synth
        dat_ped_new$tend_margin2 <- time_synth
        
        dat_ped_ready <- dat_ped_new %>% 
          mutate(x1 = 0,
                 x2 = 0,
                 x3 = 0,
                 x5 = 0,
                 x4 = 0)
        
        # Remove the zero here!!!
        dat_ped_ready <- make_newdata(dataset_long_margin2,
                                      tend = time_synth[-1]) %>%  mutate(x1 = 0,
                                                                         x2 = 0,
                                                                         x3 = 0,
                                                                         x5 = 0,
                                                                         x4 = 0)
        
        dat_ped_ready2 <- dat_ped_ready
        
        # Step 2 + 3 + 4:
        # Intercept is added
        baseline_link_scale <-  predict(res$value,
                                        eq = 1,
                                        newdata = dat_ped_ready2,
                                        type = "terms")[,3] +
          coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
        
        
        # Step 5:
        baseline_hazard <- exp( baseline_link_scale )
        
        # Step 6: not needed in DTS
        
        # Step 7:
        cumuhazard_justcumsum <- cumsum( baseline_hazard * exp(dat_ped_ready2$offset)  )
        
        cumuhazard_logoneminus <- NULL
        
        # Step 8:
        survivalfunction <- exp(  - cumuhazard_justcumsum )
        # 
        # 
        ###########################
        ###########################
        
        estimated_kendall_tau <- res$value$tau
        
        # Copula / dependence part 
        # --- > intercept of model of copula parameter
        # --- > copula parameter (in copula parameter scale)
        # --- > kendall´s tau (pred.mvt) with confidence interval
        copula_parameter_intercept <- tail(coef(res$value),1)
        
        copula_parameter <- res$value$theta
        
        # Check fitted bivariate distribution in the MBS model to 
        # compute the correct Kendall's tau:
        #GAUSS copula
        if(res$value$BivD == "N"){
          
          tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
          
        }
        
        # GUMBEL copula
        if(res$value$BivD == "G0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED GUMBEL copula (90)
        if(res$value$BivD == "G90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          
          tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
          
        }
        
        # CLAYTON copula
        if(res$value$BivD == "C0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED CLAYTON copula (90)
        if(res$value$BivD == "C90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- - theta_coppar
          
          tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
          
        }
        
        # FRANK copula
        if(copula_class == "F"){
          
          
          signs <- sign(copula_parameter) 
          theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
          theta_coppar <- theta_coppar*signs 
          
          
          tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
          
        }
        
        # JOE copula
        if(res$value$BivD == "J0"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # ROTATED JOE (90)
        if(res$value$BivD == "J90"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
        #        Object Vb 
        #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
        #        function of the mvt normal distr. is used to sample from them!
        #        Obtain the following coverages: 90% ,     95%,        99%
        #                                       (1-0.05),  (1-0.025)   (1-0.005)
        
        # Confidence intervals of all coefficients will be obtained via simulations
        # For transformations of the linear predictor (i.e. survival function, etc): 
        # simulation as well as direct transformation of the linear predictor
        
        # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
        # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
        # Compute quantiles from this sample of size R.  
        # Set the number of simulations from the posterior to: 500, default = 200.
        
        # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
        # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
        # Extract coeffs again
        coefficient_vec <- coef(res$value)
        
        # Extract coeffs
        coeff_cov_mat <- res$value$Vb
        
        n.sim <- n.sim
        
        # Samples from the asymptotic distribution of of the coefficient vector
        bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
        
        
        # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
        # using the typical levels
        prob_levels <- c(0.01, 0.05, 0.1)
        
        confints_list <- sapply(prob_levels, 
                                function(i) matrixStats:::colQuantiles(bs, 
                                                                       probs = c(i/2, 
                                                                                 1 - i/2),
                                                                       na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # For the specific splines:
        # Recover the synthetic values of the covariates:
        # remove other covariates values from the linear predictor: 
        dat_new <- dat_ped_ready %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
        
        # Obtain various additive predictors: 
        Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
        
        Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
        
        # Compute xbeta for first margin: 
        fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
        
        # # Compute xbeta for second margin: 
        fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] )
        
        # Compute xbeta for copula parameter:
        fitCopParSim <- bs[,length(coefficient_vec)]
        
        # Compute now transformation of this: 
        # Binary margin: just the spline: 
        # confints_binary_spline <-sapply(prob_levels,
        #                                 function(i)
        #                                   matrixStats:::rowQuantiles(fit1Sim,
        #                                                              probs = c(i/2, 1 - i/2),
        #                                                              na.rm = TRUE),
        #                                 simplify = FALSE)
        
        # # Survival margin:
        confints_linkscalehazard <- sapply(prob_levels,
                                           function(i)
                                             matrixStats:::rowQuantiles(fit1Sim,
                                                                        probs = c(i/2, 1 - i/2),
                                                                        na.rm = TRUE),
                                           simplify = FALSE)
        
        
        
        confints_hazard <- sapply(prob_levels,
                                  function(i)
                                    matrixStats:::rowQuantiles(exp( fit1Sim ),
                                                               probs = c(i/2, 1 - i/2),
                                                               na.rm = TRUE),
                                  simplify = FALSE)
        
        
        # # Compute the cumulative sum correctly:
        fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                 function(i)
                                   cumsum( exp(fit1Sim[,i] ) * exp(dat_ped_ready2$offset) ),
                                 simplify = TRUE)
        
        
        fit2Sim_minuslogoneminus <- NULL
        
        
        fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                  function(i)
                                     exp( - cumsum( exp(fit1Sim[,i] ) * exp(dat_ped_ready2$offset) ) ),
                                  simplify = TRUE)
        
        # # Compute quantiles
        confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                              function(i)
                                                matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                           probs = c(i/2, 1 - i/2),
                                                                           na.rm = TRUE),
                                              simplify = FALSE)
        
        confints_cumuhazard_logoneminus <-  NULL
        
        confints_survival <-  sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
        
        
        
        # Compute confidence intervals for the copula parameter:
        # GAUSS COPULA
        if(res$value$BivD == "N"){
          
          # just a vector of values, since the model is currently has only an intercept:
          fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                  sign(fitCopParSim)*8.75, 
                                  fitCopParSim)
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- tanh(fitCopParSim) 
          
          # computation of TAU:
          fitTauSim <-  2 / pi * asin(fitCopParSim) 
          # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
          
        }
        
        
        # CLAYTON COPULA
        if(res$value$BivD == "C0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
          
        }
        
        
        # ROTATED CLAYTON COPULA (90)
        if(res$value$BivD == "C90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <-  -( exp( fitCopParSim ) )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
          
          
          
        }
        
        
        # GUMBEL COPULA 
        if(res$value$BivD == "G0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim ) + 1   
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <-  1 - 1 / fitTauSim 
          
        }
        
        
        # ROTATED GUMBEL COPULA (90)
        if(res$value$BivD == "G90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- -( exp( fitCopParSim ) + 1  )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
          
        }
        
        
        # JOE COPULA
        if(res$value$BivD == "J0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp(fitCopParSim) + 1
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          
          fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
          
          
        }
        
        
        # ROTATED JOE COPULA (90)
        if(res$value$BivD == "J90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- - ( exp(fitCopParSim) + 1 )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- - fitTauSim
          
          fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
          
          
        }
        
        
        # FRANK COPULA
        if(res$value$BivD == "F"){
          
          epsilon <- c(sqrt(.Machine$double.eps))
          
          fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                  epsilon, 
                                  fitCopParSim )     
          
          
          signs <- sign(fitCopParSim) 
          
          fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                 35, 
                                 abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
          
          fitCopParSim <- fitCopParSim*signs
          
          fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
          
          
        }
        
        
        
        
        
        confints_copulaparam <-  sapply(prob_levels,
                                        function(i)
                                          quantile(fitCopParSim,
                                                   probs = c(i/2, 1 - i/2),
                                                   na.rm = TRUE),
                                        simplify = FALSE)
        
        
        # intervals for KENDALLs TAU:
        confints_tau <-  sapply(prob_levels,
                                function(i)
                                  quantile(fitTauSim,
                                           probs = c(i/2, 1 - i/2),
                                           na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # Compute the coverages:
        coverage_copula_param <- sapply(confints_copulaparam, function(i) 
          
          lies_in_interval(original_data_object$true_copula_param, i)
          
        )
        
        coverage_tau <- sapply(confints_tau, function(i) 
          
          lies_in_interval(original_data_object$original_tau, i)
          
        )
        
        
        # extract coefficients of nonsurvival margin
        beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
        
        surv_beta_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
        
        
        # This returns a list with the 99% confidence intervals
        surv_marg_confints1 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        surv_marg_confints2 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        surv_marg_confints3 <- sapply(1:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        
        # Now for the nonsurvival margin:
        
        nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # Compute coverages:
        coverage1_surv_margin <- sapply(surv_marg_confints1, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        coverage2_surv_margin <- sapply(surv_marg_confints2, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        coverage3_surv_margin <- sapply(surv_marg_confints3, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          
        )
        
        
        ########### now for the nonsurvival margin:
        coverage1_nonsurv_margin <- sapply(nonsurv_marg_confints1, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          
        )
        
        coverage2_nonsurv_margin <- sapply(nonsurv_marg_confints2, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          
        )
        
        coverage3_nonsurv_margin <- sapply(nonsurv_marg_confints3, function(i) 
          
          lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          
        )
        
        
        
        names(coverage_tau) <- c("99%", "95%", "90%")
        names(coverage_copula_param) <- c("99%", "95%", "90%")
        
        
        
        
        confint_materials <- list(all_coefficients  = confints_list,
                                  #binary_spline = confints_binary_spline,
                                  linkscale_hazard = confints_linkscalehazard,
                                  hazard = confints_hazard,
                                  cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                  cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                  survival = confints_survival,
                                  copula_param = confints_copulaparam,
                                  kendall_tau = confints_tau, 
                                  #
                                  coverage_beta_nonsurv_margin = list(coverage1_nonsurv_margin,
                                                                      coverage2_nonsurv_margin,
                                                                      coverage3_nonsurv_margin),
                                  #
                                  coverage_beta_survival_margin = list(coverage1_surv_margin,
                                                                       coverage2_surv_margin,
                                                                       coverage3_surv_margin),
                                  coverage_tau = coverage_tau,
                                  coverage_copula_parameter = coverage_copula_param
        )
        
        # coverages_materials <-list(tau = coverage_tau,
        #                            copula_parameter = coverage_copula_param,
        #                            beta_nonsurv_margin = NULL,
        #                            beta_surv_margin = NULL)
        
        # Put everything together
        output <- list(
          # Coefficients
          coefficients_nonsurv = coefficients_nonsurv_margin,
          coefficients_survival = coefficients_survival_margin,
          copula_parameter_intercept = copula_parameter_intercept,
          #
          # Smooth functions
          #binary_spline = binary_pred_spline,
          linkscale_baseline = baseline_link_scale,
          baseline = baseline_hazard,
          cumu_hazard = cumuhazard_justcumsum,
          cumu_hazard_logoneminus = cumuhazard_logoneminus,
          survival = survivalfunction,
          #
          # copula parameter and dependence
          copula_parameter = copula_parameter,
          tau_of_kendall = tau_of_kendall,
          #
          # Big matrix of coefficient's confidence intervals:
          confint_materials = confint_materials,
          #
          # Various summaries
          survival_data_n = nrow(dataset_long_margin2),
          original_data_n = nrow(original_data),
          edf_nonsurvival_margin = res$value$edf[[2]],
          edf_survival_margin = res$value$edf[[1]],
          #
          #
          #
          # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
          estimated_kendall = res$value$tau,
          copula_parameter_estimate = res$value$theta,
          # some other diagnostics
          cuts_placement_intime = the_used_cuts,
          the_unique_tends = the_unique_tends,
          the_warning = res$warning,
          the_error = res$error,
          model_runtime = model_runtime
        )
      
      
    }
    
    
    if(NonSurv_Margin %in% c("NBI", "NBII") ){
      
      output <- list(the_warning = res$warning, 
                     the_error = res$error)
      
    }else{
    
    # Evaluate the fitted model:
    
    # --- > overall coefficients
    # --- > all prediction points of the spline in 100, equidistant points!
    
    # CODE FOR EXTRACTING THINGS FROM BINARY MARGIN: 
    # Extract coefficients
    coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
    
    # create artificial covariate values to evaluate the fitted spline!
    # Edges of covariate space are not considered here!
    x_synth <- seq(-0.999, +0.999, length.out = 200)
    
    # insert this synthetic covariate in the original dataset (used for binary margin)
    # only take the first 100 observations
    dat_new <- original_data[1:length(x_synth), ]
    
    # x3 is the covariate used for the spline
    dat_new$x3 <- x_synth
    
    # predict the particular covariate: (should always be in the third column)
    #nonsurv_margin_pred_spline <- predict(res$value, eq = 1, newdata = dat_new, type = "terms")[, 3]
    
    
    
    # Survival / margin
    # --- > overall coefficients
    # --- > all prediction points of the spline in 100, equidistant points! (baseline hazard)
    
    # CODE FOR EXTRACTING THINGS FROM PWE MARGIN:
    coefficients_survmargin <- coef(res$value)[1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)]
    
    
    ###########################
    ###########################
    
    # 1: Create rich sequence of time points for the splines
    # 2: Use predict(, type = "terms")
    # 3: Extract the prediction of only the log( baseline hazard )
    # 4: Add the intercept to all observations
    # 5: Transform into hazard rate, 
    # 6: Obtain original interval lengths (all equidistant)  
    # 7: Obtain the cumu hazard, 
    # 8: Transform into survival function.
    # Step 1: 
    time_synth <- seq(0, 19.5, length.out = 100)
    time_synth2 <- seq(0, 11, length.out = 100)
    
    dat_ped_new <- dataset_long_margin2[1:100, ]
    
    dat_ped_new$timeInt <- time_synth
    dat_ped_new$timeInt_margin2 <- time_synth
    
    dat_ped_ready <- dat_ped_new %>% 
      mutate(x1 = 0,
             x2 = 0,
             x3 = 0,
             x5 = 0,
             x4 = 0)
    
    # Step 2 + 3 + 4:
    # Intercept is added
    # cloglog_baseline <-  predict(res$value, 
    #                              eq = 2,
    #                              newdata = dat_ped_ready,
    #                              type = "terms")[,3] + 
    #   coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]
    # 
    # # Step 5:
    # pwe_baseline <- 1-exp( -exp( cloglog_baseline ) )
    # 
    # # Step 6: not needed in DTS
    # 
    # # Step 7:
    # pwe_cumuhazard <- cumsum( pwe_baseline  )
    # 
    # # Step 8: 
    # pwe_surv <- cumprod( 1 - pwe_baseline )
    # 
    # 
    ###########################
    ###########################
    
    kendall_binary_PWE <- res$value$tau
    
    # Copula / dependence part 
    # --- > intercept of model of copula parameter
    # --- > copula parameter (in copula parameter scale)
    # --- > kendall´s tau (pred.mvt) with confidence interval
    copula_parameter_intercept <- tail(coef(res$value),1)
    copula_parameter <- res$value$theta
    
    # Check fitted bivariate distribution in the MBS model to 
    # compute the correct Kendall's tau:
    #GAUSS copula
    if(res$value$BivD == "N"){
      
      tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
      
    }
    
    # GUMBEL copula
    if(res$value$BivD == "G0"){
      
      theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                             abs(copula_parameter)) # based on BiCopPar2Tau 
      
      tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
      
    }
    
    # ROTATED GUMBEL copula (90)
    if(res$value$BivD == "G90"){
      
      theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                             abs(copula_parameter)) # based on BiCopPar2Tau 
      
      theta_coppar <- -theta_coppar
      
      
      tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
      
    }
    
    # CLAYTON copula
    if(res$value$BivD == "C0"){
      
      theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                             abs(copula_parameter)) # based on BiCopPar2Tau 
      
      tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
      
    }
    
    # ROTATED CLAYTON copula (90)
    if(res$value$BivD == "C90"){
      
      theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                             abs(copula_parameter)) # based on BiCopPar2Tau 
      
      theta_coppar <- - theta_coppar
      
      tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
      
    }
    
    # FRANK copula
    if(copula_class == "F"){
      
      
      signs <- sign(copula_parameter) 
      theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
      theta_coppar <- theta_coppar*signs 
      
      
      tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
      
    }
    
    # JOE copula
    if(res$value$BivD == "J0"){
      
      
      theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                             30, 
                             abs(copula_parameter)) # based on BiCopPar2Tau 
      
      tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
      
      
    }
    
    # ROTATED JOE (90)
    if(res$value$BivD == "J90"){
      
      
      theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                             30, 
                             abs(copula_parameter)) # based on BiCopPar2Tau 
      
      theta_coppar <- -theta_coppar
      
      tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
      
      
    }
    
    # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
    #        Object Vb 
    #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
    #        function of the mvt normal distr. is used to sample from them!
    #        Obtain the following coverages: 90% ,     95%,        99%
    #                                       (1-0.05),  (1-0.025)   (1-0.005)
    
    # Confidence intervals of all coefficients will be obtained via simulations
    # For transformations of the linear predictor (i.e. survival function, etc): 
    # simulation as well as direct transformation of the linear predictor
    
    # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
    # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
    # Compute quantiles from this sample of size R.  
    # Set the number of simulations from the posterior to: 500, default = 200.
    
    # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
    # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
    # Extract coeffs again
    coefficient_vec <- coef(res$value)
    
    # Extract coeffs
    coeff_cov_mat <- res$value$Vb
    
    n.sim <- 200
    
    # Samples from the asymptotic distribution of of the coefficient vector
    bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
    
    
    # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
    # using the typical levels
    prob_levels <- c(0.01, 0.05, 0.1)
    
    confints_list <- sapply(prob_levels, 
                            function(i) matrixStats:::colQuantiles(bs, 
                                                                   probs = c(i/2, 
                                                                             1 - i/2),
                                                                   na.rm = TRUE),
                            simplify = FALSE)
    
    
    
    # For the specific splines:
    # Recover the synthetic values of the covariates:
    # remove other covariates values from the linear predictor: 
    dat_new <- dat_new %>% mutate(x1 = 0, 
                                  x2 = 0)
    
    # Obtain various additive predictors: 
    # Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
    # 
    # Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
    
    # Compute xbeta for first margin: binary
    # fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
    # 
    # # Compute xbeta for second margin: PWE
    # fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] )
    
    # Compute xbeta for copula parameter:
    fitCopParSim <- bs[,length(coefficient_vec)]
    
    # Compute now transformation of this: 
    # Binary margin: just the spline: 
    # confints_binary_spline <-sapply(prob_levels, 
    #                                 function(i) 
    #                                   matrixStats:::rowQuantiles(fit1Sim, 
    #                                                              probs = c(i/2, 1 - i/2), 
    #                                                              na.rm = TRUE),
    #                                 simplify = FALSE)
    # 
    # # PWE margin:
    # confints_loghazard <- sapply(prob_levels, 
    #                              function(i) 
    #                                matrixStats:::rowQuantiles(fit2Sim, 
    #                                                           probs = c(i/2, 1 - i/2), 
    #                                                           na.rm = TRUE),
    #                              simplify = FALSE)
    # 
    # 
    # 
    # confints_hazard <- sapply(prob_levels, 
    #                           function(i) 
    #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
    #                                                        probs = c(i/2, 1 - i/2), 
    #                                                        na.rm = TRUE),
    #                           simplify = FALSE)
    # 
    # 
    # # Compute the cumulative sum correctily:
    # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
    #                          function(i) 
    #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
    #                          simplify = TRUE)
    # 
    # # Compute quantiles
    # confints_cumuhazard <-  sapply(prob_levels, 
    #                                function(i) 
    #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
    #                                                             probs = c(i/2, 1 - i/2), 
    #                                                             na.rm = TRUE),
    #                                simplify = FALSE)
    # 
    # 
    # confints_survival <-  sapply(prob_levels, 
    #                              function(i) 
    #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
    #                                                           probs = c(i/2, 1 - i/2), 
    #                                                           na.rm = TRUE),
    #                              simplify = FALSE)
    # 
    
    
    # Compute confidence intervals for the copula parameter:
    # GAUSS COPULA
    if(res$value$BivD == "N"){
      
      # just a vector of values, since the model is currently has only an intercept:
      fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                              sign(fitCopParSim)*8.75, 
                              fitCopParSim)
      
      # compute copula parameter from the additive predictor of
      # the copula parameter:
      fitCopParSim <- tanh(fitCopParSim) 
      
      # computation of TAU:
      fitTauSim <-  2 / pi * asin(fitCopParSim) 
      # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
      
    }
    
    
    # CLAYTON COPULA
    if(res$value$BivD == "C0"){
      
      
      fitCopParSim <- ifelse( fitCopParSim > 20, 
                              20, 
                              fitCopParSim )     # 709, maximum allowed # these values look fine
      
      fitCopParSim <- ifelse( fitCopParSim < -17, 
                              -17, 
                              fitCopParSim )   # -20                  # 
      
      
      # compute copula parameter from the additive predictor of
      # the copula parameter:
      fitCopParSim <- exp( fitCopParSim )
      
      # computation of TAU:
      fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                          28, 
                          abs(fitCopParSim)) # based on BiCopPar2Tau 
      
      fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
      
    }
    
    
    # ROTATED CLAYTON COPULA (90)
    if(res$value$BivD == "C90"){
      
      
      fitCopParSim <- ifelse( fitCopParSim > 20, 
                              20, 
                              fitCopParSim )     # 709, maximum allowed # these values look fine
      
      fitCopParSim <- ifelse( fitCopParSim < -17, 
                              -17, 
                              fitCopParSim )   # -20                  # 
      
      
      # compute copula parameter from the additive predictor of
      # the copula parameter:
      fitCopParSim <-  -( exp( fitCopParSim ) )
      
      # computation of TAU:
      fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                          28, 
                          abs(fitCopParSim)) # based on BiCopPar2Tau 
      
      fitTauSim <- -fitTauSim
      
      fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
      
      
      
    }
    
    
    # GUMBEL COPULA 
    if(res$value$BivD == "G0"){
      
      
      fitCopParSim <- ifelse( fitCopParSim > 20, 
                              20, 
                              fitCopParSim )     # 709, maximum allowed # these values look fine
      
      fitCopParSim <- ifelse( fitCopParSim < -17, 
                              -17, 
                              fitCopParSim )   # -20                
      
      # compute copula parameter from the additive predictor of
      # the copula parameter:
      fitCopParSim <- exp( fitCopParSim ) + 1   
      
      # computation of TAU:
      fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                          17, 
                          abs(fitCopParSim)) # based on BiCopPar2Tau 
      
      fitTauSim <-  1 - 1 / fitTauSim 
      
    }
    
    
    # ROTATED GUMBEL COPULA (90)
    if(res$value$BivD == "G90"){
      
      
      fitCopParSim <- ifelse( fitCopParSim > 20, 
                              20, 
                              fitCopParSim )     # 709, maximum allowed # these values look fine
      
      fitCopParSim <- ifelse( fitCopParSim < -17, 
                              -17, 
                              fitCopParSim )   # -20                
      
      # compute copula parameter from the additive predictor of
      # the copula parameter:
      fitCopParSim <- -( exp( fitCopParSim ) + 1  )
      
      # computation of TAU:
      fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                          17, 
                          abs(fitCopParSim)) # based on BiCopPar2Tau 
      
      fitTauSim <- -fitTauSim
      
      fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
      
    }
    
    
    # JOE COPULA
    if(res$value$BivD == "J0"){
      
      
      fitCopParSim <- ifelse( fitCopParSim > 20, 
                              20, 
                              fitCopParSim )     # 709, maximum allowed # these values look fine
      
      fitCopParSim <- ifelse( fitCopParSim < -17, 
                              -17, 
                              fitCopParSim )   # -20                  # 
      
      
      # compute copula parameter from the additive predictor of
      # the copula parameter:
      fitCopParSim <- exp(fitCopParSim) + 1
      
      # computation of TAU:
      fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                          30, 
                          abs(fitCopParSim)) # based on BiCopPar2Tau 
      
      
      fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
      
      
    }
    
    
    # ROTATED JOE COPULA (90)
    if(res$value$BivD == "J90"){
      
      
      fitCopParSim <- ifelse( fitCopParSim > 20, 
                              20, 
                              fitCopParSim )     # 709, maximum allowed # these values look fine
      
      fitCopParSim <- ifelse( fitCopParSim < -17, 
                              -17, 
                              fitCopParSim )   # -20                  # 
      
      
      # compute copula parameter from the additive predictor of
      # the copula parameter:
      fitCopParSim <- - ( exp(fitCopParSim) + 1 )
      
      # computation of TAU:
      fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                          30, 
                          abs(fitCopParSim)) # based on BiCopPar2Tau 
      
      fitTauSim <- - fitTauSim
      
      fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
      
      
    }
    
    
    # FRANK COPULA
    if(res$value$BivD == "F"){
      
      epsilon <- c(sqrt(.Machine$double.eps))
      
      fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                              epsilon, 
                              fitCopParSim )     
      
      
      signs <- sign(fitCopParSim) 
      
      fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                             35, 
                             abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
      
      fitCopParSim <- fitCopParSim*signs
      
      fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
      
      
    }
    
    
    
    
    
    confints_copulaparam <-  sapply(prob_levels,
                                    function(i)
                                      quantile(fitCopParSim,
                                               probs = c(i/2, 1 - i/2),
                                               na.rm = TRUE),
                                    simplify = FALSE)
    
    
    # intervals for KENDALLs TAU:
    confints_tau <-  sapply(prob_levels,
                            function(i)
                              quantile(fitTauSim,
                                       probs = c(i/2, 1 - i/2),
                                       na.rm = TRUE),
                            simplify = FALSE)
    
    
    
    # Compute the coverages:
    coverage_copula_param <- sapply(confints_copulaparam, function(i) 
      
      lies_in_interval(original_data_object$true_copula_param, i)
      
    )
    
    coverage_tau <- sapply(confints_tau, function(i) 
      
      lies_in_interval(original_data_object$original_tau, i)
      
    )
    
    
    names(coverage_tau) <- c("99%", "95%", "90%")
    
    
    # confint_materials <- list(all_coefficients  = confints_list, 
    #                           binary_spline = confints_binary_spline, 
    #                           loghazard = confints_loghazard, 
    #                           hazard = confints_loghazard, 
    #                           cumuhazard = confints_cumuhazard, 
    #                           survival = confints_survival,
    #                           copula_param = confints_copulaparam,
    #                           kendall_tau = confints_tau)
    
    coverages_materials <-list(tau = coverage_tau,
                               copula_parameter = coverage_copula_param,
                               beta_nonsurv_margin = NULL,
                               beta_surv_margin = NULL)
    
    # Put everything together
    # output <- list(
    #   # Coefficients 
    #   coefficients_binary = coefficients_binary,
    #   coefficients_pwe = coefficients_pwe,
    #   copula_parameter_intercept = copula_parameter_intercept,
    #   #
    #   # Smooth functions
    #   binary_spline = binary_pred_spline, 
    #   pwe_log_baseline = cloglog_baseline,
    #   pwe_baseline = pwe_baseline,
    #   pwe_cumu_hazard = pwe_cumuhazard,
    #   pwe_surv = pwe_surv,
    #   #
    #   # copula parameter and dependence
    #   copula_parameter = copula_parameter,
    #   tau_of_kendall = tau_of_kendall,
    #   #
    #   # Big matrix of coefficient's confidence intervals:
    #   confint_materials = confint_materials,
    #   #
    #   # Various summaries
    #   pwe_data_n = nrow(dataset_long_margin2),
    #   original_data_n = nrow(original_data),
    #   edf_binary_margin = res$value$edf[[1]],
    #   edf_pwe_margin = res$value$edf[[2]],
    #   #
    #   #
    #   #
    #   # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
    #   kendall_binary_PWE = res$value$tau,
    #   copula_parameter_estimate = res$value$theta,
    #   # some other diagnostics
    #   cuts_placement = the_used_cuts,
    #   the_unique_tends = the_unique_tends,
    #   the_warning = res$warning,
    #   the_error = res$error,
    #   model_runtime = model_runtime
    # )
    # 
    
    
    output <- list(estimated_copula_parameter = res$value$theta,
                   estimated_kendall_tau = res$value$tau,
                   copula_type = copula_class,
                   coverages = coverages_materials,
                   correlation_materials = original_data_object$correlations_materials
    )
    
    
    }
    
    }else{
      
      if(NonSurv_Margin == "N"){
        
        # Evaluate the fitted model:
        # --- > overall coefficients
        # --- > all prediction points of the spline in 100, equidistant points!
        
        #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
        model_coefficients <- coef(res$value)
        
        
        kendall_binary_PWE <- res$value$tau
        
        # Copula / dependence part 
        # --- > intercept of model of copula parameter
        # --- > copula parameter (in copula parameter scale)
        # --- > kendall´s tau (pred.mvt) with confidence interval
        copula_parameter_intercept <- tail(coef(res$value),1)
        copula_parameter <- res$value$theta
        
        # Check fitted bivariate distribution in the MBS model to 
        # compute the correct Kendall's tau:
        #GAUSS copula
        if(res$value$BivD == "N"){
          
          tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
          
        }
        
        # GUMBEL copula
        if(res$value$BivD == "G0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED GUMBEL copula (90)
        if(res$value$BivD == "G90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          
          tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
          
        }
        
        # CLAYTON copula
        if(res$value$BivD == "C0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED CLAYTON copula (90)
        if(res$value$BivD == "C90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- - theta_coppar
          
          tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
          
        }
        
        # FRANK copula
        if(copula_class == "F"){
          
          
          signs <- sign(copula_parameter) 
          theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
          theta_coppar <- theta_coppar*signs 
          
          
          tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
          
        }
        
        # JOE copula
        if(res$value$BivD == "J0"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # ROTATED JOE (90)
        if(res$value$BivD == "J90"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
        #        Object Vb 
        #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
        #        function of the mvt normal distr. is used to sample from them!
        #        Obtain the following coverages: 90% ,     95%,        99%
        #                                       (1-0.05),  (1-0.025)   (1-0.005)
        
        # Confidence intervals of all coefficients will be obtained via simulations
        # For transformations of the linear predictor (i.e. survival function, etc): 
        # simulation as well as direct transformation of the linear predictor
        
        # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
        # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
        # Compute quantiles from this sample of size R.  
        # Set the number of simulations from the posterior to: 500, default = 200.
        
        # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
        # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
        # Extract coeffs again
        coefficient_vec <- coef(res$value)
        
        # Extract coeffs
        coeff_cov_mat <- res$value$Vb
        
        n.sim <- 200
        
        # Samples from the asymptotic distribution of of the coefficient vector
        bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
        
        
        # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
        # using the typical levels
        prob_levels <- c(0.01, 0.05, 0.1)
        
        confints_list <- sapply(prob_levels, 
                                function(i) matrixStats:::colQuantiles(bs, 
                                                                       probs = c(i/2, 
                                                                                 1 - i/2),
                                                                       na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        
        # Compute xbeta for copula parameter:
        fitCopParSim <- bs[,length(coefficient_vec)]
        
        # Compute now transformation of this: 
        # Binary margin: just the spline: 
        # confints_binary_spline <-sapply(prob_levels, 
        #                                 function(i) 
        #                                   matrixStats:::rowQuantiles(fit1Sim, 
        #                                                              probs = c(i/2, 1 - i/2), 
        #                                                              na.rm = TRUE),
        #                                 simplify = FALSE)
        # 
        # # PWE margin:
        # confints_loghazard <- sapply(prob_levels, 
        #                              function(i) 
        #                                matrixStats:::rowQuantiles(fit2Sim, 
        #                                                           probs = c(i/2, 1 - i/2), 
        #                                                           na.rm = TRUE),
        #                              simplify = FALSE)
        # 
        # 
        # 
        # confints_hazard <- sapply(prob_levels, 
        #                           function(i) 
        #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
        #                                                        probs = c(i/2, 1 - i/2), 
        #                                                        na.rm = TRUE),
        #                           simplify = FALSE)
        # 
        # 
        # # Compute the cumulative sum correctily:
        # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
        #                          function(i) 
        #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
        #                          simplify = TRUE)
        # 
        # # Compute quantiles
        # confints_cumuhazard <-  sapply(prob_levels, 
        #                                function(i) 
        #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
        #                                                             probs = c(i/2, 1 - i/2), 
        #                                                             na.rm = TRUE),
        #                                simplify = FALSE)
        # 
        # 
        # confints_survival <-  sapply(prob_levels, 
        #                              function(i) 
        #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
        #                                                           probs = c(i/2, 1 - i/2), 
        #                                                           na.rm = TRUE),
        #                              simplify = FALSE)
        # 
        
        
        # Compute confidence intervals for the copula parameter:
        # GAUSS COPULA
        if(res$value$BivD == "N"){
          
          # just a vector of values, since the model is currently has only an intercept:
          fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                  sign(fitCopParSim)*8.75, 
                                  fitCopParSim)
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- tanh(fitCopParSim) 
          
          # computation of TAU:
          fitTauSim <-  2 / pi * asin(fitCopParSim) 
          # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
          
        }
        
        
        # CLAYTON COPULA
        if(res$value$BivD == "C0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
          
        }
        
        
        # ROTATED CLAYTON COPULA (90)
        if(res$value$BivD == "C90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <-  -( exp( fitCopParSim ) )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
          
          
          
        }
        
        
        # GUMBEL COPULA 
        if(res$value$BivD == "G0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim ) + 1   
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <-  1 - 1 / fitTauSim 
          
        }
        
        
        # ROTATED GUMBEL COPULA (90)
        if(res$value$BivD == "G90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- -( exp( fitCopParSim ) + 1  )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
          
        }
        
        
        # JOE COPULA
        if(res$value$BivD == "J0"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp(fitCopParSim) + 1
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          
          fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
          
          
        }
        
        
        # ROTATED JOE COPULA (90)
        if(res$value$BivD == "J90"){
          
          
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- - ( exp(fitCopParSim) + 1 )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- - fitTauSim
          
          fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
          
          
        }
        
        
        # FRANK COPULA
        if(res$value$BivD == "F"){
          
          epsilon <- c(sqrt(.Machine$double.eps))
          
          fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                  epsilon, 
                                  fitCopParSim )     
          
          
          signs <- sign(fitCopParSim) 
          
          fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                 35, 
                                 abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
          
          fitCopParSim <- fitCopParSim*signs
          
          fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
          
          
        }
        
        
        
        
        
        confints_copulaparam <-  sapply(prob_levels,
                                        function(i)
                                          quantile(fitCopParSim,
                                                   probs = c(i/2, 1 - i/2),
                                                   na.rm = TRUE),
                                        simplify = FALSE)
        
        
        # intervals for KENDALLs TAU:
        confints_tau <-  sapply(prob_levels,
                                function(i)
                                  quantile(fitTauSim,
                                           probs = c(i/2, 1 - i/2),
                                           na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # Compute the coverages:
        coverage_copula_param <- sapply(confints_copulaparam, function(i) 
          
          lies_in_interval(original_data_object$true_copula_param, i)
          
        )
        
        coverage_tau <- sapply(confints_tau, function(i) 
          
          lies_in_interval(original_data_object$original_tau, i)
          
        )
        
        
        
        
        names(coverage_tau) <- c("99%", "95%", "90%")
        names(coverage_copula_param) <- c("99%", "95%", "90%")
        
        
        
        
        # confint_materials <- list(all_coefficients  = confints_list, 
        #                           binary_spline = confints_binary_spline, 
        #                           loghazard = confints_loghazard, 
        #                           hazard = confints_loghazard, 
        #                           cumuhazard = confints_cumuhazard, 
        #                           survival = confints_survival,
        #                           copula_param = confints_copulaparam,
        #                           kendall_tau = confints_tau)
        
        coverages_materials <-list(tau = coverage_tau,
                                   copula_parameter = coverage_copula_param,
                                   beta_nonsurv_margin = NULL,
                                   beta_surv_margin = NULL)
        
        
        output <- list(model_coefficients = model_coefficients,
                       confints = coverages_materials,
                       estimated_copula_parameter = res$value$theta,
                       estimated_kendall_tau = res$value$tau, 
                       nrow_datalong = dim(dataset_long_margin2))
        
        
        
      }
      
      # This is the output in case of binary non-survival margins
      if( NonSurv_Margin %in% c("logit", "probit", "cloglog", "GEVlink") ){
        
        
        # extract Goodness of fit residuals from the survival margin: 
        residuals_materials <- myTryCatch(compute_relevant_residuals(model = res$value, 
                                                          data_short = original_data, 
                                                          data_long = dataset_long_margin2, 
                                                          type = "PW", 
                                                          indices = INDCS_list, 
                                                          equation_survmodel = 2))
        
        # Evaluate the fitted model:
        # --- > overall coefficients
        coefficients_nonsurv_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ]
        
        coefficients_survival_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
        
        coefficients_copula_parameter <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[3]):(length(coef(res$value)))]
        
        
        
        # Survival / margin
        # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
        
        # 1: Create rich sequence of time points for the splines
        # 2: Use predict(, type = "terms")
        # 3: Extract the prediction of only the log( baseline hazard )
        # 4: Add the intercept to all observations
        # 5: Transform into hazard rate, 
        # 6: Obtain original interval lengths (all equidistant)  
        # 7: Obtain the cumu hazard, 
        # 8: Transform into survival function.
        # Step 1: 
        time_synth <-  seq(from = 0, 
                           to = maximum_time_cut, 
                           length.out = number_of_ints)
        
        time_synth2 <-  seq(from = 0, 
                            to = maximum_time_cut, 
                            length.out = number_of_ints)
        
        dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
        
        dat_ped_new$tend <- time_synth
        dat_ped_new$tend_margin2 <- time_synth
        
        dat_ped_ready <- dat_ped_new %>% 
          mutate(x1 = 0,
                 x2 = 0,
                 x3 = 0,
                 x5 = 0,
                 x4 = 0)
        
        # Remove the zero here!!!
        dat_ped_ready <- make_newdata(dataset_long_margin2,
                                      tend = time_synth[-1]) %>%  mutate(x1 = 0,
                                                                         x2 = 0,
                                                                         x3 = 0,
                                                                         x5 = 0,
                                                                         x4 = 0)
        
        dat_ped_ready2 <- dat_ped_ready
        
        # Step 2 + 3 + 4:
        # Intercept is added
        baseline_link_scale <-  predict(res$value,
                                        eq = 2,
                                        newdata = dat_ped_ready2,
                                        type = "terms")[,3] +
          coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]
        
        # Step 5:
        baseline_hazard <- exp( baseline_link_scale )
        
        # Step 6: not needed in DTS
        
        # Step 7:
        cumuhazard_justcumsum <- cumsum( baseline_hazard * exp(dat_ped_ready2$offset)  )
        
        cumuhazard_logoneminus <- NULL
        
        # Step 8:
        survivalfunction <- exp(- cumuhazard_justcumsum )
        # 
        # 
        ###########################
        ###########################
        
        estimated_kendall_tau <- res$value$tau
        
        # Copula / dependence part 
        # --- > intercept of model of copula parameter
        # --- > copula parameter (in copula parameter scale)
        # --- > kendall´s tau (pred.mvt) with confidence interval
        copula_parameter_intercept <- tail(coef(res$value), 2)[1]
        
        copula_parameter <- res$value$theta
        
        # Check fitted bivariate distribution in the MBS model to 
        # compute the correct Kendall's tau:
        #GAUSS copula
        if(res$value$BivD == "N"){
          
          tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
          
        }
        
        # GUMBEL copula
        if(res$value$BivD == "G0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED GUMBEL copula (90)
        if(res$value$BivD == "G90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          
          tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
          
        }
        
        # CLAYTON copula
        if(res$value$BivD == "C0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED CLAYTON copula (90)
        if(res$value$BivD == "C90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- - theta_coppar
          
          tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
          
        }
        
        # FRANK copula
        if(copula_class == "F"){
          
          
          signs <- sign(copula_parameter) 
          theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
          theta_coppar <- theta_coppar*signs 
          
          
          tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
          
        }
        
        # JOE copula
        if(res$value$BivD == "J0"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # ROTATED JOE (90)
        if(res$value$BivD == "J90"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
        #        Object Vb 
        #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
        #        function of the mvt normal distr. is used to sample from them!
        #        Obtain the following coverages: 90% ,     95%,        99%
        #                                       (1-0.05),  (1-0.025)   (1-0.005)
        
        # Confidence intervals of all coefficients will be obtained via simulations
        # For transformations of the linear predictor (i.e. survival function, etc): 
        # simulation as well as direct transformation of the linear predictor
        
        # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
        # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
        # Compute quantiles from this sample of size R.  
        # Set the number of simulations from the posterior to: 500, default = 200.
        
        # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
        # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
        # Extract coeffs again
        coefficient_vec <- coef(res$value)
        
        # Extract coeffs
        coeff_cov_mat <- res$value$Vb
        
        n.sim <- n.sim
        
        # Samples from the asymptotic distribution of of the coefficient vector
        bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
        
        
        # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
        # using the typical levels
        prob_levels <- c(0.01, 0.05, 0.1)
        
        confints_list <- sapply(prob_levels, 
                                function(i) matrixStats:::colQuantiles(bs, 
                                                                       probs = c(i/2, 
                                                                                 1 - i/2),
                                                                       na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # For the specific splines:
        # Recover the synthetic values of the covariates:
        # remove other covariates values from the linear predictor: 
        dat_new <- dat_ped_ready %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
        
        # Obtain various additive predictors: 
        Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
        
        Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
        
        # Compute xbeta for first margin: binary
        fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
        
        # # Compute xbeta for second margin: PWE
        fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)] )
        
        
        # Copula parameter and then into tau:
        dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
        
        XfitCopParam <- predict(res$value, eq = 3, type = "lpmatrix", newdata = dat_ped_ready_copparam)
        
        
        # Compute xbeta for copula parameter:
        fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
        
        # Compute now transformation of this: 
        # Binary margin: just the spline: 
        # confints_binary_spline <-sapply(prob_levels,
        #                                 function(i)
        #                                   matrixStats:::rowQuantiles(fit1Sim,
        #                                                              probs = c(i/2, 1 - i/2),
        #                                                              na.rm = TRUE),
        #                                 simplify = FALSE)
        
        # # Survival margin:
        confints_linkscalehazard <- sapply(prob_levels,
                                           function(i)
                                             matrixStats:::rowQuantiles(fit2Sim,
                                                                        probs = c(i/2, 1 - i/2),
                                                                        na.rm = TRUE),
                                           simplify = FALSE)
        
        
        
        confints_hazard <- sapply(prob_levels,
                                  function(i)
                                    matrixStats:::rowQuantiles( exp( fit2Sim ),
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                  simplify = FALSE)
        
        
        # # Compute the cumulative sum correctly:
        fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                 function(i)
                                   cumsum( exp(fit2Sim[,i] ) * exp(dat_new$offset)  ),
                                 simplify = TRUE)
        
        
        fit2Sim_minuslogoneminus <- NULL
        
        
        fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                  function(i)
                                    exp( -  cumsum( exp(fit2Sim[,i] ) * exp(dat_new$offset)  ) ),
                                  simplify = TRUE)
        
        # # Compute quantiles
        confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                              function(i)
                                                matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                           probs = c(i/2, 1 - i/2),
                                                                           na.rm = TRUE),
                                              simplify = FALSE)
        
        confints_cumuhazard_logoneminus <- NULL
        
        confints_survival <-  sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
        
        
        
        
        # For the true value: 
        copparam_true_df <- data.frame(Intercept = 1,
                                       x5_true = seq(-1, +1, length.out = 200)
        )
        
        eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
        
        
        
        # Compute confidence intervals for the copula parameter:
        # GAUSS COPULA
        if(res$value$BivD == "N"){
          
          
          copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                   sign(eta_copparam_true) * 8.75, 
                                   eta_copparam_true)
          
          copparam_true <- tanh(copparam_true) 
          
          
          tau_true <-  2 / pi * asin(copparam_true) 
          
          
          ### FOR CONFIDENCE INTERVALS
          # just a vector of values, since the model is currently has only an intercept:
          fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                  sign(fitCopParSim)*8.75, 
                                  fitCopParSim)
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- tanh(fitCopParSim) 
          
          # computation of TAU:
          fitTauSim <-  2 / pi * asin(fitCopParSim) 
          # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
          
        }
        
        
        # CLAYTON COPULA
        if(res$value$BivD == "C0"){
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true ) 
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true ) 
          
          copparam_true <- exp( copparam_true )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 28, 
                             28, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- tau_true / ( tau_true + 2 ) 
          
          
          
          
          ##############
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
          
        }
        
        
        # ROTATED CLAYTON COPULA (90)
        if(res$value$BivD == "C90"){
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <-  -( exp( copparam_true ) )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 28, 
                             28, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- -tau_true
          
          tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
          
          
          
          ###########################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <-  -( exp( fitCopParSim ) )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
          
          
          
        }
        
        
        # GUMBEL COPULA 
        if(res$value$BivD == "G0"){
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- exp( copparam_true ) + 1   
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 17, 
                             17, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <-  1 - 1 / tau_true 
          
          
          ##############################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim ) + 1   
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <-  1 - 1 / fitTauSim 
          
        }
        
        
        # ROTATED GUMBEL COPULA (90)
        if(res$value$BivD == "G90"){
          
          
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- -( exp( copparam_true ) + 1  )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 17, 
                             17, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- -tau_true
          
          tau_true <-  -( 1 - 1 / abs(tau_true) ) 
          
          
          #############################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- -( exp( fitCopParSim ) + 1  )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
          
        }
        
        
        # JOE COPULA
        if(res$value$BivD == "J0"){
          
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- exp(copparam_true) + 1
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 30, 
                             30, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          
          tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
          
          
          
          
          ################################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp(fitCopParSim) + 1
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          
          fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
          
          
        }
        
        
        # ROTATED JOE COPULA (90)
        if(res$value$BivD == "J90"){
          
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- - ( exp(copparam_true) + 1 )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 30, 
                             30, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- - tau_true
          
          tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
          
          
          ##############################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- - ( exp(fitCopParSim) + 1 )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- - fitTauSim
          
          fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
          
          
        }
        
        
        # FRANK COPULA
        if(res$value$BivD == "F"){
          
          
          epsilon <- c(sqrt(.Machine$double.eps))
          
          copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                   epsilon, 
                                   eta_copparam_true )     
          
          
          signs <- sign(copparam_true) 
          
          copparam_true <- ifelse(abs(copparam_true) > 35, 
                                  35, 
                                  abs(copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
          
          copparam_true <- copparam_true*signs
          
          tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
          
          
          #################
          epsilon <- c(sqrt(.Machine$double.eps))
          
          fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                  epsilon, 
                                  fitCopParSim )     
          
          
          signs <- sign(fitCopParSim) 
          
          fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                 35, 
                                 abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
          
          fitCopParSim <- fitCopParSim*signs
          
          fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
          
          
        }
        
        
        
        
        
        confints_copulaparam <-  sapply(prob_levels,
                                        function(i)
                                          rowQuantiles(fitCopParSim,
                                                       probs = c(i/2, 1 - i/2),
                                                       na.rm = TRUE),
                                        simplify = FALSE)
        
        
        # intervals for KENDALLs TAU:
        confints_tau <-  sapply(prob_levels,
                                function(i)
                                  rowQuantiles(fitTauSim,
                                               probs = c(i/2, 1 - i/2),
                                               na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # Compute the coverages:
        coverage_copula_param <- sapply(confints_copulaparam, function(i) 
          
          mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
          
        )
        
        
        
        coverage_tau <- sapply(confints_tau, function(i) 
          
          mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
          
        )
        
        
        # extract coefficients of nonsurvival margin
        beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
        
        surv_beta_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
        
        copparam_beta_vector <- bs[, (ncol(bs)-1):ncol(bs) ]
        
        # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
        surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals  of each coefficient!
        surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals  of each coefficient!
        surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        
        # Now for the nonsurvival margin:
        nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
          quantile(copparam_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
          quantile(copparam_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
          quantile(copparam_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        # Compute coverages:
        coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                  surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
          
        )
        
        coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                  surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
        )
        
        coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                  surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
        )
        
        
        
        ########### now for the nonsurvival margin:
        coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                  nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
          
        )
        
        coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                  nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
          
        )
        
        coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                  nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
          
        )
        
        
        
        names(coverage_tau) <- c("99%", "95%", "90%")
        names(coverage_copula_param) <- c("99%", "95%", "90%")
        
        
        
        
        confint_materials <- list(all_coefficients  = confints_list,
                                  linkscale_hazard = confints_linkscalehazard,
                                  hazard = confints_hazard,
                                  cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                  cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                  survival = confints_survival,
                                  copula_param = confints_copulaparam,
                                  kendall_tau = confints_tau, 
                                  #
                                  coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                      ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                      ninetyfive = coverage3_nonsurv_margin),
                                  #
                                  coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                       ninetyseven_pointfive = coverage2_surv_margin,
                                                                       ninetyfive = coverage3_surv_margin),
                                  coverage_tau = coverage_tau,
                                  coverage_copula_parameter = coverage_copula_param
        )
        
        
        
        
        # Put everything together
        output <- list(
          # Coefficients
          coefficients_nonsurv = coefficients_nonsurv_margin,
          coefficients_survival = coefficients_survival_margin,
          coefficients_copula_parameter = coefficients_copula_parameter,
          #
          #
          residuals_materials = residuals_materials,
          #
          # Smooth functions
          #binary_spline = binary_pred_spline,
          linkscale_baseline = baseline_link_scale,
          baseline = baseline_hazard,
          cumu_hazard = cumuhazard_justcumsum,
          cumu_hazard_logoneminus = cumuhazard_logoneminus,
          survival = survivalfunction,
          #
          # copula parameter and dependence
          copula_parameter = copula_parameter,
          tau_of_kendall = tau_of_kendall,
          #
          # Big matrix of coefficient's confidence intervals:
          confint_materials = confint_materials,
          #
          # Various summaries
          survival_data_n = nrow(dataset_long_margin2),
          original_data_n = nrow(original_data),
          edf_nonsurvival_margin = res$value$edf[[2]],
          edf_survival_margin = res$value$edf[[1]],
          #
          #
          #
          # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
          estimated_kendall = res$value$tau,
          copula_parameter_estimate = res$value$theta,
          # some other diagnostics
          cuts_placement_intime = the_used_cuts,
          the_unique_tends = the_unique_tends,
          the_warning = res$warning,
          the_error = res$error,
          model_runtime = model_runtime
        )
        
        
        
        
      }
      
      
      # This is the output in case of count non-survival margins
      if( NonSurv_Margin == "PO" ){
        
        
        # extract Goodness of fit residuals from the survival margin: 
        residuals_materials <- compute_relevant_residuals(model = res$value, 
                                                          data_short = original_data, 
                                                          data_long = dataset_long_margin2, 
                                                          type = "PW", 
                                                          indices = INDCS_list, 
                                                          equation_survmodel = 1)
        
        # Evaluate the fitted model:
        # --- > overall coefficients
        coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)]
        
        coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
        
        coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
        
        
        
        # Survival / margin
        # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
        
        # 1: Create rich sequence of time points for the splines
        # 2: Use predict(, type = "terms")
        # 3: Extract the prediction of only the log( baseline hazard )
        # 4: Add the intercept to all observations
        # 5: Transform into hazard rate, 
        # 6: Obtain original interval lengths (all equidistant)  
        # 7: Obtain the cumu hazard, 
        # 8: Transform into survival function.
        # Step 1: 
        time_synth <-  seq(from = 0, 
                           to = maximum_time_cut, 
                           length.out = number_of_ints)
        
        time_synth2 <-  seq(from = 0, 
                            to = maximum_time_cut, 
                            length.out = number_of_ints)
        
        dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
        
        dat_ped_new$tend <- time_synth
        dat_ped_new$tend_margin2 <- time_synth
        
        dat_ped_ready <- dat_ped_new %>% 
          mutate(x1 = 0,
                 x2 = 0,
                 x3 = 0,
                 x5 = 0,
                 x4 = 0)
        
        # Remove the zero here!!!
        dat_ped_ready <- make_newdata(dataset_long_margin2,
                                      tend = time_synth[-1]) %>%  mutate(x1 = 0,
                                                                         x2 = 0,
                                                                         x3 = 0,
                                                                         x5 = 0,
                                                                         x4 = 0)
        
        dat_ped_ready2 <- dat_ped_ready
        
        # Step 2 + 3 + 4:
        # Intercept is added
        baseline_link_scale <-  predict(res$value,
                                        eq = 1,
                                        newdata = dat_ped_ready2,
                                        type = "terms")[,3] +
          coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
        
        
        # Step 5:
        baseline_hazard <- exp( baseline_link_scale )
        
        # Step 6: not needed in DTS
        
        # Step 7:
        cumuhazard_justcumsum <- cumsum( baseline_hazard * exp(dat_ped_ready2$offset)  )
        
        cumuhazard_logoneminus <- NULL
        
        # Step 8:
        survivalfunction <- exp(  - cumuhazard_justcumsum )
        # 
        # 
        ###########################
        ###########################
        
        estimated_kendall_tau <- res$value$tau
        
        # Copula / dependence part 
        # --- > intercept of model of copula parameter
        # --- > copula parameter (in copula parameter scale)
        # --- > kendall´s tau (pred.mvt) with confidence interval
        copula_parameter_intercept <- tail(coef(res$value), 2)[1]
        
        copula_parameter <- res$value$theta
        
        # Check fitted bivariate distribution in the MBS model to 
        # compute the correct Kendall's tau:
        #GAUSS copula
        if(res$value$BivD == "N"){
          
          tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
          
        }
        
        # GUMBEL copula
        if(res$value$BivD == "G0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED GUMBEL copula (90)
        if(res$value$BivD == "G90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          
          tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
          
        }
        
        # CLAYTON copula
        if(res$value$BivD == "C0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED CLAYTON copula (90)
        if(res$value$BivD == "C90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- - theta_coppar
          
          tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
          
        }
        
        # FRANK copula
        if(copula_class == "F"){
          
          
          signs <- sign(copula_parameter) 
          theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
          theta_coppar <- theta_coppar*signs 
          
          
          tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
          
        }
        
        # JOE copula
        if(res$value$BivD == "J0"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # ROTATED JOE (90)
        if(res$value$BivD == "J90"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
        #        Object Vb 
        #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
        #        function of the mvt normal distr. is used to sample from them!
        #        Obtain the following coverages: 90% ,     95%,        99%
        #                                       (1-0.05),  (1-0.025)   (1-0.005)
        
        # Confidence intervals of all coefficients will be obtained via simulations
        # For transformations of the linear predictor (i.e. survival function, etc): 
        # simulation as well as direct transformation of the linear predictor
        
        # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
        # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
        # Compute quantiles from this sample of size R.  
        # Set the number of simulations from the posterior to: 500, default = 200.
        
        # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
        # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
        # Extract coeffs again
        coefficient_vec <- coef(res$value)
        
        # Extract coeffs
        coeff_cov_mat <- res$value$Vb
        
        n.sim <- n.sim
        
        # Samples from the asymptotic distribution of of the coefficient vector
        bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
        
        
        # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
        # using the typical levels
        prob_levels <- c(0.01, 0.05, 0.1)
        
        confints_list <- sapply(prob_levels, 
                                function(i) matrixStats:::colQuantiles(bs, 
                                                                       probs = c(i/2, 
                                                                                 1 - i/2),
                                                                       na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # For the specific splines:
        # Recover the synthetic values of the covariates:
        # remove other covariates values from the linear predictor: 
        dat_new <- dat_ped_ready %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
        
        # Obtain various additive predictors: 
        Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
        
        Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
        
        # Compute xbeta for first margin: 
        fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
        
        # # Compute xbeta for second margin: 
        fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)] )
        
        
        # Copula parameter and then into tau:
        dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
        
        XfitCopParam <- predict(res$value, eq = 3, type = "lpmatrix", newdata = dat_ped_ready_copparam)
        
        
        # Compute xbeta for copula parameter:
        fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
        
        # Compute now transformation of this: 
        # Binary margin: just the spline: 
        # confints_binary_spline <-sapply(prob_levels,
        #                                 function(i)
        #                                   matrixStats:::rowQuantiles(fit1Sim,
        #                                                              probs = c(i/2, 1 - i/2),
        #                                                              na.rm = TRUE),
        #                                 simplify = FALSE)
        
        # # Survival margin:
        confints_linkscalehazard <- sapply(prob_levels,
                                           function(i)
                                             matrixStats:::rowQuantiles(fit1Sim,
                                                                        probs = c(i/2, 1 - i/2),
                                                                        na.rm = TRUE),
                                           simplify = FALSE)
        
        
        
        confints_hazard <- sapply(prob_levels,
                                  function(i)
                                    matrixStats:::rowQuantiles(exp( fit1Sim ),
                                                               probs = c(i/2, 1 - i/2),
                                                               na.rm = TRUE),
                                  simplify = FALSE)
        
        
        # # Compute the cumulative sum correctly:
        fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                 function(i)
                                   cumsum( exp(fit1Sim[,i] ) * exp(dat_ped_ready2$offset) ),
                                 simplify = TRUE)
        
        
        fit2Sim_minuslogoneminus <- NULL
        
        
        fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                  function(i)
                                    exp( - cumsum( exp(fit1Sim[,i] ) * exp(dat_ped_ready2$offset) ) ),
                                  simplify = TRUE)
        
        # # Compute quantiles
        confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                              function(i)
                                                matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                           probs = c(i/2, 1 - i/2),
                                                                           na.rm = TRUE),
                                              simplify = FALSE)
        
        confints_cumuhazard_logoneminus <-  NULL
        
        confints_survival <-  sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
        
        
        
        
        # For the true value: 
        copparam_true_df <- data.frame(Intercept = 1,
                                       x5_true = seq(-1, +1, length.out = 200)
        )
        
        eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
        
        
        
        # Compute confidence intervals for the copula parameter:
        # GAUSS COPULA
        if(res$value$BivD == "N"){
          
          
          copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                   sign(eta_copparam_true) * 8.75, 
                                   eta_copparam_true)
          
          copparam_true <- tanh(copparam_true) 
          
          
          tau_true <-  2 / pi * asin(copparam_true) 
          
          
          ### FOR CONFIDENCE INTERVALS
          # just a vector of values, since the model is currently has only an intercept:
          fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                  sign(fitCopParSim)*8.75, 
                                  fitCopParSim)
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- tanh(fitCopParSim) 
          
          # computation of TAU:
          fitTauSim <-  2 / pi * asin(fitCopParSim) 
          # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
          
        }
        
        
        # CLAYTON COPULA
        if(res$value$BivD == "C0"){
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true ) 
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true ) 
          
          copparam_true <- exp( copparam_true )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 28, 
                             28, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- tau_true / ( tau_true + 2 ) 
          
          
          
          
          ##############
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
          
        }
        
        
        # ROTATED CLAYTON COPULA (90)
        if(res$value$BivD == "C90"){
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <-  -( exp( copparam_true ) )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 28, 
                             28, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- -tau_true
          
          tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
          
          
          
          ###########################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <-  -( exp( fitCopParSim ) )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
          
          
          
        }
        
        
        # GUMBEL COPULA 
        if(res$value$BivD == "G0"){
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- exp( copparam_true ) + 1   
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 17, 
                             17, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <-  1 - 1 / tau_true 
          
          
          ##############################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim ) + 1   
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <-  1 - 1 / fitTauSim 
          
        }
        
        
        # ROTATED GUMBEL COPULA (90)
        if(res$value$BivD == "G90"){
          
          
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- -( exp( copparam_true ) + 1  )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 17, 
                             17, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- -tau_true
          
          tau_true <-  -( 1 - 1 / abs(tau_true) ) 
          
          
          #############################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- -( exp( fitCopParSim ) + 1  )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
          
        }
        
        
        # JOE COPULA
        if(res$value$BivD == "J0"){
          
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- exp(copparam_true) + 1
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 30, 
                             30, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          
          tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
          
          
          
          
          ################################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp(fitCopParSim) + 1
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          
          fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
          
          
        }
        
        
        # ROTATED JOE COPULA (90)
        if(res$value$BivD == "J90"){
          
          
          copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          copparam_true <- ifelse( copparam_true < -17, 
                                   -17, 
                                   copparam_true )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- - ( exp(copparam_true) + 1 )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 30, 
                             30, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- - tau_true
          
          tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
          
          
          ##############################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- - ( exp(fitCopParSim) + 1 )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- - fitTauSim
          
          fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
          
          
        }
        
        
        # FRANK COPULA
        if(res$value$BivD == "F"){
          
          
          epsilon <- c(sqrt(.Machine$double.eps))
          
          copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                   epsilon, 
                                   eta_copparam_true )     
          
          
          signs <- sign(copparam_true) 
          
          copparam_true <- ifelse(abs(copparam_true) > 35, 
                                  35, 
                                  abs(copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
          
          copparam_true <- copparam_true*signs
          
          tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
          
          
          #################
          epsilon <- c(sqrt(.Machine$double.eps))
          
          fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                  epsilon, 
                                  fitCopParSim )     
          
          
          signs <- sign(fitCopParSim) 
          
          fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                 35, 
                                 abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
          
          fitCopParSim <- fitCopParSim*signs
          
          fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
          
          
        }
        
        
        
        
        
        confints_copulaparam <-  sapply(prob_levels,
                                        function(i)
                                          rowQuantiles(fitCopParSim,
                                                       probs = c(i/2, 1 - i/2),
                                                       na.rm = TRUE),
                                        simplify = FALSE)
        
        
        # intervals for KENDALLs TAU:
        confints_tau <-  sapply(prob_levels,
                                function(i)
                                  rowQuantiles(fitTauSim,
                                               probs = c(i/2, 1 - i/2),
                                               na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # Compute the coverages:
        coverage_copula_param <- sapply(confints_copulaparam, function(i) 
          
          mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
          
        )
        
        
        
        coverage_tau <- sapply(confints_tau, function(i) 
          
          mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
          
        )
        
        
        # extract coefficients of nonsurvival margin
        beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
        
        surv_beta_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
        
        copparam_beta_vector <- bs[, (ncol(bs)-1):ncol(bs) ]
        
        # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
        surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals  of each coefficient!
        surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals  of each coefficient!
        surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        
        # Now for the nonsurvival margin:
        nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
          quantile(copparam_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
          quantile(copparam_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
          quantile(copparam_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        # Compute coverages:
        coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                  surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
          
        )
        
        coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                  surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
        )
        
        coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                  surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
        )
        
        
        
        ########### now for the nonsurvival margin:
        coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                  nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
          
        )
        
        coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                  nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
          
        )
        
        coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                  nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
          
        )
        
        
        
        names(coverage_tau) <- c("99%", "95%", "90%")
        names(coverage_copula_param) <- c("99%", "95%", "90%")
        
        
        
        
        confint_materials <- list(all_coefficients  = confints_list,
                                  linkscale_hazard = confints_linkscalehazard,
                                  hazard = confints_hazard,
                                  cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                  cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                  survival = confints_survival,
                                  copula_param = confints_copulaparam,
                                  kendall_tau = confints_tau, 
                                  #
                                  coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                      ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                      ninetyfive = coverage3_nonsurv_margin),
                                  #
                                  coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                       ninetyseven_pointfive = coverage2_surv_margin,
                                                                       ninetyfive = coverage3_surv_margin),
                                  coverage_tau = coverage_tau,
                                  coverage_copula_parameter = coverage_copula_param
        )
        
        
        
        
        # Put everything together
        output <- list(
          # Coefficients
          coefficients_nonsurv = coefficients_nonsurv_margin,
          coefficients_survival = coefficients_survival_margin,
          coefficients_copula_parameter = coefficients_copula_parameter,
          #
          #
          residuals_materials = residuals_materials,
          #
          # Smooth functions
          #binary_spline = binary_pred_spline,
          linkscale_baseline = baseline_link_scale,
          baseline = baseline_hazard,
          cumu_hazard = cumuhazard_justcumsum,
          cumu_hazard_logoneminus = cumuhazard_logoneminus,
          survival = survivalfunction,
          #
          # copula parameter and dependence
          copula_parameter = copula_parameter,
          tau_of_kendall = tau_of_kendall,
          #
          # Big matrix of coefficient's confidence intervals:
          confint_materials = confint_materials,
          #
          # Various summaries
          survival_data_n = nrow(dataset_long_margin2),
          original_data_n = nrow(original_data),
          edf_nonsurvival_margin = res$value$edf[[2]],
          edf_survival_margin = res$value$edf[[1]],
          #
          #
          #
          # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
          estimated_kendall = res$value$tau,
          copula_parameter_estimate = res$value$theta,
          # some other diagnostics
          cuts_placement_intime = the_used_cuts,
          the_unique_tends = the_unique_tends,
          the_warning = res$warning,
          the_error = res$error,
          model_runtime = model_runtime
        )
        
        
        
        
      }
      
      
    }
    
    
  }else{
    
    output <- list(the_warning = res$warning,
                   the_error = res$error)
    
  }
  
  
  rm(res)
  
  return(output)
  
  
}










# The fitting function for recursive settings:
fit_MXS_recursive <- function(original_data_object, 
                              copula_class = "N", 
                              # non-survival marginal response
                              NonSurv_Margin = "N",
                              # cuts / intervals
                              number_of_ints = 25, 
                              #
                              maximum_time_cut = 8.1,
                              #
                              varying_dependence = FALSE,
                              # smooth the baseline function of time on time scale or log(time) scale
                              baseline_smooth = "log",
                              # for confidence intervals
                              n.sim = 500,
                              # further arguments
                              hess_reg = "t"
){
  
  original_data <- original_data_object$dataset
  
  # extra reg settings:
  extra.regularization <- hess_reg
  
  
  the_used_cuts <- seq(from = 0,  
                       to = maximum_time_cut, 
                       length.out = number_of_ints)
  
  # ADDED ONE SYNTHETIC OBSERVATION OT GET DATALONG TO WORK:
  # original_data_synth <- original_data[nrow(original_data), ]
  # original_data_synth$status <- 0
  # 
  # original_data[(nrow(original_data)+1), ] <- original_data_synth
  
  # create intervals:
  # 0 is always included in this function, so remove it from the vector of the_used_cuts!
  dat_disc <-  contToDisc(dataShort = original_data, 
                          timeColumn = "time", 
                          intervalLimits = the_used_cuts[-1]
  )
  
  
  # Adjustment for identification (see documentation of discSurv)
  dat_disc$timeDisc[dat_disc$timeDisc == max(dat_disc$timeDisc)] <- tail(sort(unique(dat_disc$timeDisc)), 2)[1]
  dat_disc$status[dat_disc$timeDisc == max(dat_disc$timeDisc)] <- 0
  
  
  # create long-format for survival margin (called internally margin 2 but enters the
  # fitting function and is treated there as margin 1)
  dataset_long_margin2 <- discSurv:::dataLong(dat_disc, 
                                              timeColumn = "timeDisc", 
                                              eventColumn = "status")
  
  # create list of indices for margin 2 
  INDCS_list <- sapply(levels(as.factor(dataset_long_margin2$obj)), 
                       function(i) which(dataset_long_margin2$obj == i), 
                       simplify = FALSE)
  
  
  # extract unique values of time intervals:
  the_unique_tends <- unique(dat_disc$timeDisc)
  
  
  # attach ped_status in the model:
  # this is to trick GJRM into fitting!
  original_data$y_margin2 <- sample(dataset_long_margin2$y, size = nrow(original_data), replace = TRUE)
  original_data$timeInt_margin2 <- sample(dataset_long_margin2$y, size = nrow(original_data), replace = TRUE)
  
  # rename in long dataset to avoid any issues
  dataset_long_margin2$y_margin2 <- dataset_long_margin2$y
  dataset_long_margin2$timeInt_margin2 <- dataset_long_margin2$timeInt
  
  
  
  ###########################################################################################################
  # DTS formula, i.e. smooth baseline hazard using splines
  DTS_formula <- as.formula( y_margin2 ~ s(timeInt_margin2, bs = "ps", k = 10, m = 2) + 
                               y1 +
                               x2 +
                               x4
  )
  
  
  # smooth time on the log() scale (for smoother results according to literature)
  DTS_log_formula <- as.formula(y_margin2 ~ s(log(as.numeric(timeInt_margin2)), bs = "ps", k = 10,  m = 2) +
                                y1 +
                                + x2 
                                + x4
  )
  
  
  # Formula for dependence parameter (necessary in some cases)
  if(varying_dependence){
    
    Copula_param_formula <- as.formula( ~ 1 + x5)
    
  }else{
    
    Copula_param_formula <- as.formula( ~ 1)
  }
  
  
  #### CONTINUOUS
  # Gaussian
  if(NonSurv_Margin == "N"){
    
    MXS_margins <- c("PO", "N")
    
    #NonSurv_Mar_formula <- as.formula(y1 ~ 1)#x1 + x2 + s(x3, bs = "ps", k = 10, m = 2))
    #NonSurv_Mar_Param2_formula <- as.formula( ~  1)
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  1)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Log-normal
  if(NonSurv_Margin == "LN"){
    MXS_margins <- c("PO", "LN")
  }
  
  # Logistic
  if(NonSurv_Margin == "LO"){
    MXS_margins <- c("PO", "LO")
  }
  
  # Beta
  if(NonSurv_Margin == "BE"){
    MXS_margins <- c("PO", "BE")
  }
  
  # Log-logistic
  if(NonSurv_Margin == "FISK"){
    MXS_margins <- c("PO", "FISK")
  }
  
  # Dagum
  if(NonSurv_Margin == "DAGUM"){
    MXS_margins <- c("PO", "DAGUM")
  }
  
  
  #### DISCRETE 
  # Poisson
  if(NonSurv_Margin == "PO"){
    
    MXS_margins <- c("PO", "PO")
    
    
    NonSurv_Mar_formula <- as.formula(y1 ~ 1)#x1 + x2 + s(x3, bs = "ps", k = 10, m = 2))
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula)
      
    }
  }
  
  # Negative binomial I 
  if(NonSurv_Margin == "NBI"){
    MXS_margins <- c("PO", "NBI")
  }
  
  # Negative binomial I 
  if(NonSurv_Margin == "NBII"){
    MXS_margins <- c("PO", "NBII")
  }
  
  
  #### BINARY 
  # Logit
  if(NonSurv_Margin == "logit"){
    
    MXS_margins <- c("logit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Probit
  if(NonSurv_Margin == "probit"){
    
    MXS_margins <- c("probit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula,
                          Copula_param_formula)
      
    }
    
  }
  
  # Clog log 
  if(NonSurv_Margin == "cloglog"){
    
    MXS_margins <- c("cloglog", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula,
                          Copula_param_formula)
      
    }
  }
  
  # GEV link
  if(NonSurv_Margin == "GEVlink"){
    
    MXS_margins <- c("GEVlink", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula,
                          Copula_param_formula)
      
    }
  }
  
  
  
  # FIT:
  # Control for the computation time as well 
  model_runtime <- system.time(
    res <- myTryCatch(
      gjrm(
        MXS_formula, 
        data = original_data, 
        BivD = copula_class,      
        # This is MBS with either DTS or PWE margin
        margins = MXS_margins, # Combination of margins
        Model = "B",
        # List of subject ids
        ListOfIDs = INDCS_list,
        # PWE format dataset (long)
        PAMM_dataset = dataset_long_margin2,
        # further arguments
        gc.l = FALSE,
        extra.regI = extra.regularization)
    )
  )
  
  
  
  # Check if the model was actually fitted and there is an output!
  if(!is.null(res$value)){
    
    
    if( !(varying_dependence) ){
    
    # In this case we only care about the copula parameter / kendall's tau:
    if( NonSurv_Margin == "N" ){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      # --- > all prediction points of the spline in 100, equidistant points!
      
      #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      model_coefficients <- coef(res$value)
      
      
      kendall_binary_PWE <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- 200
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels, 
      #                                 function(i) 
      #                                   matrixStats:::rowQuantiles(fit1Sim, 
      #                                                              probs = c(i/2, 1 - i/2), 
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      # 
      # # PWE margin:
      # confints_loghazard <- sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(fit2Sim, 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      # 
      # 
      # confints_hazard <- sapply(prob_levels, 
      #                           function(i) 
      #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
      #                                                        probs = c(i/2, 1 - i/2), 
      #                                                        na.rm = TRUE),
      #                           simplify = FALSE)
      # 
      # 
      # # Compute the cumulative sum correctily:
      # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
      #                          function(i) 
      #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
      #                          simplify = TRUE)
      # 
      # # Compute quantiles
      # confints_cumuhazard <-  sapply(prob_levels, 
      #                                function(i) 
      #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
      #                                                             probs = c(i/2, 1 - i/2), 
      #                                                             na.rm = TRUE),
      #                                simplify = FALSE)
      # 
      # 
      # confints_survival <-  sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      # confint_materials <- list(all_coefficients  = confints_list, 
      #                           binary_spline = confints_binary_spline, 
      #                           loghazard = confints_loghazard, 
      #                           hazard = confints_loghazard, 
      #                           cumuhazard = confints_cumuhazard, 
      #                           survival = confints_survival,
      #                           copula_param = confints_copulaparam,
      #                           kendall_tau = confints_tau)
      
      coverages_materials <-list(tau = coverage_tau,
                                 copula_parameter = coverage_copula_param,
                                 beta_nonsurv_margin = NULL,
                                 beta_surv_margin = NULL)
      
      
      output <- list(model_coefficients = model_coefficients,
                     confints = coverages_materials,
                     estimated_copula_parameter = res$value$theta,
                     estimated_kendall_tau = res$value$tau,
                     nrow_datalong = dim(dataset_long_margin2))
      
      
      
    }
    
    if( NonSurv_Margin %in% c("logit", "probit", "cloglog", "GEVlink") ){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ]
      
      coefficients_survival_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      
      coefficients_copula_parameter <- coef(res$value)[length(coef(res$value))]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <- 0:number_of_ints
      time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$timeInt <- time_synth
      dat_ped_new$timeInt_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <- predict(res$value,
                                      eq = 2,
                                      newdata = dat_ped_ready,
                                      type = "terms")[,4] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]
      
      # Step 5:
      baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard  )
      
      cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
      
      # Step 8:
      survivalfunction <- cumprod( 1 - baseline_hazard )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] )
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit2Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                               function(i)
                                 cumsum( (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                         function(i)
                                           -cumsum( log(1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ) ),
                                         simplify = TRUE)
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                function(i)
                                  cumprod( 1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                 function(i)
                                                   matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                              probs = c(i/2, 1 - i/2),
                                                                              na.rm = TRUE),
                                                 simplify = FALSE)
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      surv_beta_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
      
      
      # This returns a list with the 99% confidence intervals
      surv_marg_confints1 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      surv_marg_confints2 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      surv_marg_confints3 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(surv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage2_surv_margin <- sapply(surv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage3_surv_margin <- sapply(surv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(nonsurv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage2_nonsurv_margin <- sapply(nonsurv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage3_nonsurv_margin <- sapply(nonsurv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                #binary_spline = confints_binary_spline,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                #
                                coverage_beta_nonsurv_margin = list(coverage1_nonsurv_margin,
                                                                    coverage2_nonsurv_margin,
                                                                    coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(coverage1_surv_margin,
                                                                     coverage2_surv_margin,
                                                                     coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      # coverages_materials <-list(tau = coverage_tau,
      #                            copula_parameter = coverage_copula_param,
      #                            beta_nonsurv_margin = NULL,
      #                            beta_surv_margin = NULL)
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        copula_parameter_intercept = copula_parameter_intercept,
        #
        # Smooth functions
        #binary_spline = binary_pred_spline,
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
      
      # output <- list(estimated_copula_parameter = res$value$theta,
      #                estimated_kendall_tau = res$value$tau,
      #                copula_type = copula_class,
      #                coverages = coverages_materials,
      #                correlation_materials = original_data_object$correlations_materials
      # )
      
      
      
    }
    
    if(NonSurv_Margin %in% c("ningunadeestas")){
      
      
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      # --- > all prediction points of the spline in 100, equidistant points!
      
      #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      model_coefficients <- coef(res$value)
      
      
      kendall_binary_PWE <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- 200
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels, 
      #                                 function(i) 
      #                                   matrixStats:::rowQuantiles(fit1Sim, 
      #                                                              probs = c(i/2, 1 - i/2), 
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      # 
      # # PWE margin:
      # confints_loghazard <- sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(fit2Sim, 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      # 
      # 
      # confints_hazard <- sapply(prob_levels, 
      #                           function(i) 
      #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
      #                                                        probs = c(i/2, 1 - i/2), 
      #                                                        na.rm = TRUE),
      #                           simplify = FALSE)
      # 
      # 
      # # Compute the cumulative sum correctily:
      # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
      #                          function(i) 
      #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
      #                          simplify = TRUE)
      # 
      # # Compute quantiles
      # confints_cumuhazard <-  sapply(prob_levels, 
      #                                function(i) 
      #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
      #                                                             probs = c(i/2, 1 - i/2), 
      #                                                             na.rm = TRUE),
      #                                simplify = FALSE)
      # 
      # 
      # confints_survival <-  sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      # confint_materials <- list(all_coefficients  = confints_list, 
      #                           binary_spline = confints_binary_spline, 
      #                           loghazard = confints_loghazard, 
      #                           hazard = confints_loghazard, 
      #                           cumuhazard = confints_cumuhazard, 
      #                           survival = confints_survival,
      #                           copula_param = confints_copulaparam,
      #                           kendall_tau = confints_tau)
      
      coverages_materials <-list(tau = coverage_tau,
                                 copula_parameter = coverage_copula_param,
                                 beta_nonsurv_margin = NULL,
                                 beta_surv_margin = NULL)
      
      
      output <- list(model_coefficients = model_coefficients,
                     confints = coverages_materials,
                     estimated_copula_parameter = res$value$theta,
                     estimated_kendall_tau = res$value$tau,
                     nrow_datalong = dim(dataset_long_margin2))
      
      
      
      
      
      
    }
    
    
    }else{
      
      
      if( NonSurv_Margin %in% c("logit", "probit", "cloglog", "GEVlink") ){
        
        
        # extract Goodness of fit residuals from the survival margin: 
        residuals_materials <- compute_relevant_residuals(model = res$value, 
                                                          data_short = original_data, 
                                                          data_long = dataset_long_margin2, 
                                                          type = "DT", 
                                                          indices = INDCS_list, 
                                                          equation_survmodel = 2)
        
        # Evaluate the fitted model:
        # --- > overall coefficients
        coefficients_nonsurv_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ]
        
        coefficients_survival_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)] 
        
        coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value)) - 1):length(coef(res$value)) ]
        
        
        
        # Survival / margin
        # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
        
        # 1: Create rich sequence of time points for the splines
        # 2: Use predict(, type = "terms")
        # 3: Extract the prediction of only the log( baseline hazard )
        # 4: Add the intercept to all observations
        # 5: Transform into hazard rate, 
        # 6: Obtain original interval lengths (all equidistant)  
        # 7: Obtain the cumu hazard, 
        # 8: Transform into survival function.
        # Step 1: 
        time_synth <- 0:number_of_ints
        time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
        
        dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
        
        dat_ped_new$timeInt <- time_synth
        dat_ped_new$timeInt_margin2 <- time_synth
        
        dat_ped_ready <- dat_ped_new %>% 
          mutate(x1 = 0,
                 x2 = 0,
                 x3 = 0,
                 x5 = 0,
                 x4 = 0,
                 y1 = 0)
        
        # Step 2 + 3 + 4:
        # Intercept is added
        baseline_link_scale <- predict(res$value,
                                       eq = 2,
                                       newdata = dat_ped_ready,
                                       type = "terms")[,4] +
          coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]
        
        # Step 5:
        baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
        
        # Step 6: not needed in DTS
        
        # Step 7:
        cumuhazard_justcumsum <- cumsum( baseline_hazard  )
        
        cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
        
        # Step 8:
        survivalfunction <- cumprod( 1 - baseline_hazard )
        # 
        # 
        ###########################
        ###########################
        
        estimated_kendall_tau <- res$value$tau
        
        # Copula / dependence part 
        # --- > intercept of model of copula parameter
        # --- > copula parameter (in copula parameter scale)
        # --- > kendall´s tau (pred.mvt) with confidence interval
        copula_parameter_intercept <- tail(coef(res$value), 2)[1]
        
        copula_parameter <- res$value$theta
        
        # Check fitted bivariate distribution in the MBS model to 
        # compute the correct Kendall's tau:
        #GAUSS copula
        if(res$value$BivD == "N"){
          
          tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
          
        }
        
        # GUMBEL copula
        if(res$value$BivD == "G0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED GUMBEL copula (90)
        if(res$value$BivD == "G90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          
          tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
          
        }
        
        # CLAYTON copula
        if(res$value$BivD == "C0"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
          
        }
        
        # ROTATED CLAYTON copula (90)
        if(res$value$BivD == "C90"){
          
          theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- - theta_coppar
          
          tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
          
        }
        
        # FRANK copula
        if(copula_class == "F"){
          
          
          signs <- sign(copula_parameter) 
          theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
          theta_coppar <- theta_coppar*signs 
          
          
          tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
          
        }
        
        # JOE copula
        if(res$value$BivD == "J0"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # ROTATED JOE (90)
        if(res$value$BivD == "J90"){
          
          
          theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                                 30, 
                                 abs(copula_parameter)) # based on BiCopPar2Tau 
          
          theta_coppar <- -theta_coppar
          
          tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
          
          
        }
        
        # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
        #        Object Vb 
        #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
        #        function of the mvt normal distr. is used to sample from them!
        #        Obtain the following coverages: 90% ,     95%,        99%
        #                                       (1-0.05),  (1-0.025)   (1-0.005)
        
        # Confidence intervals of all coefficients will be obtained via simulations
        # For transformations of the linear predictor (i.e. survival function, etc): 
        # simulation as well as direct transformation of the linear predictor
        
        # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
        # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
        # Compute quantiles from this sample of size R.  
        # Set the number of simulations from the posterior to: 500, default = 200.
        
        # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
        # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
        # Extract coeffs again
        coefficient_vec <- coef(res$value)
        
        # Extract coeffs
        coeff_cov_mat <- res$value$Vb
        
        n.sim <- n.sim
        
        # Samples from the asymptotic distribution of of the coefficient vector
        bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
        
        
        # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
        # using the typical levels
        prob_levels <- c(0.01, 0.05, 0.1)
        
        confints_list <- sapply(prob_levels, 
                                function(i) matrixStats:::colQuantiles(bs, 
                                                                       probs = c(i/2, 
                                                                                 1 - i/2),
                                                                       na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # For the specific splines:
        # Recover the synthetic values of the covariates:
        # remove other covariates values from the linear predictor: 
        dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
        
        # Obtain various additive predictors: 
        Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
        
        Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
        
        # Compute xbeta for first margin: binary
        fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
        
        # # Compute xbeta for second margin: PWE
        fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)] )
        
        # Copula parameter and then into tau:
        dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
        
        XfitCopParam <- predict(res$value, eq = 3, type = "lpmatrix", newdata = dat_ped_ready_copparam)
        
        # Compute xbeta for copula parameter:
        fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
        
        
      
        
        # Compute now transformation of this: 
        # Binary margin: just the spline: 
        # confints_binary_spline <-sapply(prob_levels,
        #                                 function(i)
        #                                   matrixStats:::rowQuantiles(fit1Sim,
        #                                                              probs = c(i/2, 1 - i/2),
        #                                                              na.rm = TRUE),
        #                                 simplify = FALSE)
        
        # # Survival margin:
        confints_linkscalehazard <- sapply(prob_levels,
                                           function(i)
                                             matrixStats:::rowQuantiles(fit2Sim,
                                                                        probs = c(i/2, 1 - i/2),
                                                                        na.rm = TRUE),
                                           simplify = FALSE)
        
        
        
        confints_hazard <- sapply(prob_levels,
                                  function(i)
                                    matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ),
                                                               probs = c(i/2, 1 - i/2),
                                                               na.rm = TRUE),
                                  simplify = FALSE)
        
        
        # # Compute the cumulative sum correctly:
        fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                                 function(i)
                                   cumsum( (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                                 simplify = TRUE)
        
        
        fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                           function(i)
                                             -cumsum( log(1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ) ),
                                           simplify = TRUE)
        
        
        fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                  function(i)
                                    cumprod( 1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                                  simplify = TRUE)
        
        # # Compute quantiles
        confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                              function(i)
                                                matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                           probs = c(i/2, 1 - i/2),
                                                                           na.rm = TRUE),
                                              simplify = FALSE)
        
        confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                   function(i)
                                                     matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                                probs = c(i/2, 1 - i/2),
                                                                                na.rm = TRUE),
                                                   simplify = FALSE)
        
        confints_survival <-  sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
        
        
        
        
        # For the true value: 
        copparam_true_df <- data.frame(Intercept = 1,
                                       x5_true = seq(-1, +1, length.out = 200)
        )
        
        eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
        
        
        
        # Compute confidence intervals for the copula parameter:
        # GAUSS COPULA
        if(res$value$BivD == "N"){
          
          
          copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                   sign(eta_copparam_true) * 8.75, 
                                   eta_copparam_true)
          
          copparam_true <- tanh(copparam_true) 
          
          
          tau_true <-  2 / pi * asin(copparam_true) 
          
          
          ### FOR CONFIDENCE INTERVALS
          # just a vector of values, since the model is currently has only an intercept:
          fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                  sign(fitCopParSim)*8.75, 
                                  fitCopParSim)
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- tanh(fitCopParSim) 
          
          # computation of TAU:
          fitTauSim <-  2 / pi * asin(fitCopParSim) 
          # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
          
        }
        
        
        # CLAYTON COPULA
        if(res$value$BivD == "C0"){
          
          eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true ) 
          
          eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                   -17, 
                                   eta_copparam_true ) 
          
          copparam_true <- exp( eta_copparam_true )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 28, 
                             28, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- tau_true / ( tau_true + 2 ) 
          
          
          
          
          ##############
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
          
        }
        
        
        # ROTATED CLAYTON COPULA (90)
        if(res$value$BivD == "C90"){
          
          eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                   -17, 
                                   eta_copparam_true )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <-  -( exp( eta_copparam_true ) )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 28, 
                             28, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- -tau_true
          
          tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
          
          
          
          ###########################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <-  -( exp( fitCopParSim ) )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                              28, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
          
          
          
        }
        
        
        # GUMBEL COPULA 
        if(res$value$BivD == "G0"){
          
          eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                   -17, 
                                   eta_copparam_true )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- exp( eta_copparam_true ) + 1   
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 17, 
                             17, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <-  1 - 1 / tau_true 
          
          
          ##############################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp( fitCopParSim ) + 1   
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <-  1 - 1 / fitTauSim 
          
        }
        
        
        # ROTATED GUMBEL COPULA (90)
        if(res$value$BivD == "G90"){
          
          
          
          eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                   -17, 
                                   eta_copparam_true )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- -( exp( eta_copparam_true ) + 1  )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 17, 
                             17, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- -tau_true
          
          tau_true <-  -( 1 - 1 / abs(tau_true) ) 
          
          
          #############################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- -( exp( fitCopParSim ) + 1  )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                              17, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- -fitTauSim
          
          fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
          
        }
        
        
        # JOE COPULA
        if(res$value$BivD == "J0"){
          
          
          eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                   -17, 
                                   eta_copparam_true )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- exp(eta_copparam_true) + 1
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 30, 
                             30, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          
          tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
          
          
          
          
          ################################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- exp(fitCopParSim) + 1
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          
          fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
          
          
        }
        
        
        # ROTATED JOE COPULA (90)
        if(res$value$BivD == "J90"){
          
          
          eta_copparam_true <- ifelse( eta_copparam_true > 20, 
                                   20, 
                                   eta_copparam_true )     # 709, maximum allowed # these values look fine
          
          eta_copparam_true <- ifelse( eta_copparam_true < -17, 
                                   -17, 
                                   eta_copparam_true )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          copparam_true <- - ( exp(eta_copparam_true) + 1 )
          
          # computation of TAU:
          tau_true <- ifelse(abs(copparam_true) > 30, 
                             30, 
                             abs(copparam_true)) # based on BiCopPar2Tau 
          
          tau_true <- - tau_true
          
          tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
          
          
          ##############################
          fitCopParSim <- ifelse( fitCopParSim > 20, 
                                  20, 
                                  fitCopParSim )     # 709, maximum allowed # these values look fine
          
          fitCopParSim <- ifelse( fitCopParSim < -17, 
                                  -17, 
                                  fitCopParSim )   # -20                  # 
          
          
          # compute copula parameter from the additive predictor of
          # the copula parameter:
          fitCopParSim <- - ( exp(fitCopParSim) + 1 )
          
          # computation of TAU:
          fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                              30, 
                              abs(fitCopParSim)) # based on BiCopPar2Tau 
          
          fitTauSim <- - fitTauSim
          
          fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
          
          
        }
        
        
        # FRANK COPULA
        if(res$value$BivD == "F"){
          
          
          epsilon <- c(sqrt(.Machine$double.eps))
          
          eta_copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                   epsilon, 
                                   eta_copparam_true )     
          
          
          signs <- sign(eta_copparam_true) 
          
          eta_copparam_true <- ifelse(abs(eta_copparam_true) > 35, 
                                  35, 
                                  abs(eta_copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
          
          copparam_true <- eta_copparam_true*signs
          
          tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
          
          
          #################
          epsilon <- c(sqrt(.Machine$double.eps))
          
          fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                  epsilon, 
                                  fitCopParSim )     
          
          
          signs <- sign(fitCopParSim) 
          
          fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                                 35, 
                                 abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
          
          fitCopParSim <- fitCopParSim*signs
          
          fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
          
          
        }
        
        
        
        
        
        confints_copulaparam <-  sapply(prob_levels,
                                        function(i)
                                          rowQuantiles(fitCopParSim,
                                                       probs = c(i/2, 1 - i/2),
                                                       na.rm = TRUE),
                                        simplify = FALSE)
        
        
        # intervals for KENDALLs TAU:
        confints_tau <-  sapply(prob_levels,
                                function(i)
                                  rowQuantiles(fitTauSim,
                                               probs = c(i/2, 1 - i/2),
                                               na.rm = TRUE),
                                simplify = FALSE)
        
        
        
        # Compute the coverages:
        coverage_copula_param <- sapply(confints_copulaparam, function(i) 
          
          mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
          
        )
        
        
        
        coverage_tau <- sapply(confints_tau, function(i) 
          
          mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
          
        )
        
        
        
        # extract coefficients of nonsurvival margin
        beta_nonsurv_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
        
        surv_beta_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
        
        copparam_beta_vector <- bs[, (length(coef(res$value))-1):length(coef(res$value)) ]
        
        
        # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
        surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals  of each coefficient!
        surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals  of each coefficient!
        surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
          quantile(surv_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        
        # Now for the nonsurvival margin:
        nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        # This returns a list with the 95% confidence intervals
        nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        # This returns a list with the 90% confidence intervals
        nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
          quantile(beta_nonsurv_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
          quantile(copparam_beta_vector[,i],
                   probs = c(0.01/2, 1 - 0.01/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
          quantile(copparam_beta_vector[,i],
                   probs = c(0.05/2, 1 - 0.05/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
          quantile(copparam_beta_vector[,i],
                   probs = c(0.10/2, 1 - 0.10/2),
                   na.rm = TRUE),
          simplify = FALSE
        )
        
        
        
        # Compute coverages:
        coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                  surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
          
        )
        
        coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                  surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
        )
        
        coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                  surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
        )
        
        
        
        ########### now for the nonsurvival margin:
        coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                  nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
          
        )
        
        coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                  nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
          
        )
        
        coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
          
          #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
          1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                  nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
          
        )
        
        
        
        names(coverage_tau) <- c("99%", "95%", "90%")
        names(coverage_copula_param) <- c("99%", "95%", "90%")
        
        
        
        
        confint_materials <- list(all_coefficients  = confints_list,
                                  linkscale_hazard = confints_linkscalehazard,
                                  hazard = confints_hazard,
                                  cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                  cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                  survival = confints_survival,
                                  copula_param = confints_copulaparam,
                                  kendall_tau = confints_tau, 
                                  #
                                  coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                      ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                      ninetyfive = coverage3_nonsurv_margin),
                                  #
                                  coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                       ninetyseven_pointfive = coverage2_surv_margin,
                                                                       ninetyfive = coverage3_surv_margin),
                                  coverage_tau = coverage_tau,
                                  coverage_copula_parameter = coverage_copula_param
        )
        
        
        
        # Put everything together
        output <- list(
          # Coefficients
          coefficients_nonsurv = coefficients_nonsurv_margin,
          coefficients_survival = coefficients_survival_margin,
          coefficients_copula_parameter = coefficients_copula_parameter,
          #
          #
          residuals_materials = residuals_materials,
          #
          # Smooth functions
          linkscale_baseline = baseline_link_scale,
          baseline = baseline_hazard,
          cumu_hazard = cumuhazard_justcumsum,
          cumu_hazard_logoneminus = cumuhazard_logoneminus,
          survival = survivalfunction,
          #
          # copula parameter and dependence
          copula_parameter = copula_parameter,
          tau_of_kendall = tau_of_kendall,
          #
          # Big matrix of coefficient's confidence intervals:
          confint_materials = confint_materials,
          #
          # Various summaries
          survival_data_n = nrow(dataset_long_margin2),
          original_data_n = nrow(original_data),
          edf_nonsurvival_margin = res$value$edf[[1]],
          edf_survival_margin = res$value$edf[[2]],
          #
          #
          #
          # Stuff regarding estimated kendall taus 
          estimated_kendall = res$value$tau,
          copula_parameter_estimate = res$value$theta,
          # some other diagnostics
          cuts_placement_intime = the_used_cuts,
          the_unique_tends = the_unique_tends,
          the_warning = res$warning,
          the_error = res$error,
          model_runtime = model_runtime
        )
        
        
        
      }
      
      
    }
    
    
  }else{
    
    output <- list(the_warning = res$warning,
                   the_error = res$error)
    
  }
  
  
  rm(res)
  
  return(output)
  
  
}







# The fitting function: Recursive PWE is not used
fit_MXS_recursive_PWE <- function(original_data_object, 
                              copula_class = "N", 
                              # non-survival marginal response
                              NonSurv_Margin = "N",
                              # cuts / intervals
                              number_of_ints = 25, 
                              #
                              maximum_time_cut = 8.1,
                              #
                              varying_dependence = FALSE,
                              # smooth the baseline function of time on time scale or log(time) scale
                              baseline_smooth = "log",
                              # for confidence intervals
                              n.sim = 500,
                              # further arguments
                              hess_reg = "t"
){
  
  original_data <- original_data_object$dataset
  
  # extra reg settings:
  extra.regularization <- hess_reg
  
  
  the_used_cuts <- seq(from = 0,  
                       to = maximum_time_cut, 
                       length.out = number_of_ints)
  
  
  # Create augmented dataset for piecewise exponential margin!
  dat_ped <- as_ped(Surv(time, status) ~ x1 + x2 + x3 + x4 + x5 + y1, 
                    cut = seq(from = 0, 
                              #to = max(original_data$time), 
                              to = maximum_time_cut, 
                              length.out = number_of_ints),
                    data = original_data)
  
  the_used_cuts <- seq(from = 0, 
                       to = maximum_time_cut, 
                       length.out = number_of_ints)
  
  the_unique_tends <- unique(dat_ped$tend)
  
  
  # declare IDs as factor:
  dat_ped$id <- factor(dat_ped$id)
  
  # Create list of indices: (ABSOLUTELY NECESSARY FOR MBS)
  INDCS_list <- sapply(levels(dat_ped$id), 
                       function(i) which(dat_ped$id == i), 
                       simplify = FALSE)
  
  
  # attach ped_status in the model:
  # this is to trick GJRM into fitting!
  original_data$ped_status <- unlist(lapply(INDCS_list, function(i) tail(i, 1)))
  original_data$tend <- dat_ped$tend[original_data$ped_status]
  
  dataset_long_margin2 <- dat_ped
  
  
  ###########################################################################################################
  #  formula, i.e. smooth baseline hazard using splines
  DTS_formula <- as.formula( ped_status ~ s(tend, bs = "ps", k = 10, m = 2) + 
                               y1 +
                               x2 +
                               x4
  )
  
  
  # smooth time on the log() scale (for smoother results according to literature)
  DTS_log_formula <- as.formula( ped_status ~ s(log(as.numeric(tend)), bs = "ps", k = 10,  m = 2) +
                                  y1 +
                                  + x2 
                                  + x4
  )
  
  # Formula for dependence parameter (necessary in some cases)
  Copula_param_formula <- as.formula( ~ 1)
  
  
  #### CONTINUOUS
  # Gaussian
  if(NonSurv_Margin == "N"){
    
    MXS_margins <- c("PO", "N")
    
    #NonSurv_Mar_formula <- as.formula(y1 ~ 1)#x1 + x2 + s(x3, bs = "ps", k = 10, m = 2))
    #NonSurv_Mar_Param2_formula <- as.formula( ~  1)
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  1)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Log-normal
  if(NonSurv_Margin == "LN"){
    MXS_margins <- c("PO", "LN")
  }
  
  # Logistic
  if(NonSurv_Margin == "LO"){
    MXS_margins <- c("PO", "LO")
  }
  
  # Beta
  if(NonSurv_Margin == "BE"){
    MXS_margins <- c("PO", "BE")
  }
  
  # Log-logistic
  if(NonSurv_Margin == "FISK"){
    MXS_margins <- c("PO", "FISK")
  }
  
  # Dagum
  if(NonSurv_Margin == "DAGUM"){
    MXS_margins <- c("PO", "DAGUM")
  }
  
  
  #### DISCRETE 
  # Poisson
  if(NonSurv_Margin == "PO"){
    
    MXS_margins <- c("PO", "PO")
    
    
    NonSurv_Mar_formula <- as.formula(y1 ~ 1)#x1 + x2 + s(x3, bs = "ps", k = 10, m = 2))
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula)
      
    }
  }
  
  # Negative binomial I 
  if(NonSurv_Margin == "NBI"){
    MXS_margins <- c("PO", "NBI")
  }
  
  # Negative binomial I 
  if(NonSurv_Margin == "NBII"){
    MXS_margins <- c("PO", "NBII")
  }
  
  
  #### BINARY 
  # Logit
  if(NonSurv_Margin == "logit"){
    
    MXS_margins <- c("logit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
  }
  
  # Probit
  if(NonSurv_Margin == "probit"){
    
    MXS_margins <- c("probit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
    
  }
  
  # Clog log 
  if(NonSurv_Margin == "cloglog"){
    
    MXS_margins <- c("cloglog", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
  }
  
  # GEV link
  if(NonSurv_Margin == "GEVlink"){
    
    MXS_margins <- c("GEVlink", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
  }
  
  
  
  # FIT:
  # Control for the computation time as well 
  model_runtime <- system.time(
    res <- myTryCatch(
      gjrm(
        MXS_formula, 
        data = original_data, 
        BivD = copula_class,      
        # This is MBS with either DTS or PWE margin
        margins = MXS_margins, # Combination of margins
        Model = "B",
        # List of subject ids
        ListOfIDs = INDCS_list,
        # PWE format dataset (long)
        PAMM_dataset = dataset_long_margin2, 
        PAMM_offset = dataset_long_margin2$offset,
        # further arguments
        gc.l = FALSE,
        extra.regI = extra.regularization)
    )
  )
  
  
  
  # Check if the model was actually fitted and there is an output!
  if(!is.null(res$value)){
    
    # In this case we only care about the copula parameter / kendall's tau:
    if( NonSurv_Margin == "N" ){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      # --- > all prediction points of the spline in 100, equidistant points!
      
      #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      model_coefficients <- coef(res$value)
      
      
      kendall_binary_PWE <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- 200
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels, 
      #                                 function(i) 
      #                                   matrixStats:::rowQuantiles(fit1Sim, 
      #                                                              probs = c(i/2, 1 - i/2), 
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      # 
      # # PWE margin:
      # confints_loghazard <- sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(fit2Sim, 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      # 
      # 
      # confints_hazard <- sapply(prob_levels, 
      #                           function(i) 
      #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
      #                                                        probs = c(i/2, 1 - i/2), 
      #                                                        na.rm = TRUE),
      #                           simplify = FALSE)
      # 
      # 
      # # Compute the cumulative sum correctily:
      # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
      #                          function(i) 
      #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
      #                          simplify = TRUE)
      # 
      # # Compute quantiles
      # confints_cumuhazard <-  sapply(prob_levels, 
      #                                function(i) 
      #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
      #                                                             probs = c(i/2, 1 - i/2), 
      #                                                             na.rm = TRUE),
      #                                simplify = FALSE)
      # 
      # 
      # confints_survival <-  sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      # confint_materials <- list(all_coefficients  = confints_list, 
      #                           binary_spline = confints_binary_spline, 
      #                           loghazard = confints_loghazard, 
      #                           hazard = confints_loghazard, 
      #                           cumuhazard = confints_cumuhazard, 
      #                           survival = confints_survival,
      #                           copula_param = confints_copulaparam,
      #                           kendall_tau = confints_tau)
      
      coverages_materials <-list(tau = coverage_tau,
                                 copula_parameter = coverage_copula_param,
                                 beta_nonsurv_margin = NULL,
                                 beta_surv_margin = NULL)
      
      
      output <- list(model_coefficients = model_coefficients,
                     confints = coverages_materials,
                     estimated_copula_parameter = res$value$theta,
                     estimated_kendall_tau = res$value$tau,
                     nrow_datalong = dim(dataset_long_margin2))
      
      
      
    }
    
    if( NonSurv_Margin %in% c("logit", "probit", "cloglog", "GEVlink") ){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ]
      
      coefficients_survival_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      
      coefficients_copula_parameter <- coef(res$value)[length(coef(res$value))]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <- seq(from = 0, 
                        to = maximum_time_cut, 
                        length.out = number_of_ints)
      
      time_synth2 <- seq(from = 0,  
                         to = maximum_time_cut, 
                         length.out = number_of_ints)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$timeInt <- time_synth
      dat_ped_new$timeInt_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      dat_ped_ready <- make_newdata(dataset_long_margin2, tend = time_synth[-1]) %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <- predict(res$value,
                                     eq = 2,
                                     newdata = dat_ped_ready,
                                     type = "terms")[,4] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]
      
      # Step 5:
      baseline_hazard <- exp( baseline_link_scale )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard * exp(dat_ped_ready$offset) )
      
      cumuhazard_logoneminus <- NULL
      
      # Step 8:
      survivalfunction <- exp( - cumuhazard_justcumsum )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_ready %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] )
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit2Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles( exp( fit2Sim ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                               function(i)
                                 cumsum( exp(fit2Sim[,i] * dat_new$offset ) ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- NULL
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                function(i)
                                 exp( - exp(fit2Sim[,i] ) * dat_new$offset),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <-  NULL
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      surv_beta_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
      
      
      # This returns a list with the 99% confidence intervals
      surv_marg_confints1 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      surv_marg_confints2 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      surv_marg_confints3 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(surv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage2_surv_margin <- sapply(surv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage3_surv_margin <- sapply(surv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(nonsurv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage2_nonsurv_margin <- sapply(nonsurv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage3_nonsurv_margin <- sapply(nonsurv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                #binary_spline = confints_binary_spline,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                #
                                coverage_beta_nonsurv_margin = list(coverage1_nonsurv_margin,
                                                                    coverage2_nonsurv_margin,
                                                                    coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(coverage1_surv_margin,
                                                                     coverage2_surv_margin,
                                                                     coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      # coverages_materials <-list(tau = coverage_tau,
      #                            copula_parameter = coverage_copula_param,
      #                            beta_nonsurv_margin = NULL,
      #                            beta_surv_margin = NULL)
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        copula_parameter_intercept = copula_parameter_intercept,
        #
        # Smooth functions
        #binary_spline = binary_pred_spline,
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
      
      # output <- list(estimated_copula_parameter = res$value$theta,
      #                estimated_kendall_tau = res$value$tau,
      #                copula_type = copula_class,
      #                coverages = coverages_materials,
      #                correlation_materials = original_data_object$correlations_materials
      # )
      
      
      
    }
    
    if(NonSurv_Margin %in% c("ningunadeestas")){
      
      
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      # --- > all prediction points of the spline in 100, equidistant points!
      
      #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      model_coefficients <- coef(res$value)
      
      
      kendall_binary_PWE <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- 200
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels, 
      #                                 function(i) 
      #                                   matrixStats:::rowQuantiles(fit1Sim, 
      #                                                              probs = c(i/2, 1 - i/2), 
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      # 
      # # PWE margin:
      # confints_loghazard <- sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(fit2Sim, 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      # 
      # 
      # confints_hazard <- sapply(prob_levels, 
      #                           function(i) 
      #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
      #                                                        probs = c(i/2, 1 - i/2), 
      #                                                        na.rm = TRUE),
      #                           simplify = FALSE)
      # 
      # 
      # # Compute the cumulative sum correctily:
      # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
      #                          function(i) 
      #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
      #                          simplify = TRUE)
      # 
      # # Compute quantiles
      # confints_cumuhazard <-  sapply(prob_levels, 
      #                                function(i) 
      #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
      #                                                             probs = c(i/2, 1 - i/2), 
      #                                                             na.rm = TRUE),
      #                                simplify = FALSE)
      # 
      # 
      # confints_survival <-  sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      # confint_materials <- list(all_coefficients  = confints_list, 
      #                           binary_spline = confints_binary_spline, 
      #                           loghazard = confints_loghazard, 
      #                           hazard = confints_loghazard, 
      #                           cumuhazard = confints_cumuhazard, 
      #                           survival = confints_survival,
      #                           copula_param = confints_copulaparam,
      #                           kendall_tau = confints_tau)
      
      coverages_materials <-list(tau = coverage_tau,
                                 copula_parameter = coverage_copula_param,
                                 beta_nonsurv_margin = NULL,
                                 beta_surv_margin = NULL)
      
      
      output <- list(model_coefficients = model_coefficients,
                     confints = coverages_materials,
                     estimated_copula_parameter = res$value$theta,
                     estimated_kendall_tau = res$value$tau,
                     nrow_datalong = dim(dataset_long_margin2))
      
      
      
      
      
      
    }
    
    
    
    
    
  }else{
    
    output <- list(the_warning = res$warning,
                   the_error = res$error)
    
  }
  
  
  rm(res)
  
  return(output)
  
  
}





# Recursive with endogenous discrete variable
fit_MXS_discrete_recursive <- function(original_data_object, 
                                       copula_class = "N", 
                                       # non-survival marginal response
                                       NonSurv_Margin = "N",
                                       # cuts / intervals
                                       number_of_ints = 25, 
                                       #
                                       maximum_time_cut = 18.5,
                                       #
                                       varying_dependence = FALSE,
                                       #
                                       endogeneity_funcform = "nonlinear",
                                       # smooth the baseline function of time on time scale or log(time) scale
                                       baseline_smooth = "log",
                                       # for confidence intervals
                                       n.sim = 500,
                                       # further arguments
                                       hess_reg = "t"
){
  
  original_data <- original_data_object$dataset
  
  # extra reg settings:
  extra.regularization <- hess_reg
  
  
  the_used_cuts <- seq(from = 0,  
                       to = maximum_time_cut, 
                       length.out = number_of_ints)
  
  # ADDED ONE SYNTHETIC OBSERVATION OT GET DATALONG TO WORK:
  # original_data_synth <- original_data[nrow(original_data), ]
  # original_data_synth$status <- 0
  # 
  # original_data[(nrow(original_data)+1), ] <- original_data_synth
  
  # create intervals:
  # 0 is always included in this function, so remove it from the vector of the_used_cuts!
  dat_disc <-  contToDisc(dataShort = original_data, 
                          timeColumn = "time", 
                          intervalLimits = the_used_cuts[-1]
  )
  
  
  # Adjustment for identification (see documentation of discSurv)
  dat_disc$timeDisc[dat_disc$timeDisc == max(dat_disc$timeDisc)] <- tail(sort(unique(dat_disc$timeDisc)), 2)[1]
  dat_disc$status[dat_disc$timeDisc == max(dat_disc$timeDisc)] <- 0
  
  
  # create long-format for survival margin (called internally margin 2 but enters the
  # fitting function and is treated there as margin 1)
  dataset_long_margin2 <- discSurv:::dataLong(dat_disc, 
                                              timeColumn = "timeDisc", 
                                              eventColumn = "status")
  
  # create list of indices for margin 2 
  INDCS_list <- sapply(levels(as.factor(dataset_long_margin2$obj)), 
                       function(i) which(dataset_long_margin2$obj == i), 
                       simplify = FALSE)
  
  
  # extract unique values of time intervals:
  the_unique_tends <- unique(dat_disc$timeDisc)
  
  
  # attach ped_status in the model:
  # this is to trick GJRM into fitting!
  original_data$y_margin2 <- sample(dataset_long_margin2$y, size = nrow(original_data), replace = TRUE)
  original_data$timeInt_margin2 <- sample(dataset_long_margin2$y, size = nrow(original_data), replace = TRUE)
  
  # rename in long dataset to avoid any issues
  dataset_long_margin2$y_margin2 <- dataset_long_margin2$y
  dataset_long_margin2$timeInt_margin2 <- dataset_long_margin2$timeInt
  
  
  
  ###########################################################################################################
  # DTS formula, i.e. smooth baseline hazard using splines
  
  if(endogeneity_funcform == "nonlinear"){
    
    DTS_formula <- as.formula( y_margin2 ~ s(timeInt_margin2, bs = "ps", k = 10, m = 2) + 
                                 s(y1, k = 6, m = 2) +
                                 x2 +
                                 x4
    )
    
    
    # smooth time on the log() scale (for smoother results according to literature)
    DTS_log_formula <- as.formula(y_margin2 ~ s(log(as.numeric(timeInt_margin2)), bs = "ps", k = 10,  m = 2) +
                                  s(y1, bs = "ps", k = 6, m = 2) +
                                  + x2 
                                  + x4
    )
    
    
  }
  
  if(endogeneity_funcform == "linear"){
  
  DTS_formula <- as.formula( y_margin2 ~ s(timeInt_margin2, bs = "ps", k = 10, m = 2) + 
                               y1 +
                               x2 +
                               x4
  )
  
  
  # smooth time on the log() scale (for smoother results according to literature)
  DTS_log_formula <- as.formula(y_margin2 ~ s(log(as.numeric(timeInt_margin2)), bs = "ps", k = 10,  m = 2) +
                                  y1 +
                                  x2 +
                                  x4
  )
  
  }
  
  # Formula for dependence parameter (necessary in some cases)
  if(varying_dependence){
    
    Copula_param_formula <- as.formula( ~ 1 + x5)
    
  }else{
    
    Copula_param_formula <- as.formula( ~ 1)
  }
  
  
  #### CONTINUOUS
  # Gaussian
  if(NonSurv_Margin == "N"){
    
    MXS_margins <- c("PO", "N")
    
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  1)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Log-normal
  if(NonSurv_Margin == "LN"){
    MXS_margins <- c("PO", "LN")
  }
  
  # Logistic
  if(NonSurv_Margin == "LO"){
    MXS_margins <- c("PO", "LO")
  }
  
  # Beta
  if(NonSurv_Margin == "BE"){
    MXS_margins <- c("PO", "BE")
  }
  
  # Log-logistic
  if(NonSurv_Margin == "FISK"){
    MXS_margins <- c("PO", "FISK")
  }
  
  # Dagum
  if(NonSurv_Margin == "DAGUM"){
    MXS_margins <- c("PO", "DAGUM")
  }
  
  
  #### DISCRETE 
  # Poisson
  if(NonSurv_Margin == "PO"){
    
    MXS_margins <- c("PO", "PO")
    
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Negative binomial I 
  if(NonSurv_Margin == "NBI"){
    
    MXS_margins <- c("PO", "NBI")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Negative binomial I 
  if(NonSurv_Margin == "NBII"){
    
    MXS_margins <- c("PO", "NBII")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
  }
  
  
  #### BINARY 
  # Logit
  if(NonSurv_Margin == "logit"){
    
    MXS_margins <- c("logit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
  }
  
  # Probit
  if(NonSurv_Margin == "probit"){
    
    MXS_margins <- c("probit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
    
  }
  
  # Clog log 
  if(NonSurv_Margin == "cloglog"){
    
    MXS_margins <- c("cloglog", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
  }
  
  # GEV link
  if(NonSurv_Margin == "GEVlink"){
    
    MXS_margins <- c("GEVlink", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
  }
  
  
  
  # FIT:
  # Control for the computation time as well 
  model_runtime <- system.time(
    res <- myTryCatch(
      gjrm(
        MXS_formula, 
        data = original_data, 
        BivD = copula_class,      
        # This is MBS with either DTS or PWE margin
        margins = MXS_margins, # Combination of margins
        Model = "B",
        # List of subject ids
        ListOfIDs = INDCS_list,
        # PWE format dataset (long)
        PAMM_dataset = dataset_long_margin2,
        # further arguments
        gc.l = FALSE,
        extra.regI = extra.regularization)
    )
  )
  
  
  
  # Check if the model was actually fitted and there is an output!
  if(!is.null(res$value)){
    
    # In this case we only care about the copula parameter / kendall's tau:
    if( NonSurv_Margin == "N" ){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      # --- > all prediction points of the spline in 100, equidistant points!
      
      #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      model_coefficients <- coef(res$value)
      
      
      kendall_binary_PWE <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- 200
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels, 
      #                                 function(i) 
      #                                   matrixStats:::rowQuantiles(fit1Sim, 
      #                                                              probs = c(i/2, 1 - i/2), 
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      # 
      # # PWE margin:
      # confints_loghazard <- sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(fit2Sim, 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      # 
      # 
      # confints_hazard <- sapply(prob_levels, 
      #                           function(i) 
      #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
      #                                                        probs = c(i/2, 1 - i/2), 
      #                                                        na.rm = TRUE),
      #                           simplify = FALSE)
      # 
      # 
      # # Compute the cumulative sum correctily:
      # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
      #                          function(i) 
      #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
      #                          simplify = TRUE)
      # 
      # # Compute quantiles
      # confints_cumuhazard <-  sapply(prob_levels, 
      #                                function(i) 
      #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
      #                                                             probs = c(i/2, 1 - i/2), 
      #                                                             na.rm = TRUE),
      #                                simplify = FALSE)
      # 
      # 
      # confints_survival <-  sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      # confint_materials <- list(all_coefficients  = confints_list, 
      #                           binary_spline = confints_binary_spline, 
      #                           loghazard = confints_loghazard, 
      #                           hazard = confints_loghazard, 
      #                           cumuhazard = confints_cumuhazard, 
      #                           survival = confints_survival,
      #                           copula_param = confints_copulaparam,
      #                           kendall_tau = confints_tau)
      
      coverages_materials <-list(tau = coverage_tau,
                                 copula_parameter = coverage_copula_param,
                                 beta_nonsurv_margin = NULL,
                                 beta_surv_margin = NULL)
      
      
      output <- list(model_coefficients = model_coefficients,
                     confints = coverages_materials,
                     estimated_copula_parameter = res$value$theta,
                     estimated_kendall_tau = res$value$tau,
                     nrow_datalong = dim(dataset_long_margin2))
      
      
      
    }
    
    if( NonSurv_Margin %in% c("logit", "probit", "cloglog", "GEVlink") ){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ]
      
      coefficients_survival_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      
      coefficients_copula_parameter <- coef(res$value)[length(coef(res$value))]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <- 0:number_of_ints
      time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$timeInt <- time_synth
      dat_ped_new$timeInt_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <- predict(res$value,
                                     eq = 2,
                                     newdata = dat_ped_ready,
                                     type = "terms")[,4] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]
      
      # Step 5:
      baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard  )
      
      cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
      
      # Step 8:
      survivalfunction <- cumprod( 1 - baseline_hazard )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] )
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit2Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                               function(i)
                                 cumsum( (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                         function(i)
                                           -cumsum( log(1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ) ),
                                         simplify = TRUE)
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                function(i)
                                  cumprod( 1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                 function(i)
                                                   matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                              probs = c(i/2, 1 - i/2),
                                                                              na.rm = TRUE),
                                                 simplify = FALSE)
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      surv_beta_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
      
      
      # This returns a list with the 99% confidence intervals
      surv_marg_confints1 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      surv_marg_confints2 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      surv_marg_confints3 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(surv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage2_surv_margin <- sapply(surv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage3_surv_margin <- sapply(surv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(nonsurv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage2_nonsurv_margin <- sapply(nonsurv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage3_nonsurv_margin <- sapply(nonsurv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                #binary_spline = confints_binary_spline,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                #
                                coverage_beta_nonsurv_margin = list(coverage1_nonsurv_margin,
                                                                    coverage2_nonsurv_margin,
                                                                    coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(coverage1_surv_margin,
                                                                     coverage2_surv_margin,
                                                                     coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      # coverages_materials <-list(tau = coverage_tau,
      #                            copula_parameter = coverage_copula_param,
      #                            beta_nonsurv_margin = NULL,
      #                            beta_surv_margin = NULL)
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        copula_parameter_intercept = copula_parameter_intercept,
        #
        # Smooth functions
        #binary_spline = binary_pred_spline,
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
      
      # output <- list(estimated_copula_parameter = res$value$theta,
      #                estimated_kendall_tau = res$value$tau,
      #                copula_type = copula_class,
      #                coverages = coverages_materials,
      #                correlation_materials = original_data_object$correlations_materials
      # )
      
      
      
    }
    
    if( NonSurv_Margin == "PO" ){
      
      # extract Goodness of fit residuals from the survival margin: 
      residuals_materials <- myTryCatch(compute_relevant_residuals(model = res$value, 
                                                        data_short = original_data, 
                                                        data_long = dataset_long_margin2, 
                                                        type = "DT", 
                                                        indices = INDCS_list, 
                                                        equation_survmodel = 1))
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)]
      
      coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
      
      coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <- 0:number_of_ints
      time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$timeInt <- time_synth
      dat_ped_new$timeInt_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <- predict(res$value,
                                     eq = 1,
                                     newdata = dat_ped_ready,
                                     type = "terms")[,3] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
      
      # Step 5:
      baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard  )
      
      cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
      
      # Step 8:
      survivalfunction <- cumprod( 1 - baseline_hazard )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),2)[1]
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0, y1 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)] )
      
      # Copula parameter and then into tau:
      dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
      
      XfitCopParam <- predict(res$value, eq = 3, type = "lpmatrix", newdata = dat_ped_ready_copparam)
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
      
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit1Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit1Sim),
                               function(i)
                                 cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- sapply(1:ncol(fit1Sim),
                                         function(i)
                                           -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                         simplify = TRUE)
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit1Sim),
                                function(i)
                                  cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                 function(i)
                                                   matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                              probs = c(i/2, 1 - i/2),
                                                                              na.rm = TRUE),
                                                 simplify = FALSE)
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      ## endogenous spline
      endo_spline_data <- data.frame(y1 = seq(0, 10, length.out = 100),
                                     x1 = 0,
                                     x2 = 0,
                                     x4 = 0,
                                     x5 = 0,
                                     timeInt_margin2 = 0)
      
      estimated_endo_spline <- predict(res$value, eq = 1, type = "terms", newdata = endo_spline_data)[ , 4 ]
      
      
      XfitEndo <- predict(res$value, eq = 1, type = "lpmatrix", newdata = endo_spline_data)
      
      XfitEndo[,1] <- 0
      
      XfitEndo <- XfitEndo[,  13:ncol(XfitEndo) ]
      
      fit2SimEndo <- XfitEndo %*% t(bs[, 13:17 ])
      
      confints_endo_spline <- sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2SimEndo,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
      
      # For the true value: 
      copparam_true_df <- data.frame(Intercept = 1,
                                     x5_true = seq(-1, +1, length.out = 200)
      )
      
      eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        
        copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                 sign(eta_copparam_true) * 8.75, 
                                 eta_copparam_true)
        
        copparam_true <- tanh(copparam_true) 
        
        
        tau_true <-  2 / pi * asin(copparam_true) 
        
        
        ### FOR CONFIDENCE INTERVALS
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true ) 
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true ) 
        
        copparam_true <- exp( copparam_true )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- tau_true / ( tau_true + 2 ) 
        
        
        
        
        ##############
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <-  -( exp( copparam_true ) )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
        
        
        
        ###########################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp( copparam_true ) + 1   
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <-  1 - 1 / tau_true 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- -( exp( copparam_true ) + 1  )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <-  -( 1 - 1 / abs(tau_true) ) 
        
        
        #############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp(copparam_true) + 1
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        
        tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
        
        
        
        
        ################################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- - ( exp(copparam_true) + 1 )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- - tau_true
        
        tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                 epsilon, 
                                 eta_copparam_true )     
        
        
        signs <- sign(copparam_true) 
        
        copparam_true <- ifelse(abs(copparam_true) > 35, 
                                35, 
                                abs(copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        copparam_true <- copparam_true*signs
        
        tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
        
        
        #################
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        rowQuantiles(fitCopParSim,
                                                     probs = c(i/2, 1 - i/2),
                                                     na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                rowQuantiles(fitTauSim,
                                             probs = c(i/2, 1 - i/2),
                                             na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
      
      surv_beta_vector <-  bs[ , 1:3 ]#bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      copparam_beta_vector <- bs[, (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
      surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals  of each coefficient!
      surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals  of each coefficient!
      surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
        
      )
      
      coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
      )
      
      coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
      )
      
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
        
      )
      
      coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
        
      )
      
      coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                confints_endo_spline = confints_endo_spline,
                                #
                                coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                    ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                    ninetyfive = coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                     ninetyseven_pointfive = coverage2_surv_margin,
                                                                     ninetyfive = coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        coefficients_copula_parameter = coefficients_copula_parameter,
        #
        #
        estimated_endo_spline = estimated_endo_spline,
        #
        #
        residuals_materials = residuals_materials,
        #
        # Smooth functions
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus 
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
    }
    
    if( NonSurv_Margin %in% c("NBI", "NBII") ){
      
      # extract Goodness of fit residuals from the survival margin: 
      residuals_materials <- myTryCatch(compute_relevant_residuals(model = res$value, 
                                                                   data_short = original_data, 
                                                                   data_long = dataset_long_margin2, 
                                                                   type = "DT", 
                                                                   indices = INDCS_list, 
                                                                   equation_survmodel = 1))
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)]
      
      coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
      
      coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <- 0:number_of_ints
      time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$timeInt <- time_synth
      dat_ped_new$timeInt_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <- predict(res$value,
                                     eq = 1,
                                     newdata = dat_ped_ready,
                                     type = "terms")[,3] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
      
      # Step 5:
      baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard  )
      
      cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
      
      # Step 8:
      survivalfunction <- cumprod( 1 - baseline_hazard )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),2)[1]
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0, y1 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 4)] )
      
      # Copula parameter and then into tau:
      dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
      
      XfitCopParam <- predict(res$value, eq = 4, type = "lpmatrix", newdata = dat_ped_ready_copparam)
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
      
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit1Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit1Sim),
                               function(i)
                                 cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- sapply(1:ncol(fit1Sim),
                                         function(i)
                                           -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                         simplify = TRUE)
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit1Sim),
                                function(i)
                                  cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                 function(i)
                                                   matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                              probs = c(i/2, 1 - i/2),
                                                                              na.rm = TRUE),
                                                 simplify = FALSE)
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      ## endogenous spline
      endo_spline_data <- data.frame(y1 = seq(0, 10, length.out = 100),
                                     x1 = 0,
                                     x2 = 0,
                                     x4 = 0,
                                     x5 = 0,
                                     timeInt_margin2 = 0)
      
      estimated_endo_spline <- predict(res$value, eq = 1, type = "terms", newdata = endo_spline_data)[ , 4 ]
      
      
      XfitEndo <- predict(res$value, eq = 1, type = "lpmatrix", newdata = endo_spline_data)
      
      XfitEndo[,1] <- 0
      
      XfitEndo <- XfitEndo[,  13:ncol(XfitEndo) ]
      
      fit2SimEndo <- XfitEndo %*% t(bs[, 13:17 ])
      
      confints_endo_spline <- sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2SimEndo,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
      
      # For the true value: 
      copparam_true_df <- data.frame(Intercept = 1,
                                     x5_true = seq(-1, +1, length.out = 200)
      )
      
      eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        
        copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                 sign(eta_copparam_true) * 8.75, 
                                 eta_copparam_true)
        
        copparam_true <- tanh(copparam_true) 
        
        
        tau_true <-  2 / pi * asin(copparam_true) 
        
        
        ### FOR CONFIDENCE INTERVALS
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true ) 
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true ) 
        
        copparam_true <- exp( copparam_true )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- tau_true / ( tau_true + 2 ) 
        
        
        
        
        ##############
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <-  -( exp( copparam_true ) )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
        
        
        
        ###########################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp( copparam_true ) + 1   
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <-  1 - 1 / tau_true 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- -( exp( copparam_true ) + 1  )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <-  -( 1 - 1 / abs(tau_true) ) 
        
        
        #############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp(copparam_true) + 1
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        
        tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
        
        
        
        
        ################################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- - ( exp(copparam_true) + 1 )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- - tau_true
        
        tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                 epsilon, 
                                 eta_copparam_true )     
        
        
        signs <- sign(copparam_true) 
        
        copparam_true <- ifelse(abs(copparam_true) > 35, 
                                35, 
                                abs(copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        copparam_true <- copparam_true*signs
        
        tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
        
        
        #################
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        rowQuantiles(fitCopParSim,
                                                     probs = c(i/2, 1 - i/2),
                                                     na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                rowQuantiles(fitTauSim,
                                             probs = c(i/2, 1 - i/2),
                                             na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 4) ]
      
      surv_beta_vector <-  bs[ , 1:3 ]#bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      copparam_beta_vector <- bs[, (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
      surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals  of each coefficient!
      surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals  of each coefficient!
      surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
        
      )
      
      coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
      )
      
      coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
      )
      
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
        
      )
      
      coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
        
      )
      
      coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                confints_endo_spline = confints_endo_spline,
                                #
                                coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                    ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                    ninetyfive = coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                     ninetyseven_pointfive = coverage2_surv_margin,
                                                                     ninetyfive = coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        coefficients_copula_parameter = coefficients_copula_parameter,
        #
        #
        estimated_endo_spline = estimated_endo_spline,
        #
        #
        residuals_materials = residuals_materials,
        #
        # Smooth functions
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus 
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
    }
    
    if(NonSurv_Margin %in% c("ningunadeestas")){
      
      
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      # --- > all prediction points of the spline in 100, equidistant points!
      
      #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      model_coefficients <- coef(res$value)
      
      
      kendall_binary_PWE <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- 200
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels, 
      #                                 function(i) 
      #                                   matrixStats:::rowQuantiles(fit1Sim, 
      #                                                              probs = c(i/2, 1 - i/2), 
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      # 
      # # PWE margin:
      # confints_loghazard <- sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(fit2Sim, 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      # 
      # 
      # confints_hazard <- sapply(prob_levels, 
      #                           function(i) 
      #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
      #                                                        probs = c(i/2, 1 - i/2), 
      #                                                        na.rm = TRUE),
      #                           simplify = FALSE)
      # 
      # 
      # # Compute the cumulative sum correctily:
      # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
      #                          function(i) 
      #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
      #                          simplify = TRUE)
      # 
      # # Compute quantiles
      # confints_cumuhazard <-  sapply(prob_levels, 
      #                                function(i) 
      #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
      #                                                             probs = c(i/2, 1 - i/2), 
      #                                                             na.rm = TRUE),
      #                                simplify = FALSE)
      # 
      # 
      # confints_survival <-  sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      # confint_materials <- list(all_coefficients  = confints_list, 
      #                           binary_spline = confints_binary_spline, 
      #                           loghazard = confints_loghazard, 
      #                           hazard = confints_loghazard, 
      #                           cumuhazard = confints_cumuhazard, 
      #                           survival = confints_survival,
      #                           copula_param = confints_copulaparam,
      #                           kendall_tau = confints_tau)
      
      coverages_materials <-list(tau = coverage_tau,
                                 copula_parameter = coverage_copula_param,
                                 beta_nonsurv_margin = NULL,
                                 beta_surv_margin = NULL)
      
      
      output <- list(model_coefficients = model_coefficients,
                     confints = coverages_materials,
                     estimated_copula_parameter = res$value$theta,
                     estimated_kendall_tau = res$value$tau,
                     nrow_datalong = dim(dataset_long_margin2))
      
      
      
      
      
      
    }
    
    
    
    
    
  }else{
    
    output <- list(the_warning = res$warning,
                   the_error = res$error)
    
  }
  
  
  rm(res)
  
  return(output)
  
  
}




# Recursive with endogenous continuous variable
fit_MXS_continuous_recursive <- function(original_data_object, 
                                         copula_class = "N", 
                                         # non-survival marginal response
                                         NonSurv_Margin = "N",
                                         # cuts / intervals
                                         number_of_ints = 25, 
                                         #
                                         maximum_time_cut = 18.5,
                                         #
                                         varying_dependence = FALSE,
                                         #
                                         endogeneity_funcform = "nonlinear",
                                         # smooth the baseline function of time on time scale or log(time) scale
                                         baseline_smooth = "log",
                                         # for confidence intervals
                                         n.sim = 500,
                                         # further arguments
                                         hess_reg = "t"
){
  
  original_data <- original_data_object$dataset
  
  # extra reg settings:
  extra.regularization <- hess_reg
  
  
  the_used_cuts <- seq(from = 0,  
                       to = maximum_time_cut, 
                       length.out = number_of_ints)
  
  # ADDED ONE SYNTHETIC OBSERVATION OT GET DATALONG TO WORK:
  # original_data_synth <- original_data[nrow(original_data), ]
  # original_data_synth$status <- 0
  # 
  # original_data[(nrow(original_data)+1), ] <- original_data_synth
  
  # create intervals:
  # 0 is always included in this function, so remove it from the vector of the_used_cuts!
  dat_disc <-  contToDisc(dataShort = original_data, 
                          timeColumn = "time", 
                          intervalLimits = the_used_cuts[-1]
  )
  
  
  # Adjustment for identification (see documentation of discSurv)
  dat_disc$timeDisc[dat_disc$timeDisc == max(dat_disc$timeDisc)] <- tail(sort(unique(dat_disc$timeDisc)), 2)[1]
  dat_disc$status[dat_disc$timeDisc == max(dat_disc$timeDisc)] <- 0
  
  
  # create long-format for survival margin (called internally margin 2 but enters the
  # fitting function and is treated there as margin 1)
  dataset_long_margin2 <- discSurv:::dataLong(dat_disc, 
                                              timeColumn = "timeDisc", 
                                              eventColumn = "status")
  
  # create list of indices for margin 2 
  INDCS_list <- sapply(levels(as.factor(dataset_long_margin2$obj)), 
                       function(i) which(dataset_long_margin2$obj == i), 
                       simplify = FALSE)
  
  
  # extract unique values of time intervals:
  the_unique_tends <- unique(dat_disc$timeDisc)
  
  
  # attach ped_status in the model:
  # this is to trick GJRM into fitting!
  original_data$y_margin2 <- sample(dataset_long_margin2$y, size = nrow(original_data), replace = TRUE)
  original_data$timeInt_margin2 <- sample(dataset_long_margin2$y, size = nrow(original_data), replace = TRUE)
  
  # rename in long dataset to avoid any issues
  dataset_long_margin2$y_margin2 <- dataset_long_margin2$y
  dataset_long_margin2$timeInt_margin2 <- dataset_long_margin2$timeInt
  
  
  
  ###########################################################################################################
  # DTS formula, i.e. smooth baseline hazard using splines
  
  if(endogeneity_funcform == "nonlinear"){
    
    DTS_formula <- as.formula( y_margin2 ~ s(timeInt_margin2, bs = "ps", k = 10, m = 2) + 
                                 s(y1, k = 6, m = 2) +
                                 x2 +
                                 x4
    )
    
    
    # smooth time on the log() scale (for smoother results according to literature)
    DTS_log_formula <- as.formula(y_margin2 ~ s(log(as.numeric(timeInt_margin2)), bs = "ps", k = 10,  m = 2) +
                                    s(y1, bs = "ps", k = 6, m = 2) +
                                    x2 +
                                    x4
    )
    
    
  }
  
  if(endogeneity_funcform == "linear"){
    
    DTS_formula <- as.formula( y_margin2 ~ s(timeInt_margin2, bs = "ps", k = 10, m = 2) + 
                                 y1 +
                                 x2 +
                                 x4
    )
    
    
    # smooth time on the log() scale (for smoother results according to literature)
    DTS_log_formula <- as.formula(y_margin2 ~ s(log(as.numeric(timeInt_margin2)), bs = "ps", k = 10,  m = 2) +
                                    y1 +
                                    x2 +
                                    x4
    )
    
  }
  
  # Formula for dependence parameter (necessary in some cases)
  if(varying_dependence){
    
    Copula_param_formula <- as.formula( ~ 1 + x5)
    
  }else{
    
    Copula_param_formula <- as.formula( ~ 1)
  }
  
  
  #### CONTINUOUS
  # Gaussian
  if(NonSurv_Margin == "N"){
    
    MXS_margins <- c("PO", "N")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Log-normal
  if(NonSurv_Margin == "LN"){
    
    MXS_margins <- c("PO", "LN")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
    
  }
  
  # Logistic
  if(NonSurv_Margin == "LO"){
    
    MXS_margins <- c("PO", "LO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
    
  }
  
  # Beta
  if(NonSurv_Margin == "BE"){
    
    MXS_margins <- c("PO", "BE")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
    
  }
  
  # Log-logistic
  if(NonSurv_Margin == "FISK"){
    
    MXS_margins <- c("PO", "FISK")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
    
  }
  
  # Dagum
  if(NonSurv_Margin == "DAGUM"){
    
    MXS_margins <- c("PO", "DAGUM")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    NonSurv_Mar_Param3_formula <- as.formula( ~  1)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          NonSurv_Mar_Param3_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula, 
                          NonSurv_Mar_Param3_formula,
                          Copula_param_formula)
      
    }
    
  }
  
  
  #### DISCRETE 
  # Poisson
  if(NonSurv_Margin == "PO"){
    
    MXS_margins <- c("PO", "PO")
    
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Negative binomial I 
  if(NonSurv_Margin == "NBI"){
    
    MXS_margins <- c("PO", "NBI")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
  }
  
  # Negative binomial I 
  if(NonSurv_Margin == "NBII"){
    
    MXS_margins <- c("PO", "NBII")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2)
    
    NonSurv_Mar_Param2_formula <- as.formula( ~  x3)
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(DTS_log_formula,
                          NonSurv_Mar_formula, 
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }else{
      
      MXS_formula <- list(DTS_formula,
                          NonSurv_Mar_formula,
                          NonSurv_Mar_Param2_formula,
                          Copula_param_formula)
      
    }
  }
  
  
  #### BINARY 
  # Logit
  if(NonSurv_Margin == "logit"){
    
    MXS_margins <- c("logit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
  }
  
  # Probit
  if(NonSurv_Margin == "probit"){
    
    MXS_margins <- c("probit", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
    
  }
  
  # Clog log 
  if(NonSurv_Margin == "cloglog"){
    
    MXS_margins <- c("cloglog", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
  }
  
  # GEV link
  if(NonSurv_Margin == "GEVlink"){
    
    MXS_margins <- c("GEVlink", "PO")
    
    NonSurv_Mar_formula <- as.formula(y1 ~ x1 + x2) 
    
    # Create final list of formulae for fitting
    if(baseline_smooth == "log"){
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_log_formula)
      
    }else{
      
      MXS_formula <- list(NonSurv_Mar_formula,
                          DTS_formula)
      
    }
  }
  
  
  
  # FIT:
  # Control for the computation time as well 
  model_runtime <- system.time(
    res <- myTryCatch(
      gjrm(
        MXS_formula, 
        data = original_data, 
        BivD = copula_class,      
        # This is MBS with either DTS or PWE margin
        margins = MXS_margins, # Combination of margins
        Model = "B",
        # List of subject ids
        ListOfIDs = INDCS_list,
        # PWE format dataset (long)
        PAMM_dataset = dataset_long_margin2,
        # further arguments
        gc.l = FALSE,
        extra.regI = extra.regularization)
    )
  )
  
  
  
  # Check if the model was actually fitted and there is an output!
  if(!is.null(res$value)){
    
    # In this case we only care about the copula parameter / kendall's tau:
    if( NonSurv_Margin == "N" ){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      # --- > all prediction points of the spline in 100, equidistant points!
      
      #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      model_coefficients <- coef(res$value)
      
      
      kendall_binary_PWE <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- 200
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels, 
      #                                 function(i) 
      #                                   matrixStats:::rowQuantiles(fit1Sim, 
      #                                                              probs = c(i/2, 1 - i/2), 
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      # 
      # # PWE margin:
      # confints_loghazard <- sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(fit2Sim, 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      # 
      # 
      # confints_hazard <- sapply(prob_levels, 
      #                           function(i) 
      #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
      #                                                        probs = c(i/2, 1 - i/2), 
      #                                                        na.rm = TRUE),
      #                           simplify = FALSE)
      # 
      # 
      # # Compute the cumulative sum correctily:
      # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
      #                          function(i) 
      #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
      #                          simplify = TRUE)
      # 
      # # Compute quantiles
      # confints_cumuhazard <-  sapply(prob_levels, 
      #                                function(i) 
      #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
      #                                                             probs = c(i/2, 1 - i/2), 
      #                                                             na.rm = TRUE),
      #                                simplify = FALSE)
      # 
      # 
      # confints_survival <-  sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      # confint_materials <- list(all_coefficients  = confints_list, 
      #                           binary_spline = confints_binary_spline, 
      #                           loghazard = confints_loghazard, 
      #                           hazard = confints_loghazard, 
      #                           cumuhazard = confints_cumuhazard, 
      #                           survival = confints_survival,
      #                           copula_param = confints_copulaparam,
      #                           kendall_tau = confints_tau)
      
      coverages_materials <-list(tau = coverage_tau,
                                 copula_parameter = coverage_copula_param,
                                 beta_nonsurv_margin = NULL,
                                 beta_surv_margin = NULL)
      
      
      output <- list(model_coefficients = model_coefficients,
                     confints = coverages_materials,
                     estimated_copula_parameter = res$value$theta,
                     estimated_kendall_tau = res$value$tau,
                     nrow_datalong = dim(dataset_long_margin2))
      
      
      
    }
    
    if( (NonSurv_Margin == "N" && (varying_dependence)) ){
      
      # extract Goodness of fit residuals from the survival margin: 
      residuals_materials <- myTryCatch(compute_relevant_residuals(model = res$value, 
                                                                   data_short = original_data, 
                                                                   data_long = dataset_long_margin2, 
                                                                   type = "DT", 
                                                                   indices = INDCS_list, 
                                                                   equation_survmodel = 1))
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)]
      
      coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
      
      coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <- 0:number_of_ints
      time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$timeInt <- time_synth
      dat_ped_new$timeInt_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <- predict(res$value,
                                     eq = 1,
                                     newdata = dat_ped_ready,
                                     type = "terms")[,3] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
      
      # Step 5:
      baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard  )
      
      cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
      
      # Step 8:
      survivalfunction <- cumprod( 1 - baseline_hazard )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),2)[1]
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0, y1 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 4)] )
      
      # Copula parameter and then into tau:
      dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
      
      XfitCopParam <- predict(res$value, eq = 4, type = "lpmatrix", newdata = dat_ped_ready_copparam)
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
      
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit1Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit1Sim),
                               function(i)
                                 cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- sapply(1:ncol(fit1Sim),
                                         function(i)
                                           -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                         simplify = TRUE)
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit1Sim),
                                function(i)
                                  cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                 function(i)
                                                   matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                              probs = c(i/2, 1 - i/2),
                                                                              na.rm = TRUE),
                                                 simplify = FALSE)
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      ## endogenous spline
      endo_spline_data <- data.frame(y1 = seq(0, 10, length.out = 100),
                                     x1 = 0,
                                     x2 = 0,
                                     x4 = 0,
                                     x5 = 0,
                                     timeInt_margin2 = 0)
      
      estimated_endo_spline <- predict(res$value, eq = 1, type = "terms", newdata = endo_spline_data)[ , 4 ]
      
      
      XfitEndo <- predict(res$value, eq = 1, type = "lpmatrix", newdata = endo_spline_data)
      
      XfitEndo[,1] <- 0
      
      XfitEndo <- XfitEndo[,  13:ncol(XfitEndo) ]
      
      fit2SimEndo <- XfitEndo %*% t(bs[, 13:17 ])
      
      confints_endo_spline <- sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2SimEndo,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
      
      # For the true value: 
      copparam_true_df <- data.frame(Intercept = 1,
                                     x5_true = seq(-1, +1, length.out = 200)
      )
      
      eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        
        copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                 sign(eta_copparam_true) * 8.75, 
                                 eta_copparam_true)
        
        copparam_true <- tanh(copparam_true) 
        
        
        tau_true <-  2 / pi * asin(copparam_true) 
        
        
        ### FOR CONFIDENCE INTERVALS
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true ) 
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true ) 
        
        copparam_true <- exp( copparam_true )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- tau_true / ( tau_true + 2 ) 
        
        
        
        
        ##############
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <-  -( exp( copparam_true ) )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
        
        
        
        ###########################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp( copparam_true ) + 1   
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <-  1 - 1 / tau_true 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- -( exp( copparam_true ) + 1  )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <-  -( 1 - 1 / abs(tau_true) ) 
        
        
        #############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp(copparam_true) + 1
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        
        tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
        
        
        
        
        ################################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- - ( exp(copparam_true) + 1 )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- - tau_true
        
        tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                 epsilon, 
                                 eta_copparam_true )     
        
        
        signs <- sign(copparam_true) 
        
        copparam_true <- ifelse(abs(copparam_true) > 35, 
                                35, 
                                abs(copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        copparam_true <- copparam_true*signs
        
        tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
        
        
        #################
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        rowQuantiles(fitCopParSim,
                                                     probs = c(i/2, 1 - i/2),
                                                     na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                rowQuantiles(fitTauSim,
                                             probs = c(i/2, 1 - i/2),
                                             na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 4) ]
      
      surv_beta_vector <-  bs[ , 1:3 ]#bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      copparam_beta_vector <- bs[, (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
      surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals  of each coefficient!
      surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals  of each coefficient!
      surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
        
      )
      
      coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
      )
      
      coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
      )
      
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
        
      )
      
      coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
        
      )
      
      coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                confints_endo_spline = confints_endo_spline,
                                #
                                coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                    ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                    ninetyfive = coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                     ninetyseven_pointfive = coverage2_surv_margin,
                                                                     ninetyfive = coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        coefficients_copula_parameter = coefficients_copula_parameter,
        #
        #
        estimated_endo_spline = estimated_endo_spline,
        #
        #
        residuals_materials = residuals_materials,
        #
        # Smooth functions
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus 
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
    }
    
    if( NonSurv_Margin %in% c("logit", "probit", "cloglog", "GEVlink") ){
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ]
      
      coefficients_survival_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      
      coefficients_copula_parameter <- coef(res$value)[length(coef(res$value))]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <- 0:number_of_ints
      time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$timeInt <- time_synth
      dat_ped_new$timeInt_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <- predict(res$value,
                                     eq = 2,
                                     newdata = dat_ped_ready,
                                     type = "terms")[,4] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][2]
      
      # Step 5:
      baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard  )
      
      cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
      
      # Step 8:
      survivalfunction <- cumprod( 1 - baseline_hazard )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] )
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit2Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit2Sim),
                               function(i)
                                 cumsum( (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- sapply(1:ncol(fit2Sim),
                                         function(i)
                                           -cumsum( log(1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ) ),
                                         simplify = TRUE)
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit2Sim),
                                function(i)
                                  cumprod( 1 -  (1 - exp( - exp(fit2Sim[,i] ) ) ) ),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                 function(i)
                                                   matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                              probs = c(i/2, 1 - i/2),
                                                                              na.rm = TRUE),
                                                 simplify = FALSE)
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      surv_beta_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
      
      
      # This returns a list with the 99% confidence intervals
      surv_marg_confints1 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      surv_marg_confints2 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      surv_marg_confints3 <- sapply(1:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(surv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage2_surv_margin <- sapply(surv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      coverage3_surv_margin <- sapply(surv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        
      )
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(nonsurv_marg_confints1, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage2_nonsurv_margin <- sapply(nonsurv_marg_confints2, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      coverage3_nonsurv_margin <- sapply(nonsurv_marg_confints3, function(i) 
        
        lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                #binary_spline = confints_binary_spline,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                #
                                coverage_beta_nonsurv_margin = list(coverage1_nonsurv_margin,
                                                                    coverage2_nonsurv_margin,
                                                                    coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(coverage1_surv_margin,
                                                                     coverage2_surv_margin,
                                                                     coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      # coverages_materials <-list(tau = coverage_tau,
      #                            copula_parameter = coverage_copula_param,
      #                            beta_nonsurv_margin = NULL,
      #                            beta_surv_margin = NULL)
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        copula_parameter_intercept = copula_parameter_intercept,
        #
        # Smooth functions
        #binary_spline = binary_pred_spline,
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus between some quantities (F(y1), S(y2), etc)
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
      
      # output <- list(estimated_copula_parameter = res$value$theta,
      #                estimated_kendall_tau = res$value$tau,
      #                copula_type = copula_class,
      #                coverages = coverages_materials,
      #                correlation_materials = original_data_object$correlations_materials
      # )
      
      
      
    }
    
    if( NonSurv_Margin == "PO" ){
      
      # extract Goodness of fit residuals from the survival margin: 
      residuals_materials <- myTryCatch(compute_relevant_residuals(model = res$value, 
                                                                   data_short = original_data, 
                                                                   data_long = dataset_long_margin2, 
                                                                   type = "DT", 
                                                                   indices = INDCS_list, 
                                                                   equation_survmodel = 1))
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)]
      
      coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
      
      coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <- 0:number_of_ints
      time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$timeInt <- time_synth
      dat_ped_new$timeInt_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <- predict(res$value,
                                     eq = 1,
                                     newdata = dat_ped_ready,
                                     type = "terms")[,3] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
      
      # Step 5:
      baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard  )
      
      cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
      
      # Step 8:
      survivalfunction <- cumprod( 1 - baseline_hazard )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),2)[1]
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0, y1 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)] )
      
      # Copula parameter and then into tau:
      dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
      
      XfitCopParam <- predict(res$value, eq = 3, type = "lpmatrix", newdata = dat_ped_ready_copparam)
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
      
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit1Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit1Sim),
                               function(i)
                                 cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- sapply(1:ncol(fit1Sim),
                                         function(i)
                                           -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                         simplify = TRUE)
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit1Sim),
                                function(i)
                                  cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                 function(i)
                                                   matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                              probs = c(i/2, 1 - i/2),
                                                                              na.rm = TRUE),
                                                 simplify = FALSE)
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      ## endogenous spline
      endo_spline_data <- data.frame(y1 = seq(0, 10, length.out = 100),
                                     x1 = 0,
                                     x2 = 0,
                                     x4 = 0,
                                     x5 = 0,
                                     timeInt_margin2 = 0)
      
      estimated_endo_spline <- predict(res$value, eq = 1, type = "terms", newdata = endo_spline_data)[ , 4 ]
      
      
      XfitEndo <- predict(res$value, eq = 1, type = "lpmatrix", newdata = endo_spline_data)
      
      XfitEndo[,1] <- 0
      
      XfitEndo <- XfitEndo[,  13:ncol(XfitEndo) ]
      
      fit2SimEndo <- XfitEndo %*% t(bs[, 13:17 ])
      
      confints_endo_spline <- sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2SimEndo,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
      
      # For the true value: 
      copparam_true_df <- data.frame(Intercept = 1,
                                     x5_true = seq(-1, +1, length.out = 200)
      )
      
      eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        
        copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                 sign(eta_copparam_true) * 8.75, 
                                 eta_copparam_true)
        
        copparam_true <- tanh(copparam_true) 
        
        
        tau_true <-  2 / pi * asin(copparam_true) 
        
        
        ### FOR CONFIDENCE INTERVALS
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true ) 
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true ) 
        
        copparam_true <- exp( copparam_true )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- tau_true / ( tau_true + 2 ) 
        
        
        
        
        ##############
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <-  -( exp( copparam_true ) )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
        
        
        
        ###########################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp( copparam_true ) + 1   
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <-  1 - 1 / tau_true 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- -( exp( copparam_true ) + 1  )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <-  -( 1 - 1 / abs(tau_true) ) 
        
        
        #############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp(copparam_true) + 1
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        
        tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
        
        
        
        
        ################################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- - ( exp(copparam_true) + 1 )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- - tau_true
        
        tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                 epsilon, 
                                 eta_copparam_true )     
        
        
        signs <- sign(copparam_true) 
        
        copparam_true <- ifelse(abs(copparam_true) > 35, 
                                35, 
                                abs(copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        copparam_true <- copparam_true*signs
        
        tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
        
        
        #################
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        rowQuantiles(fitCopParSim,
                                                     probs = c(i/2, 1 - i/2),
                                                     na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                rowQuantiles(fitTauSim,
                                             probs = c(i/2, 1 - i/2),
                                             na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 2) ]
      
      surv_beta_vector <-  bs[ , 1:3 ]#bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      copparam_beta_vector <- bs[, (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
      surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals  of each coefficient!
      surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals  of each coefficient!
      surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
        
      )
      
      coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
      )
      
      coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
      )
      
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
        
      )
      
      coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
        
      )
      
      coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                confints_endo_spline = confints_endo_spline,
                                #
                                coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                    ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                    ninetyfive = coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                     ninetyseven_pointfive = coverage2_surv_margin,
                                                                     ninetyfive = coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        coefficients_copula_parameter = coefficients_copula_parameter,
        #
        #
        estimated_endo_spline = estimated_endo_spline,
        #
        #
        residuals_materials = residuals_materials,
        #
        # Smooth functions
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus 
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
    }
    
    if( NonSurv_Margin %in% c("NBI", "NBII") ){
      
      # extract Goodness of fit residuals from the survival margin: 
      residuals_materials <- myTryCatch(compute_relevant_residuals(model = res$value, 
                                                                   data_short = original_data, 
                                                                   data_long = dataset_long_margin2, 
                                                                   type = "DT", 
                                                                   indices = INDCS_list, 
                                                                   equation_survmodel = 1))
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 2)]
      
      coefficients_survival_margin <- coef(res$value)[ 1:( (which(names(coef(res$value)) == "(Intercept)")[2])-1 ) ] 
      
      coefficients_copula_parameter <- coef(res$value)[ (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      
      # Survival / margin
      # --- > all prediction points of the spline in 200, equidistant points! (baseline hazard)
      
      # 1: Create rich sequence of time points for the splines
      # 2: Use predict(, type = "terms")
      # 3: Extract the prediction of only the log( baseline hazard )
      # 4: Add the intercept to all observations
      # 5: Transform into hazard rate, 
      # 6: Obtain original interval lengths (all equidistant)  
      # 7: Obtain the cumu hazard, 
      # 8: Transform into survival function.
      # Step 1: 
      time_synth <- 0:number_of_ints
      time_synth2 <- 0:number_of_ints#seq(0, max(dataset_long_margin2$timeInt_margin2), length.out = 200)
      
      dat_ped_new <- dataset_long_margin2[1:length(time_synth), ]
      
      dat_ped_new$timeInt <- time_synth
      dat_ped_new$timeInt_margin2 <- time_synth
      
      dat_ped_ready <- dat_ped_new %>% 
        mutate(x1 = 0,
               x2 = 0,
               x3 = 0,
               x5 = 0,
               x4 = 0,
               y1 = 0)
      
      # Step 2 + 3 + 4:
      # Intercept is added
      baseline_link_scale <- predict(res$value,
                                     eq = 1,
                                     newdata = dat_ped_ready,
                                     type = "terms")[,3] +
        coef(res$value)[which(names(coef(res$value)) == "(Intercept)")][1]
      
      # Step 5:
      baseline_hazard <- 1 - exp( -exp( baseline_link_scale ) )
      
      # Step 6: not needed in DTS
      
      # Step 7:
      cumuhazard_justcumsum <- cumsum( baseline_hazard  )
      
      cumuhazard_logoneminus <- - cumsum( log( 1 - baseline_hazard) )
      
      # Step 8:
      survivalfunction <- cumprod( 1 - baseline_hazard )
      # 
      # 
      ###########################
      ###########################
      
      estimated_kendall_tau <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),2)[1]
      
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- n.sim
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # For the specific splines:
      # Recover the synthetic values of the covariates:
      # remove other covariates values from the linear predictor: 
      dat_new <- dat_ped_new %>% mutate(x1 = 0, x2 = 0, x3 = 0, x4 = 0, x5 = 0, y1 = 0)
      
      # Obtain various additive predictors: 
      Xfit1 <- predict(res$value, eq = 1, type = "lpmatrix", newdata = dat_new)
      
      Xfit2 <- predict(res$value, eq = 2, type = "lpmatrix", newdata = dat_ped_ready)
      
      # Compute xbeta for first margin: binary
      fit1Sim <- Xfit1%*%t(bs[, 1:(which(names(coef(res$value)) == "(Intercept)")[2]-1)])
      
      # # Compute xbeta for second margin: PWE
      fit2Sim <- Xfit2%*%t(bs[,(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 4)] )
      
      # Copula parameter and then into tau:
      dat_ped_ready_copparam <- data.frame(x5 = seq(-1, 1, length.out = 200))
      
      XfitCopParam <- predict(res$value, eq = 4, type = "lpmatrix", newdata = dat_ped_ready_copparam)
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- XfitCopParam %*% t(bs[,(length(coefficient_vec)-1):length(coefficient_vec)])
      
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels,
      #                                 function(i)
      #                                   matrixStats:::rowQuantiles(fit1Sim,
      #                                                              probs = c(i/2, 1 - i/2),
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      
      # # Survival margin:
      confints_linkscalehazard <- sapply(prob_levels,
                                         function(i)
                                           matrixStats:::rowQuantiles(fit1Sim,
                                                                      probs = c(i/2, 1 - i/2),
                                                                      na.rm = TRUE),
                                         simplify = FALSE)
      
      
      
      confints_hazard <- sapply(prob_levels,
                                function(i)
                                  matrixStats:::rowQuantiles(1 - exp( -exp( fit1Sim ) ),
                                                             probs = c(i/2, 1 - i/2),
                                                             na.rm = TRUE),
                                simplify = FALSE)
      
      
      # # Compute the cumulative sum correctly:
      fit2Sim_cumsum <- sapply(1:ncol(fit1Sim),
                               function(i)
                                 cumsum( (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                               simplify = TRUE)
      
      
      fit2Sim_minuslogoneminus <- sapply(1:ncol(fit1Sim),
                                         function(i)
                                           -cumsum( log(1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ) ),
                                         simplify = TRUE)
      
      
      fit2Sim_cumprod <- sapply(1:ncol(fit1Sim),
                                function(i)
                                  cumprod( 1 -  (1 - exp( - exp(fit1Sim[,i] ) ) ) ),
                                simplify = TRUE)
      
      # # Compute quantiles
      confints_cumuhazard_cumsum <-  sapply(prob_levels,
                                            function(i)
                                              matrixStats:::rowQuantiles(fit2Sim_cumsum,
                                                                         probs = c(i/2, 1 - i/2),
                                                                         na.rm = TRUE),
                                            simplify = FALSE)
      
      confints_cumuhazard_logoneminus <-  sapply(prob_levels,
                                                 function(i)
                                                   matrixStats:::rowQuantiles(fit2Sim_minuslogoneminus,
                                                                              probs = c(i/2, 1 - i/2),
                                                                              na.rm = TRUE),
                                                 simplify = FALSE)
      
      confints_survival <-  sapply(prob_levels,
                                   function(i)
                                     matrixStats:::rowQuantiles(fit2Sim_cumprod,
                                                                probs = c(i/2, 1 - i/2),
                                                                na.rm = TRUE),
                                   simplify = FALSE)
      
      ## endogenous spline
      endo_spline_data <- data.frame(y1 = seq(0, 10, length.out = 100),
                                     x1 = 0,
                                     x2 = 0,
                                     x4 = 0,
                                     x5 = 0,
                                     timeInt_margin2 = 0)
      
      estimated_endo_spline <- predict(res$value, eq = 1, type = "terms", newdata = endo_spline_data)[ , 4 ]
      
      
      XfitEndo <- predict(res$value, eq = 1, type = "lpmatrix", newdata = endo_spline_data)
      
      XfitEndo[,1] <- 0
      
      XfitEndo <- XfitEndo[,  13:ncol(XfitEndo) ]
      
      fit2SimEndo <- XfitEndo %*% t(bs[, 13:17 ])
      
      confints_endo_spline <- sapply(prob_levels,
                                     function(i)
                                       matrixStats:::rowQuantiles(fit2SimEndo,
                                                                  probs = c(i/2, 1 - i/2),
                                                                  na.rm = TRUE),
                                     simplify = FALSE)
      
      # For the true value: 
      copparam_true_df <- data.frame(Intercept = 1,
                                     x5_true = seq(-1, +1, length.out = 200)
      )
      
      eta_copparam_true <- as.matrix(copparam_true_df) %*% original_data_object$true_coefficients$copula_param
      
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        
        copparam_true <- ifelse( abs(eta_copparam_true) > 8.75, 
                                 sign(eta_copparam_true) * 8.75, 
                                 eta_copparam_true)
        
        copparam_true <- tanh(copparam_true) 
        
        
        tau_true <-  2 / pi * asin(copparam_true) 
        
        
        ### FOR CONFIDENCE INTERVALS
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true ) 
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true ) 
        
        copparam_true <- exp( copparam_true )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- tau_true / ( tau_true + 2 ) 
        
        
        
        
        ##############
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <-  -( exp( copparam_true ) )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 28, 
                           28, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <- -( abs(tau_true) / ( abs(tau_true) + 2 ) )
        
        
        
        ###########################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp( copparam_true ) + 1   
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <-  1 - 1 / tau_true 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- -( exp( copparam_true ) + 1  )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 17, 
                           17, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- -tau_true
        
        tau_true <-  -( 1 - 1 / abs(tau_true) ) 
        
        
        #############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- exp(copparam_true) + 1
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        
        tau_true <- BiCopPar2Tau(family = 6, par = tau_true) 
        
        
        
        
        ################################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        copparam_true <- ifelse( eta_copparam_true > 20, 
                                 20, 
                                 eta_copparam_true )     # 709, maximum allowed # these values look fine
        
        copparam_true <- ifelse( copparam_true < -17, 
                                 -17, 
                                 copparam_true )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        copparam_true <- - ( exp(copparam_true) + 1 )
        
        # computation of TAU:
        tau_true <- ifelse(abs(copparam_true) > 30, 
                           30, 
                           abs(copparam_true)) # based on BiCopPar2Tau 
        
        tau_true <- - tau_true
        
        tau_true <- BiCopPar2Tau(family = 26, par = tau_true) 
        
        
        ##############################
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        copparam_true <- ifelse( abs(eta_copparam_true) < epsilon, 
                                 epsilon, 
                                 eta_copparam_true )     
        
        
        signs <- sign(copparam_true) 
        
        copparam_true <- ifelse(abs(copparam_true) > 35, 
                                35, 
                                abs(copparam_true)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        copparam_true <- copparam_true*signs
        
        tau_true <- BiCopPar2Tau(family = 5, par = copparam_true) 
        
        
        #################
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitCopParSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        rowQuantiles(fitCopParSim,
                                                     probs = c(i/2, 1 - i/2),
                                                     na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                rowQuantiles(fitTauSim,
                                             probs = c(i/2, 1 - i/2),
                                             na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        mean( 1 * data.table::between(copparam_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        mean( 1 * data.table::between(tau_true, i[,1], i[,2]) ) 
        
      )
      
      
      
      # extract coefficients of nonsurvival margin
      beta_nonsurv_vector <- bs[ , (which(colnames(bs) == "(Intercept)")[2]):(which(colnames(bs) == "(Intercept)")[2] + 4) ]
      
      surv_beta_vector <-  bs[ , 1:3 ]#bs[ , 1:(which(colnames(bs) == "(Intercept)")[2]-1) ]
      
      copparam_beta_vector <- bs[, (length(coef(res$value))-1):length(coef(res$value)) ]
      
      
      # This returns a list with the 99% confidence intervals of each coefficient! (START AT 2 BECAUSE THE INTERCEPT IS NOT USED)
      surv_marg_confints1 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals  of each coefficient!
      surv_marg_confints2 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals  of each coefficient!
      surv_marg_confints3 <- sapply(2:ncol(surv_beta_vector), function(i) 
        quantile(surv_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      
      # Now for the nonsurvival margin:
      nonsurv_marg_confints1 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      # This returns a list with the 95% confidence intervals
      nonsurv_marg_confints2 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      # This returns a list with the 90% confidence intervals
      nonsurv_marg_confints3 <- sapply(1:ncol(beta_nonsurv_vector), function(i) 
        quantile(beta_nonsurv_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      copula_param_coeff_confints1 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.01/2, 1 - 0.01/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints2 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.05/2, 1 - 0.05/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      copula_param_coeff_confints3 <-  sapply(1:ncol(copparam_beta_vector), function(i) 
        quantile(copparam_beta_vector[,i],
                 probs = c(0.10/2, 1 - 0.10/2),
                 na.rm = TRUE),
        simplify = FALSE
      )
      
      
      
      # Compute coverages:
      coverage1_surv_margin <- sapply(1:length(surv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints1[[i]][1], surv_marg_confints1[[i]][2])
        
      )
      
      coverage2_surv_margin <- sapply(1:length(surv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints2[[i]][1], surv_marg_confints2[[i]][2])
      )
      
      coverage3_surv_margin <- sapply(1:length(surv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[2]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$surv[i], 
                                surv_marg_confints3[[i]][1], surv_marg_confints3[[i]][2])
      )
      
      
      
      ########### now for the nonsurvival margin:
      coverage1_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints1), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints1[[i]][1], nonsurv_marg_confints1[[i]][2])
        
      )
      
      coverage2_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints2), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints2[[i]][1], nonsurv_marg_confints2[[i]][2])
        
      )
      
      coverage3_nonsurv_margin <- sapply(1:length(nonsurv_marg_confints3), function(i) 
        
        #lies_in_interval(original_data_object$true_coefficients[[1]][1], i)
        1 * data.table::between(original_data_object$true_coefficients$non_surv[i], 
                                nonsurv_marg_confints3[[i]][1], nonsurv_marg_confints3[[i]][2])
        
      )
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      confint_materials <- list(all_coefficients  = confints_list,
                                linkscale_hazard = confints_linkscalehazard,
                                hazard = confints_hazard,
                                cumuhazard_cumsum = confints_cumuhazard_cumsum,
                                cumuhazard_logoneminus = confints_cumuhazard_logoneminus,
                                survival = confints_survival,
                                copula_param = confints_copulaparam,
                                kendall_tau = confints_tau, 
                                confints_endo_spline = confints_endo_spline,
                                #
                                coverage_beta_nonsurv_margin = list(ninetynine_pointfive = coverage1_nonsurv_margin,
                                                                    ninetyseven_pointfive = coverage2_nonsurv_margin,
                                                                    ninetyfive = coverage3_nonsurv_margin),
                                #
                                coverage_beta_survival_margin = list(ninetynine_pointfive = coverage1_surv_margin,
                                                                     ninetyseven_pointfive = coverage2_surv_margin,
                                                                     ninetyfive = coverage3_surv_margin),
                                coverage_tau = coverage_tau,
                                coverage_copula_parameter = coverage_copula_param
      )
      
      
      
      # Put everything together
      output <- list(
        # Coefficients
        coefficients_nonsurv = coefficients_nonsurv_margin,
        coefficients_survival = coefficients_survival_margin,
        coefficients_copula_parameter = coefficients_copula_parameter,
        #
        #
        estimated_endo_spline = estimated_endo_spline,
        #
        #
        residuals_materials = residuals_materials,
        #
        # Smooth functions
        linkscale_baseline = baseline_link_scale,
        baseline = baseline_hazard,
        cumu_hazard = cumuhazard_justcumsum,
        cumu_hazard_logoneminus = cumuhazard_logoneminus,
        survival = survivalfunction,
        #
        # copula parameter and dependence
        copula_parameter = copula_parameter,
        tau_of_kendall = tau_of_kendall,
        #
        # Big matrix of coefficient's confidence intervals:
        confint_materials = confint_materials,
        #
        # Various summaries
        survival_data_n = nrow(dataset_long_margin2),
        original_data_n = nrow(original_data),
        edf_nonsurvival_margin = res$value$edf[[1]],
        edf_survival_margin = res$value$edf[[2]],
        #
        #
        #
        # Stuff regarding estimated kendall taus 
        estimated_kendall = res$value$tau,
        copula_parameter_estimate = res$value$theta,
        # some other diagnostics
        cuts_placement_intime = the_used_cuts,
        the_unique_tends = the_unique_tends,
        the_warning = res$warning,
        the_error = res$error,
        model_runtime = model_runtime
      )
      
      
    }
    
    if(NonSurv_Margin %in% c("ningunadeestas")){
      
      
      
      # Evaluate the fitted model:
      # --- > overall coefficients
      # --- > all prediction points of the spline in 100, equidistant points!
      
      #coefficients_nonsurv_margin <- coef(res$value)[(which(names(coef(res$value)) == "(Intercept)")[2]):(length(coef(res$value)) - 1)] 
      model_coefficients <- coef(res$value)
      
      
      kendall_binary_PWE <- res$value$tau
      
      # Copula / dependence part 
      # --- > intercept of model of copula parameter
      # --- > copula parameter (in copula parameter scale)
      # --- > kendall´s tau (pred.mvt) with confidence interval
      copula_parameter_intercept <- tail(coef(res$value),1)
      copula_parameter <- res$value$theta
      
      # Check fitted bivariate distribution in the MBS model to 
      # compute the correct Kendall's tau:
      #GAUSS copula
      if(res$value$BivD == "N"){
        
        tau_of_kendall <- 2/pi * asin(copula_parameter) # check the formulas from GJRM ass.ms() function
        
      }
      
      # GUMBEL copula
      if(res$value$BivD == "G0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  1 - (1/theta_coppar) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED GUMBEL copula (90)
      if(res$value$BivD == "G90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 17, 17, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        
        tau_of_kendall <-  -( 1 - (1/abs(theta_coppar)) ) # check the formulas from GJRM ass.ms() function
        
      }
      
      # CLAYTON copula
      if(res$value$BivD == "C0"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <-  theta_coppar/(theta_coppar + 2) # check the formulas from GJRM ass.ms() function
        
      }
      
      # ROTATED CLAYTON copula (90)
      if(res$value$BivD == "C90"){
        
        theta_coppar <- ifelse(abs(copula_parameter) > 28, 28, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- - theta_coppar
        
        tau_of_kendall <- -(abs(theta_coppar)/(abs(theta_coppar)+2))  # check the formulas from GJRM ass.ms() function
        
      }
      
      # FRANK copula
      if(copula_class == "F"){
        
        
        signs <- sign(copula_parameter) 
        theta_coppar <- ifelse(abs(copula_parameter) > 35, 35, abs(copula_parameter)) 
        theta_coppar <- theta_coppar*signs 
        
        
        tau_of_kendall <- BiCopPar2Tau(family = 5, par = theta_coppar)  # check the formulas from GJRM ass.ms() function
        
      }
      
      # JOE copula
      if(res$value$BivD == "J0"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        tau_of_kendall <- BiCopPar2Tau(family = 6, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # ROTATED JOE (90)
      if(res$value$BivD == "J90"){
        
        
        theta_coppar <- ifelse(abs(copula_parameter) > 30, 
                               30, 
                               abs(copula_parameter)) # based on BiCopPar2Tau 
        
        theta_coppar <- -theta_coppar
        
        tau_of_kendall <- BiCopPar2Tau(family = 26, par = theta_coppar)     # check the formulas from GJRM ass.ms() function
        
        
      }
      
      # --- > Confidence interval for the estimated coefficients, use the following object in the model: 
      #        Object Vb 
      #        for confidence intervals of coefficients (check how these are calculated, i.e. from which 
      #        function of the mvt normal distr. is used to sample from them!
      #        Obtain the following coverages: 90% ,     95%,        99%
      #                                       (1-0.05),  (1-0.025)   (1-0.005)
      
      # Confidence intervals of all coefficients will be obtained via simulations
      # For transformations of the linear predictor (i.e. survival function, etc): 
      # simulation as well as direct transformation of the linear predictor
      
      # Simulation: OBTAIN COEFFICIENTS, OBTAIN Vb, then: 
      # Draw samples beta_r, r = 1, dots, R. Then compute the desired transformation Function(beta_r)_r. 
      # Compute quantiles from this sample of size R.  
      # Set the number of simulations from the posterior to: 500, default = 200.
      
      # Direct transformation: eta_hat +- qnorm(1-alpha/2) * se.fit(eta_hat) <- (from predict(model, eq = 2, se = TRUE)$se.fit) 
      # ALL OF THESE CONFIDENCE INTERVALS ARE OBTAINED VIA SIMULATION!
      # Extract coeffs again
      coefficient_vec <- coef(res$value)
      
      # Extract coeffs
      coeff_cov_mat <- res$value$Vb
      
      n.sim <- 200
      
      # Samples from the asymptotic distribution of of the coefficient vector
      bs <- GJRM:::rMVN(n.sim, mean = coefficient_vec, sigma = coeff_cov_mat)
      
      
      # COMPUTE CONFIDENCE INTERVALS FOR ALL coefficients:
      # using the typical levels
      prob_levels <- c(0.01, 0.05, 0.1)
      
      confints_list <- sapply(prob_levels, 
                              function(i) matrixStats:::colQuantiles(bs, 
                                                                     probs = c(i/2, 
                                                                               1 - i/2),
                                                                     na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      
      # Compute xbeta for copula parameter:
      fitCopParSim <- bs[,length(coefficient_vec)]
      
      # Compute now transformation of this: 
      # Binary margin: just the spline: 
      # confints_binary_spline <-sapply(prob_levels, 
      #                                 function(i) 
      #                                   matrixStats:::rowQuantiles(fit1Sim, 
      #                                                              probs = c(i/2, 1 - i/2), 
      #                                                              na.rm = TRUE),
      #                                 simplify = FALSE)
      # 
      # # PWE margin:
      # confints_loghazard <- sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(fit2Sim, 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      # 
      # 
      # confints_hazard <- sapply(prob_levels, 
      #                           function(i) 
      #                             matrixStats:::rowQuantiles(1 - exp( -exp( fit2Sim ) ), 
      #                                                        probs = c(i/2, 1 - i/2), 
      #                                                        na.rm = TRUE),
      #                           simplify = FALSE)
      # 
      # 
      # # Compute the cumulative sum correctily:
      # fit2Sim_cumsum <- sapply(1:ncol(fit2Sim), 
      #                          function(i) 
      #                            cumsum(   1 - exp( - exp(fit2Sim[,i] ) ) ),
      #                          simplify = TRUE)
      # 
      # # Compute quantiles
      # confints_cumuhazard <-  sapply(prob_levels, 
      #                                function(i) 
      #                                  matrixStats:::rowQuantiles(fit2Sim_cumsum, 
      #                                                             probs = c(i/2, 1 - i/2), 
      #                                                             na.rm = TRUE),
      #                                simplify = FALSE)
      # 
      # 
      # confints_survival <-  sapply(prob_levels, 
      #                              function(i) 
      #                                matrixStats:::rowQuantiles(1 - (1 - exp( -exp( fit2Sim ) )), 
      #                                                           probs = c(i/2, 1 - i/2), 
      #                                                           na.rm = TRUE),
      #                              simplify = FALSE)
      # 
      
      
      # Compute confidence intervals for the copula parameter:
      # GAUSS COPULA
      if(res$value$BivD == "N"){
        
        # just a vector of values, since the model is currently has only an intercept:
        fitCopParSim <- ifelse( abs(fitCopParSim) > 8.75, 
                                sign(fitCopParSim)*8.75, 
                                fitCopParSim)
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- tanh(fitCopParSim) 
        
        # computation of TAU:
        fitTauSim <-  2 / pi * asin(fitCopParSim) 
        # looks fine and gives almost 1# check the formulas from GJRM ass.ms() function
        
      }
      
      
      # CLAYTON COPULA
      if(res$value$BivD == "C0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- fitTauSim / ( fitTauSim + 2 ) 
        
      }
      
      
      # ROTATED CLAYTON COPULA (90)
      if(res$value$BivD == "C90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <-  -( exp( fitCopParSim ) )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 28, 
                            28, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <- -( abs(fitTauSim) / ( abs(fitTauSim) + 2 ) )
        
        
        
      }
      
      
      # GUMBEL COPULA 
      if(res$value$BivD == "G0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp( fitCopParSim ) + 1   
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <-  1 - 1 / fitTauSim 
        
      }
      
      
      # ROTATED GUMBEL COPULA (90)
      if(res$value$BivD == "G90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- -( exp( fitCopParSim ) + 1  )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 17, 
                            17, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- -fitTauSim
        
        fitTauSim <-  -( 1 - 1 / abs(fitTauSim) ) 
        
      }
      
      
      # JOE COPULA
      if(res$value$BivD == "J0"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- exp(fitCopParSim) + 1
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        
        fitTauSim <- BiCopPar2Tau(family = 6, par = fitTauSim) 
        
        
      }
      
      
      # ROTATED JOE COPULA (90)
      if(res$value$BivD == "J90"){
        
        
        fitCopParSim <- ifelse( fitCopParSim > 20, 
                                20, 
                                fitCopParSim )     # 709, maximum allowed # these values look fine
        
        fitCopParSim <- ifelse( fitCopParSim < -17, 
                                -17, 
                                fitCopParSim )   # -20                  # 
        
        
        # compute copula parameter from the additive predictor of
        # the copula parameter:
        fitCopParSim <- - ( exp(fitCopParSim) + 1 )
        
        # computation of TAU:
        fitTauSim <- ifelse(abs(fitCopParSim) > 30, 
                            30, 
                            abs(fitCopParSim)) # based on BiCopPar2Tau 
        
        fitTauSim <- - fitTauSim
        
        fitTauSim <- BiCopPar2Tau(family = 26, par = fitTauSim) 
        
        
      }
      
      
      # FRANK COPULA
      if(res$value$BivD == "F"){
        
        epsilon <- c(sqrt(.Machine$double.eps))
        
        fitCopParSim <- ifelse( abs(fitCopParSim) < epsilon, 
                                epsilon, 
                                fitCopParSim )     
        
        
        signs <- sign(fitCopParSim) 
        
        fitCopParSim <- ifelse(abs(fitCopParSim) > 35, 
                               35, 
                               abs(fitCopParSim)) # changed from 100 - 17/09/2021, due to BiCopPar2Tau
        
        fitCopParSim <- fitCopParSim*signs
        
        fitTauSim <- BiCopPar2Tau(family = 5, par = fitTauSim) 
        
        
      }
      
      
      
      
      
      confints_copulaparam <-  sapply(prob_levels,
                                      function(i)
                                        quantile(fitCopParSim,
                                                 probs = c(i/2, 1 - i/2),
                                                 na.rm = TRUE),
                                      simplify = FALSE)
      
      
      # intervals for KENDALLs TAU:
      confints_tau <-  sapply(prob_levels,
                              function(i)
                                quantile(fitTauSim,
                                         probs = c(i/2, 1 - i/2),
                                         na.rm = TRUE),
                              simplify = FALSE)
      
      
      
      # Compute the coverages:
      coverage_copula_param <- sapply(confints_copulaparam, function(i) 
        
        lies_in_interval(original_data_object$true_copula_param, i)
        
      )
      
      coverage_tau <- sapply(confints_tau, function(i) 
        
        lies_in_interval(original_data_object$original_tau, i)
        
      )
      
      
      
      
      names(coverage_tau) <- c("99%", "95%", "90%")
      names(coverage_copula_param) <- c("99%", "95%", "90%")
      
      
      
      
      # confint_materials <- list(all_coefficients  = confints_list, 
      #                           binary_spline = confints_binary_spline, 
      #                           loghazard = confints_loghazard, 
      #                           hazard = confints_loghazard, 
      #                           cumuhazard = confints_cumuhazard, 
      #                           survival = confints_survival,
      #                           copula_param = confints_copulaparam,
      #                           kendall_tau = confints_tau)
      
      coverages_materials <-list(tau = coverage_tau,
                                 copula_parameter = coverage_copula_param,
                                 beta_nonsurv_margin = NULL,
                                 beta_surv_margin = NULL)
      
      
      output <- list(model_coefficients = model_coefficients,
                     confints = coverages_materials,
                     estimated_copula_parameter = res$value$theta,
                     estimated_kendall_tau = res$value$tau,
                     nrow_datalong = dim(dataset_long_margin2))
      
      
      
      
      
      
    }
    
    
    
    
    
  }else{
    
    output <- list(the_warning = res$warning,
                   the_error = res$error)
    
  }
  
  
  rm(res)
  
  return(output)
  
  
}


